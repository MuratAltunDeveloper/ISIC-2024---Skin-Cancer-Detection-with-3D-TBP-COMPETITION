{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":8987337,"sourceType":"datasetVersion","datasetId":5412712},{"sourceId":9062527,"sourceType":"datasetVersion","datasetId":5465260},{"sourceId":9104956,"sourceType":"datasetVersion","datasetId":5495198},{"sourceId":9105684,"sourceType":"datasetVersion","datasetId":5495648},{"sourceId":9106190,"sourceType":"datasetVersion","datasetId":5495898},{"sourceId":9119975,"sourceType":"datasetVersion","datasetId":5505203},{"sourceId":9181768,"sourceType":"datasetVersion","datasetId":5549685},{"sourceId":190080588,"sourceType":"kernelVersion"},{"sourceId":193364151,"sourceType":"kernelVersion"}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":51.233237,"end_time":"2024-09-04T04:00:00.815314","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-04T03:59:09.582077","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.013690Z","iopub.execute_input":"2024-09-09T06:41:04.014695Z","iopub.status.idle":"2024-09-09T06:41:04.022369Z","shell.execute_reply.started":"2024-09-09T06:41:04.014639Z","shell.execute_reply":"2024-09-09T06:41:04.021266Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n    \n]\n\nnew_num_cols = [\n    'x1',      # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'x2',      # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'x3',      # tbp_lv_H                - tbp_lv_Hext              abs\n    'x4',      # tbp_lv_L                - tbp_lv_Lext              abs\n    'x5',      # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'x6',      # tbp_lv_norm_border      + tbp_lv_symm_2axis    \n    'x7',      # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n    'x8',      # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'x9',      # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'x10',     # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'x11',     # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'x12',     # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'x13',     # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n    'x14',     # tbp_lv_stdL             / tbp_lv_Lext\n    'x15',     # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'x16',     # clin_size_long_diam_mm  * age_approx\n    'x17',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'x18',     # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'x19',     # border_complexity       + lesion_shape_index\n    'x20',     # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n    'x21',     # tbp_lv_areaMM2          + 1  np.log\n    'x22',     # clin_size_long_diam_mm  / age_approx\n    'x23',     # tbp_lv_H                + tbp_lv_Hext    / 2\n    'x24',     # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'x25',     # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'x26',     # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'x27',     # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n    'x28',     # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'x29',     # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'x30',     # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'x31',     # tbp_lv_norm_border      * tbp_lv_norm_color\n    'x32',\n    'x33',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'x34',     # tbp_lv_nevi_confidence  / age_approx\n    'x35',\n    'x36',     # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n    'x37',     # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'x38',     # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'x39',     # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'x40',     # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'x41',     # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'x42',     # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\nnew_num_cols2 = [    \n    '_7_1',    # x1-x8   x2-x9   x3-x10  x4-x11  x5-x12  x6-x13  x7-x14\n    '_7_2',    # x1-x15  x2-x16  x3-x17  x4-x18  x5-x19  x6-x20  x7-x21\n    '_7_3',    # x1-x22  x2-x23  x3-x24  x4-x25  x5-x26  x6-x27  x7-x28\n    '_7_4',    # x1-x29  x2-x30  x3-x31  x4-x32  x5-x33  x6-x34  x7-x35\n    '_7_5',    # x1-x36  x2-x37  x3-x38  x4-x39  x5-x40  x6-x41  x7-x42\n    '_7_6',    # x8-x15  x9-x16  x10-x17  x11-x18  x12-x19  x13-x20  x14-x21\n    '_7_7',    # x8-x22  x9-x23  x10-x24  x11-x25  x12-x26  x13-x27  x14-x28\n    '_7_8',    # x8-x29  x9-x30  x10-x31  x11-x32  x12-x33  x13-x34  x14-x35\n    '_7_9',    # x8-x36  x9-x37  x10-x38  x11-x39  x12-x40  x13-x41  x14-x42\n    '_7_10',   # x15-x22  x16-x23  x17-x24  x18-x25  x19-x26  x20-x27  x21-x28\n    '_7_11',   # x15-x29  x16-x30  x17-x31  x18-x32  x19-x33  x20-x34  x21-x35\n    '_7_12',   # x15-x36  x16-x37  x17-x38  x18-x39  x19-x40  x20-x41  x21-x42\n    '_7_13',   # x22-x29  x23-x30  x24-x31  x25-x32  x26-x33  x27-x34  x28-x35\n    '_7_14',   # x22-x36  x23-x37  x24-x38  x25-x39  x26-x40  x27-x41  x28-x42\n    '_7_15',   # x29-x36  x30-x37  x31-x38  x32-x39  x33-x40  x34-x41  x35-x42\n    \n    '_6_1',    # x1-x7   x2-x8   x3-x9   x4-x10  x5-x11  x6-x12\n    '_6_2',    # x1-x13  x2-x14  x3-x15  x4-x16  x5-x17  x6-x18\n    '_6_3',    # x1-x19  x2-x20  x3-x21  x4-x22  x5-x23  x6-x24\n    '_6_4',    # x1-x25  x2-x26  x3-x27  x4-x28  x5-x29  x6-x30\n    '_6_5',    # x1-x31  x2-x32  x3-x33  x4-x34  x5-x35  x6-x36\n    '_6_6',    # x1-x37  x2-x38  x3-x39  x4-x40  x5-x41  x6-x42\n    '_6_7',    # x7-x13  x8-x14  x9-x15  x10-x16  x11-x17  x12-x23\n    '_6_8',    # x7-x19  x8-x20  x9-x21  x10-x22  x11-x23  x12-x24\n    '_6_9',    # x7-x25  x8-x26  x9-x27  x10-x28  x11-x29  x12-x30\n    '_6_10',   # x7-x31  x8-x32  x9-x33  x10-x34  x11-x35  x12-x36\n    '_6_11',   # x7-x37  x8-x38  x9-x39  x10-x40  x11-x41  x12-x42\n    '_6_12',   # x13-x19  x14-x20  x15-x21  x16-x22  x17-x23  x18-x24\n    '_6_13',   # x13-x25  x14-x26  x15-x27  x16-x28  x17-x29  x18-x30\n    '_6_14',   # x13-x31  x14-x32  x15-x33  x16-x34  x17-x35  x18-x36\n    '_6_15',   # x13-x37  x14-x38  x15-x39  x16-x40  x17-x41  x18-x42\n    '_6_16',   # x19-x25  x20-x26  x21-x27  x22-x28  x23-x29  x24-x30\n    '_6_17',   # x19-x31  x20-x32  x21-x33  x22-x34  x23-x35  x24-x36\n    '_6_18',   # x19-x37  x20-x38  x21-x39  x22-x40  x23-x41  x24-x42\n    '_6_19',   # x25-x31  x26-x32  x27-x33  x28-x34  x29-x35  x30-x36\n    '_6_20',   # x25-x37  x26-x38  x27-x39  x28-x40  x29-x41  x30-x42\n    '_6_21',   # x31-x37  x32-x38  x33-x39  x34-x40  x35-x41  x36-x42\n    \n    '_5_1',    # x1-x6    x2-x7    x3-x8    x4-x9    x5-x10\n    '_5_2',    # x1-x11   x2-x12   x3-x13   x4-x14   x5-x15\n    '_5_3',    # x1-x16   x2-x17   x3-x18   x4-x19   x5-x20\n    '_5_4',    # x1-x21   x2-x22   x3-x23   x4-x24   x5-x25\n    '_5_5',    # x1-x26   x2-x27   x3-x28   x4-x29   x5-x30\n    '_5_6',    # x1-x31   x2-x32   x3-x33   x4-x34   x5-x35\n    '_5_7',    # x1-x36   x2-x37   x3-x38   x4-x39   x5-x40\n    '_5_8',    # x6-x11   x7-x12   x8-x13   x9-x14   x10-x15\n    '_5_9',    # x6-x16   x7-x17   x8-x18   x9-x19   x10-x20\n    '_5_10',   # x6-x21   x7-x22   x8-x23   x9-x24   x10-x25\n    '_5_11',   # x6-x26   x7-x27   x8-x28   x9-x29   x10-x30\n    '_5_12',   # x6-x31   x7-x32   x8-x33   x9-x34   x10-x35\n    '_5_13',   # x6-x36   x7-x37   x8-x38   x9-x39   x10-x40\n    '_5_14',   # x11-x16   x12-x17   x13-x18   x14-x19   x15-x20\n    '_5_15',   # x11-x21   x12-x22   x13-x23   x14-x24   x15-x25\n    '_5_16',   # x11-x26   x12-x27   x13-x28   x14-x29   x15-x30\n    '_5_17',   # x11-x31   x12-x32   x13-x33   x14-x34   x15-x35\n    '_5_18',   # x11-x36   x12-x37   x13-x38   x14-x39   x15-x40\n    '_5_19',   # x16-x21   x17-x22   x18-x23   x19-x24   x20-x25\n    '_5_20',   # x16-x26   x17-x27   x18-x28   x19-x29   x20-x30\n    '_5_21',   # x16-x31   x17-x32   x18-x33   x19-x34   x20-x35\n    '_5_22',   # x16-x36   x17-x37   x18-x38   x19-x39   x20-x40\n    '_5_23',   # x21-x26   x22-x27   x23-x28   x24-x29   x25-x30\n    '_5_24',   # x21-x31   x22-x32   x23-x33   x24-x34   x25-x35\n    '_5_25',   # x21-x36   x22-x37   x23-x38   x24-x39   x25-x40\n    '_5_26',   # x26-x31   x27-x32   x28-x33   x29-x34   x30-x35\n    '_5_27',   # x26-x36   x27-x37   x28-x38   x29-x39   x30-x40\n    '_5_28',   # x31-x36   x32-x37   x33-x38   x34-x39   x35-x40\n    \n    '_4_1',    # x1-x5    x2-x6    x3-x7    x4-x8    \n    '_4_2',    # x1-x9    x2-x10   x3-x11   x4-x12\n    '_4_3',    # x1-x13   x2-x14   x3-x15   x4-x16\n    '_4_4',    # x1-x17   x2-x18   x3-x19   x4-x20\n    '_4_5',    # x1-x21   x2-x22   x3-x23   x4-x24\n    '_4_6',    # x1-x25   x2-x26   x3-x27   x4-x28\n    '_4_7',    # x1-x29   x2-x30   x3-x31   x4-x32\n    '_4_8',    # x1-x33   x2-x34   x3-x35   x4-x36\n    '_4_9',    # x1-x37   x2-x38   x3-x39   x4-x40\n    '_4_10',   # x5-x9    x6-x10   x7-x11   x8-x12\n    '_4_11',   # x5-x13   x6-x14   x7-x15   x8-x16\n    '_4_12',   # x5-x17   x6-x18   x7-x19   x8-x20\n    '_4_13',   # x5-x21   x6-x22   x7-x23   x8-x24\n    '_4_14',   # x5-x25   x6-x26   x7-x27   x8-x28\n    '_4_15',   # x5-x29   x6-x30   x7-x31   x8-x32\n    '_4_16',   # x5-x33   x6-x34   x7-x35   x8-x36\n    '_4_17',   # x5-x37   x6-x38   x7-x39   x8-x40\n    '_4_18',   # x9-x13   x10-x14   x11-x15   x12-x16\n    '_4_19',   # x9-x17   x10-x18   x11-x19   x12-x20\n    '_4_20',   # x9-x21   x10-x22   x11-x23   x12-x24\n    '_4_21',   # x9-x25   x10-x26   x11-x27   x12-x28\n    '_4_22',   # x9-x29   x10-x30   x11-x31   x12-x32\n    '_4_23',   # x9-x33   x10-x34   x11-x35   x12-x36\n    '_4_24',   # x9-x37   x10-x38   x11-x39   x12-x40\n    '_4_25',   # x13-x17   x14-x18   x15-x19   x16-x20\n    '_4_26',   # x13-x21   x14-x22   x15-x23   x16-x24\n    '_4_27',   # x13-x25   x14-x26   x15-x27   x16-x28\n    '_4_28',   # x13-x29   x14-x30   x15-x31   x16-x32\n    '_4_29',   # x13-x33   x14-x34   x15-x35   x16-x36\n    '_4_30',   # x13-x37   x14-x38   x15-x39   x16-x40\n    '_4_31',   # x17-x21   x18-x22   x19-x23   x20-x24\n    '_4_32',   # x17-x25   x18-x26   x19-x27   x20-x28\n    '_4_33',   # x17-x29   x18-x30   x19-x31   x20-x32\n    '_4_34',   # x17-x33   x18-x34   x19-x35   x20-x36\n    '_4_35',   # x17-x37   x18-x38   x19-x39   x20-x40\n    '_4_36',   # x21-x25   x22-x26   x23-x27   x24-x28\n    '_4_37',   # x21-x29   x22-x30   x23-x31   x24-x32\n    '_4_38',   # x21-x33   x22-x34   x23-x35   x24-x36\n    '_4_39',   # x21-x37   x22-x38   x23-x39   x24-x40\n    '_4_40',   # x25-x29   x26-x30   x27-x31   x28-x32\n    '_4_41',   # x25-x33   x26-x34   x27-x35   x28-x36\n    '_4_42',   # x25-x37   x26-x38   x27-x39   x28-x40\n    '_4_43',   # x29-x33   x30-x34   x31-x35   x32-x36\n    '_4_44',   # x29-x37   x30-x38   x31-x39   x32-x40\n    '_4_45',   # x33-x37   x34-x38   x35-x39   x36-x40\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\nspecial_cols = ['count_per_patient']\nfeature_cols = num_cols + new_num_cols + new_num_cols2 + cat_cols + norm_cols + special_cols # ","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.160058Z","iopub.execute_input":"2024-09-09T06:41:04.160388Z","iopub.status.idle":"2024-09-09T06:41:04.183926Z","shell.execute_reply.started":"2024-09-09T06:41:04.160354Z","shell.execute_reply":"2024-09-09T06:41:04.182992Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            x1    = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            x2    = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            x3    = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            x4    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            x5    = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            x6    = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            x7    = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            x8    = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            x9    = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            x10   = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            x11   = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            xc1   = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            x12   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            x13   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            x14   = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            x15   = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            x16   = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            x17   = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            x18   = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            x19   = pl.col('x6') + pl.col('x2'),\n            x20   = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            x21   = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            x22   = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            x23   = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            x24   = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            x25   = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            x26   = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            x27   = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            x28   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            x29   = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            x30   = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            x31   = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            x32   = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            x33   = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            x34   = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            x35   = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            x36   = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            x37   = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            x38   = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            x39   = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            x40   = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            x41   = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            x42   = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            _7_1  = ((pl.col('x1')-pl.col('x8'))**2 +(pl.col('x2')-pl.col('x9'))**2 +(pl.col('x3')-pl.col('x10'))**2+(pl.col('x4')-pl.col('x11'))**2+(pl.col('x5')-pl.col('x12'))**2+(pl.col('x6')-pl.col('x13'))**2+(pl.col('x7')-pl.col('x14'))**2).sqrt(),\n            _7_2  = ((pl.col('x1')-pl.col('x15'))**2+(pl.col('x2')-pl.col('x16'))**2+(pl.col('x3')-pl.col('x17'))**2+(pl.col('x4')-pl.col('x18'))**2+(pl.col('x5')-pl.col('x19'))**2+(pl.col('x6')-pl.col('x20'))**2+(pl.col('x7')-pl.col('x21'))**2).sqrt(),\n            _7_3  = ((pl.col('x1')-pl.col('x22'))**2+(pl.col('x2')-pl.col('x23'))**2+(pl.col('x3')-pl.col('x24'))**2+(pl.col('x4')-pl.col('x25'))**2+(pl.col('x5')-pl.col('x26'))**2+(pl.col('x6')-pl.col('x27'))**2+(pl.col('x7')-pl.col('x28'))**2).sqrt(),\n            _7_4  = ((pl.col('x1')-pl.col('x29'))**2+(pl.col('x2')-pl.col('x30'))**2+(pl.col('x3')-pl.col('x31'))**2+(pl.col('x4')-pl.col('x32'))**2+(pl.col('x5')-pl.col('x33'))**2+(pl.col('x6')-pl.col('x34'))**2+(pl.col('x7')-pl.col('x35'))**2).sqrt(),\n            _7_5  = ((pl.col('x1')-pl.col('x36'))**2+(pl.col('x2')-pl.col('x37'))**2+(pl.col('x3')-pl.col('x38'))**2+(pl.col('x4')-pl.col('x39'))**2+(pl.col('x5')-pl.col('x40'))**2+(pl.col('x6')-pl.col('x41'))**2+(pl.col('x7')-pl.col('x42'))**2).sqrt(),\n            _7_6  = ((pl.col('x8')-pl.col('x15'))**2+(pl.col('x9')-pl.col('x16'))**2+(pl.col('x10')-pl.col('x17'))**2+(pl.col('x11')-pl.col('x18'))**2+(pl.col('x12')-pl.col('x19'))**2+(pl.col('x13')-pl.col('x20'))**2+(pl.col('x14')-pl.col('x21'))**2).sqrt(),\n            _7_7  = ((pl.col('x8')-pl.col('x22'))**2+(pl.col('x9')-pl.col('x23'))**2+(pl.col('x10')-pl.col('x24'))**2+(pl.col('x11')-pl.col('x25'))**2+(pl.col('x12')-pl.col('x26'))**2+(pl.col('x13')-pl.col('x27'))**2+(pl.col('x14')-pl.col('x28'))**2).sqrt(),\n            _7_8  = ((pl.col('x8')-pl.col('x29'))**2+(pl.col('x9')-pl.col('x30'))**2+(pl.col('x10')-pl.col('x31'))**2+(pl.col('x11')-pl.col('x32'))**2+(pl.col('x12')-pl.col('x33'))**2+(pl.col('x13')-pl.col('x34'))**2+(pl.col('x14')-pl.col('x35'))**2).sqrt(),\n            _7_9  = ((pl.col('x8')-pl.col('x36'))**2+(pl.col('x9')-pl.col('x37'))**2+(pl.col('x10')-pl.col('x38'))**2+(pl.col('x11')-pl.col('x39'))**2+(pl.col('x12')-pl.col('x40'))**2+(pl.col('x13')-pl.col('x41'))**2+(pl.col('x14')-pl.col('x42'))**2).sqrt(),\n            _7_10 = ((pl.col('x15')-pl.col('x22'))**2+(pl.col('x16')-pl.col('x23'))**2+(pl.col('x17')-pl.col('x24'))**2+(pl.col('x18')-pl.col('x25'))**2+(pl.col('x19')-pl.col('x26'))**2+(pl.col('x20')-pl.col('x27'))**2+(pl.col('x21')-pl.col('x28'))**2).sqrt(),\n            _7_11 = ((pl.col('x15')-pl.col('x29'))**2+(pl.col('x16')-pl.col('x30'))**2+(pl.col('x17')-pl.col('x31'))**2+(pl.col('x18')-pl.col('x32'))**2+(pl.col('x19')-pl.col('x33'))**2+(pl.col('x20')-pl.col('x34'))**2+(pl.col('x21')-pl.col('x35'))**2).sqrt(),\n            _7_12 = ((pl.col('x15')-pl.col('x36'))**2+(pl.col('x16')-pl.col('x37'))**2+(pl.col('x17')-pl.col('x38'))**2+(pl.col('x18')-pl.col('x39'))**2+(pl.col('x19')-pl.col('x40'))**2+(pl.col('x20')-pl.col('x41'))**2+(pl.col('x21')-pl.col('x42'))**2).sqrt(),\n            _7_13 = ((pl.col('x22')-pl.col('x29'))**2+(pl.col('x23')-pl.col('x30'))**2+(pl.col('x24')-pl.col('x31'))**2+(pl.col('x25')-pl.col('x32'))**2+(pl.col('x26')-pl.col('x33'))**2+(pl.col('x27')-pl.col('x34'))**2+(pl.col('x28')-pl.col('x35'))**2).sqrt(),\n            _7_14 = ((pl.col('x22')-pl.col('x36'))**2+(pl.col('x23')-pl.col('x37'))**2+(pl.col('x24')-pl.col('x38'))**2+(pl.col('x25')-pl.col('x39'))**2+(pl.col('x26')-pl.col('x40'))**2+(pl.col('x27')-pl.col('x41'))**2+(pl.col('x28')-pl.col('x42'))**2).sqrt(),\n            _7_15 = ((pl.col('x29')-pl.col('x36'))**2+(pl.col('x30')-pl.col('x37'))**2+(pl.col('x31')-pl.col('x38'))**2+(pl.col('x32')-pl.col('x39'))**2+(pl.col('x33')-pl.col('x40'))**2+(pl.col('x34')-pl.col('x41'))**2+(pl.col('x35')-pl.col('x42'))**2).sqrt(),\n        )\n                           #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n        .with_columns(\n            _6_1  = ((pl.col('x1')-pl.col('x7'))**2+(pl.col('x2')-pl.col('x8'))**2+(pl.col('x3')-pl.col('x9'))**2+(pl.col('x4')-pl.col('x10'))**2+(pl.col('x5')-pl.col('x11'))**2+(pl.col('x6')-pl.col('x12'))**2).sqrt(),\n            _6_2  = ((pl.col('x1')-pl.col('x13'))**2+(pl.col('x2')-pl.col('x14'))**2+(pl.col('x3')-pl.col('x15'))**2+(pl.col('x4')-pl.col('x16'))**2+(pl.col('x5')-pl.col('x17'))**2+(pl.col('x6')-pl.col('x18'))**2).sqrt(),\n            _6_3  = ((pl.col('x1')-pl.col('x19'))**2+(pl.col('x2')-pl.col('x20'))**2+(pl.col('x3')-pl.col('x21'))**2+(pl.col('x4')-pl.col('x22'))**2+(pl.col('x5')-pl.col('x23'))**2+(pl.col('x6')-pl.col('x24'))**2).sqrt(),\n            _6_4  = ((pl.col('x1')-pl.col('x25'))**2+(pl.col('x2')-pl.col('x26'))**2+(pl.col('x3')-pl.col('x27'))**2+(pl.col('x4')-pl.col('x28'))**2+(pl.col('x5')-pl.col('x29'))**2+(pl.col('x6')-pl.col('x30'))**2).sqrt(),\n            _6_5  = ((pl.col('x1')-pl.col('x31'))**2+(pl.col('x2')-pl.col('x32'))**2+(pl.col('x3')-pl.col('x33'))**2+(pl.col('x4')-pl.col('x34'))**2+(pl.col('x5')-pl.col('x35'))**2+(pl.col('x6')-pl.col('x36'))**2).sqrt(),\n            _6_6  = ((pl.col('x1')-pl.col('x37'))**2+(pl.col('x2')-pl.col('x38'))**2+(pl.col('x3')-pl.col('x39'))**2+(pl.col('x4')-pl.col('x40'))**2+(pl.col('x5')-pl.col('x41'))**2+(pl.col('x6')-pl.col('x42'))**2).sqrt(),\n            _6_7  = ((pl.col('x7')-pl.col('x13'))**2+(pl.col('x8')-pl.col('x14'))**2+(pl.col('x9')-pl.col('x15'))**2+(pl.col('x10')-pl.col('x16'))**2+(pl.col('x11')-pl.col('x17'))**2+(pl.col('x12')-pl.col('x23'))**2).sqrt(),\n            _6_8  = ((pl.col('x7')-pl.col('x19'))**2+(pl.col('x8')-pl.col('x20'))**2+(pl.col('x9')-pl.col('x21'))**2+(pl.col('x10')-pl.col('x22'))**2+(pl.col('x11')-pl.col('x23'))**2+(pl.col('x12')-pl.col('x24'))**2).sqrt(),\n            _6_9  = ((pl.col('x7')-pl.col('x25'))**2+(pl.col('x8')-pl.col('x26'))**2+(pl.col('x9')-pl.col('x27'))**2+(pl.col('x10')-pl.col('x28'))**2+(pl.col('x11')-pl.col('x29'))**2+(pl.col('x12')-pl.col('x30'))**2).sqrt(),\n            _6_10 = ((pl.col('x7')-pl.col('x31'))**2+(pl.col('x8')-pl.col('x32'))**2+(pl.col('x9')-pl.col('x33'))**2+(pl.col('x10')-pl.col('x34'))**2+(pl.col('x11')-pl.col('x35'))**2+(pl.col('x12')-pl.col('x36'))**2).sqrt(),\n            _6_11 = ((pl.col('x7')-pl.col('x37'))**2+(pl.col('x8')-pl.col('x38'))**2+(pl.col('x9')-pl.col('x39'))**2+(pl.col('x10')-pl.col('x40'))**2+(pl.col('x11')-pl.col('x41'))**2+(pl.col('x12')-pl.col('x42'))**2).sqrt(),\n            _6_12 = ((pl.col('x13')-pl.col('x19'))**2+(pl.col('x14')-pl.col('x20'))**2+(pl.col('x15')-pl.col('x21'))**2+(pl.col('x16')-pl.col('x22'))**2+(pl.col('x17')-pl.col('x23'))**2+(pl.col('x18')-pl.col('x24'))**2).sqrt(),\n            _6_13 = ((pl.col('x13')-pl.col('x25'))**2+(pl.col('x14')-pl.col('x26'))**2+(pl.col('x15')-pl.col('x27'))**2+(pl.col('x16')-pl.col('x28'))**2+(pl.col('x17')-pl.col('x29'))**2+(pl.col('x18')-pl.col('x30'))**2).sqrt(),\n            _6_14 = ((pl.col('x13')-pl.col('x31'))**2+(pl.col('x14')-pl.col('x32'))**2+(pl.col('x15')-pl.col('x33'))**2+(pl.col('x16')-pl.col('x34'))**2+(pl.col('x17')-pl.col('x35'))**2+(pl.col('x18')-pl.col('x36'))**2).sqrt(),\n            _6_15 = ((pl.col('x13')-pl.col('x37'))**2+(pl.col('x14')-pl.col('x38'))**2+(pl.col('x15')-pl.col('x39'))**2+(pl.col('x16')-pl.col('x40'))**2+(pl.col('x17')-pl.col('x41'))**2+(pl.col('x18')-pl.col('x42'))**2).sqrt(),\n            _6_16 = ((pl.col('x19')-pl.col('x25'))**2+(pl.col('x20')-pl.col('x26'))**2+(pl.col('x21')-pl.col('x27'))**2+(pl.col('x22')-pl.col('x28'))**2+(pl.col('x23')-pl.col('x29'))**2+(pl.col('x24')-pl.col('x30'))**2).sqrt(),\n            _6_17 = ((pl.col('x19')-pl.col('x31'))**2+(pl.col('x20')-pl.col('x32'))**2+(pl.col('x21')-pl.col('x33'))**2+(pl.col('x22')-pl.col('x34'))**2+(pl.col('x23')-pl.col('x35'))**2+(pl.col('x24')-pl.col('x36'))**2).sqrt(),\n            _6_18 = ((pl.col('x19')-pl.col('x37'))**2+(pl.col('x20')-pl.col('x38'))**2+(pl.col('x21')-pl.col('x39'))**2+(pl.col('x22')-pl.col('x40'))**2+(pl.col('x23')-pl.col('x41'))**2+(pl.col('x24')-pl.col('x42'))**2).sqrt(),\n            _6_19 = ((pl.col('x25')-pl.col('x31'))**2+(pl.col('x26')-pl.col('x32'))**2+(pl.col('x27')-pl.col('x33'))**2+(pl.col('x28')-pl.col('x34'))**2+(pl.col('x29')-pl.col('x35'))**2+(pl.col('x30')-pl.col('x36'))**2).sqrt(),\n            _6_20 = ((pl.col('x25')-pl.col('x37'))**2+(pl.col('x26')-pl.col('x38'))**2+(pl.col('x27')-pl.col('x39'))**2+(pl.col('x28')-pl.col('x40'))**2+(pl.col('x29')-pl.col('x41'))**2+(pl.col('x30')-pl.col('x42'))**2).sqrt(),\n            _6_21 = ((pl.col('x31')-pl.col('x37'))**2+(pl.col('x32')-pl.col('x38'))**2+(pl.col('x33')-pl.col('x39'))**2+(pl.col('x34')-pl.col('x40'))**2+(pl.col('x35')-pl.col('x41'))**2+(pl.col('x36')-pl.col('x42'))**2).sqrt(),\n        )                    \n# #                            #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n        .with_columns(  \n            _5_1  = ((pl.col('x1')-pl.col('x6'))**2 +(pl.col('x2')-pl.col('x7'))**2 +(pl.col('x3')-pl.col('x8'))**2 +(pl.col('x4')-pl.col('x9'))**2 +(pl.col('x5')-pl.col('x10'))**2).sqrt(),\n            _5_2  = ((pl.col('x1')-pl.col('x11'))**2+(pl.col('x2')-pl.col('x12'))**2+(pl.col('x3')-pl.col('x13'))**2+(pl.col('x4')-pl.col('x14'))**2+(pl.col('x5')-pl.col('x15'))**2).sqrt(),\n            _5_3  = ((pl.col('x1')-pl.col('x16'))**2+(pl.col('x2')-pl.col('x17'))**2+(pl.col('x3')-pl.col('x18'))**2+(pl.col('x4')-pl.col('x19'))**2+(pl.col('x5')-pl.col('x20'))**2).sqrt(),\n            _5_4  = ((pl.col('x1')-pl.col('x21'))**2+(pl.col('x2')-pl.col('x22'))**2+(pl.col('x3')-pl.col('x23'))**2+(pl.col('x4')-pl.col('x24'))**2+(pl.col('x5')-pl.col('x25'))**2).sqrt(),\n            _5_5  = ((pl.col('x1')-pl.col('x26'))**2+(pl.col('x2')-pl.col('x27'))**2+(pl.col('x3')-pl.col('x28'))**2+(pl.col('x4')-pl.col('x29'))**2+(pl.col('x5')-pl.col('x30'))**2).sqrt(),\n            _5_6  = ((pl.col('x1')-pl.col('x31'))**2+(pl.col('x2')-pl.col('x32'))**2+(pl.col('x3')-pl.col('x33'))**2+(pl.col('x4')-pl.col('x34'))**2+(pl.col('x5')-pl.col('x35'))**2).sqrt(),\n            _5_7  = ((pl.col('x1')-pl.col('x36'))**2+(pl.col('x2')-pl.col('x37'))**2+(pl.col('x3')-pl.col('x38'))**2+(pl.col('x4')-pl.col('x39'))**2+(pl.col('x5')-pl.col('x40'))**2).sqrt(),\n            _5_8  = ((pl.col('x6')-pl.col('x11'))**2+(pl.col('x7')-pl.col('x12'))**2+(pl.col('x8')-pl.col('x13'))**2+(pl.col('x9')-pl.col('x14'))**2+(pl.col('x10')-pl.col('x15'))**2).sqrt(),\n            _5_9  = ((pl.col('x6')-pl.col('x16'))**2+(pl.col('x7')-pl.col('x17'))**2+(pl.col('x8')-pl.col('x18'))**2+(pl.col('x9')-pl.col('x19'))**2+(pl.col('x10')-pl.col('x20'))**2).sqrt(),\n            _5_10 = ((pl.col('x6')-pl.col('x21'))**2+(pl.col('x7')-pl.col('x22'))**2+(pl.col('x8')-pl.col('x23'))**2+(pl.col('x9')-pl.col('x24'))**2+(pl.col('x10')-pl.col('x25'))**2).sqrt(),\n            _5_11 = ((pl.col('x6')-pl.col('x26'))**2+(pl.col('x7')-pl.col('x27'))**2+(pl.col('x8')-pl.col('x28'))**2+(pl.col('x9')-pl.col('x29'))**2+(pl.col('x10')-pl.col('x30'))**2).sqrt(),\n            _5_12 = ((pl.col('x6')-pl.col('x31'))**2+(pl.col('x7')-pl.col('x32'))**2+(pl.col('x8')-pl.col('x33'))**2+(pl.col('x9')-pl.col('x34'))**2+(pl.col('x10')-pl.col('x35'))**2).sqrt(),\n            _5_13 = ((pl.col('x6')-pl.col('x36'))**2+(pl.col('x7')-pl.col('x37'))**2+(pl.col('x8')-pl.col('x38'))**2+(pl.col('x9')-pl.col('x39'))**2+(pl.col('x10')-pl.col('x40'))**2).sqrt(),\n            _5_14 = ((pl.col('x11')-pl.col('x16'))**2+(pl.col('x12')-pl.col('x17'))**2+(pl.col('x13')-pl.col('x18'))**2+(pl.col('x14')-pl.col('x19'))**2+(pl.col('x15')-pl.col('x20'))**2).sqrt(),\n            _5_15 = ((pl.col('x11')-pl.col('x21'))**2+(pl.col('x12')-pl.col('x22'))**2+(pl.col('x13')-pl.col('x23'))**2+(pl.col('x14')-pl.col('x24'))**2+(pl.col('x15')-pl.col('x25'))**2).sqrt(),\n            _5_16 = ((pl.col('x11')-pl.col('x26'))**2+(pl.col('x12')-pl.col('x27'))**2+(pl.col('x13')-pl.col('x28'))**2+(pl.col('x14')-pl.col('x29'))**2+(pl.col('x15')-pl.col('x30'))**2).sqrt(),\n            _5_17 = ((pl.col('x11')-pl.col('x31'))**2+(pl.col('x12')-pl.col('x32'))**2+(pl.col('x13')-pl.col('x33'))**2+(pl.col('x14')-pl.col('x34'))**2+(pl.col('x15')-pl.col('x35'))**2).sqrt(),\n            _5_18 = ((pl.col('x11')-pl.col('x36'))**2+(pl.col('x12')-pl.col('x37'))**2+(pl.col('x13')-pl.col('x38'))**2+(pl.col('x14')-pl.col('x39'))**2+(pl.col('x15')-pl.col('x40'))**2).sqrt(),\n            _5_19 = ((pl.col('x16')-pl.col('x21'))**2+(pl.col('x17')-pl.col('x22'))**2+(pl.col('x18')-pl.col('x23'))**2+(pl.col('x19')-pl.col('x24'))**2+(pl.col('x20')-pl.col('x25'))**2).sqrt(),\n            _5_20 = ((pl.col('x16')-pl.col('x26'))**2+(pl.col('x17')-pl.col('x27'))**2+(pl.col('x18')-pl.col('x28'))**2+(pl.col('x19')-pl.col('x29'))**2+(pl.col('x20')-pl.col('x30'))**2).sqrt(),\n            _5_21 = ((pl.col('x16')-pl.col('x31'))**2+(pl.col('x17')-pl.col('x32'))**2+(pl.col('x18')-pl.col('x33'))**2+(pl.col('x19')-pl.col('x34'))**2+(pl.col('x20')-pl.col('x35'))**2).sqrt(),\n            _5_22 = ((pl.col('x16')-pl.col('x36'))**2+(pl.col('x17')-pl.col('x37'))**2+(pl.col('x18')-pl.col('x38'))**2+(pl.col('x19')-pl.col('x39'))**2+(pl.col('x20')-pl.col('x40'))**2).sqrt(),\n            _5_23 = ((pl.col('x21')-pl.col('x26'))**2+(pl.col('x22')-pl.col('x27'))**2+(pl.col('x23')-pl.col('x28'))**2+(pl.col('x24')-pl.col('x29'))**2+(pl.col('x25')-pl.col('x30'))**2).sqrt(),\n            _5_24 = ((pl.col('x21')-pl.col('x31'))**2+(pl.col('x22')-pl.col('x32'))**2+(pl.col('x23')-pl.col('x33'))**2+(pl.col('x24')-pl.col('x34'))**2+(pl.col('x25')-pl.col('x35'))**2).sqrt(),\n            _5_25 = ((pl.col('x21')-pl.col('x36'))**2+(pl.col('x22')-pl.col('x37'))**2+(pl.col('x23')-pl.col('x38'))**2+(pl.col('x24')-pl.col('x39'))**2+(pl.col('x25')-pl.col('x40'))**2).sqrt(),\n            _5_26 = ((pl.col('x26')-pl.col('x31'))**2+(pl.col('x27')-pl.col('x32'))**2+(pl.col('x28')-pl.col('x33'))**2+(pl.col('x29')-pl.col('x34'))**2+(pl.col('x30')-pl.col('x35'))**2).sqrt(),\n            _5_27 = ((pl.col('x26')-pl.col('x36'))**2+(pl.col('x27')-pl.col('x37'))**2+(pl.col('x28')-pl.col('x38'))**2+(pl.col('x29')-pl.col('x39'))**2+(pl.col('x30')-pl.col('x40'))**2).sqrt(),\n            _5_28 = ((pl.col('x31')-pl.col('x36'))**2+(pl.col('x32')-pl.col('x37'))**2+(pl.col('x33')-pl.col('x38'))**2+(pl.col('x34')-pl.col('x39'))**2+(pl.col('x35')-pl.col('x40'))**2).sqrt(),\n        )\n        .with_columns(        #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n            _4_1 = ((pl.col('x1')-pl.col('x5'))**2+(pl.col('x2')-pl.col('x6'))**2+(pl.col('x3')-pl.col('x7'))**2+(pl.col('x4')-pl.col('x8'))**2).sqrt(),    \n            _4_2 = ((pl.col('x1')-pl.col('x9'))**2+(pl.col('x2')-pl.col('x10'))**2+(pl.col('x3')-pl.col('x11'))**2+(pl.col('x4')-pl.col('x12'))**2).sqrt(),\n            _4_3 = ((pl.col('x1')-pl.col('x13'))**2+(pl.col('x2')-pl.col('x14'))**2+(pl.col('x3')-pl.col('x15'))**2+(pl.col('x4')-pl.col('x16'))**2).sqrt(),\n            _4_4 = ((pl.col('x1')-pl.col('x17'))**2+(pl.col('x2')-pl.col('x18'))**2+(pl.col('x3')-pl.col('x19'))**2+(pl.col('x4')-pl.col('x20'))**2).sqrt(),\n            _4_5 = ((pl.col('x1')-pl.col('x21'))**2+(pl.col('x2')-pl.col('x22'))**2+(pl.col('x3')-pl.col('x23'))**2+(pl.col('x4')-pl.col('x24'))**2).sqrt(),\n            _4_6 = ((pl.col('x1')-pl.col('x25'))**2+(pl.col('x2')-pl.col('x26'))**2+(pl.col('x3')-pl.col('x27'))**2+(pl.col('x4')-pl.col('x28'))**2).sqrt(),\n            _4_7 = ((pl.col('x1')-pl.col('x29'))**2+(pl.col('x2')-pl.col('x30'))**2+(pl.col('x3')-pl.col('x31'))**2+(pl.col('x4')-pl.col('x32'))**2).sqrt(),\n            _4_8 = ((pl.col('x1')-pl.col('x33'))**2+(pl.col('x2')-pl.col('x34'))**2+(pl.col('x3')-pl.col('x35'))**2+(pl.col('x4')-pl.col('x36'))**2).sqrt(),\n            _4_9 = ((pl.col('x1')-pl.col('x37'))**2+(pl.col('x2')-pl.col('x38'))**2+(pl.col('x3')-pl.col('x39'))**2+(pl.col('x4')-pl.col('x40'))**2).sqrt(),\n            _4_10 = ((pl.col('x5')-pl.col('x9'))**2+(pl.col('x6')-pl.col('x10'))**2+(pl.col('x7')-pl.col('x11'))**2+(pl.col('x8')-pl.col('x12'))**2).sqrt(),\n            _4_11 = ((pl.col('x5')-pl.col('x13'))**2+(pl.col('x6')-pl.col('x14'))**2+(pl.col('x7')-pl.col('x15'))**2+(pl.col('x8')-pl.col('x16'))**2).sqrt(),\n            _4_12 = ((pl.col('x5')-pl.col('x17'))**2+(pl.col('x6')-pl.col('x18'))**2+(pl.col('x7')-pl.col('x19'))**2+(pl.col('x8')-pl.col('x20'))**2).sqrt(),\n            _4_13 = ((pl.col('x5')-pl.col('x21'))**2+(pl.col('x6')-pl.col('x22'))**2+(pl.col('x7')-pl.col('x23'))**2+(pl.col('x8')-pl.col('x24'))**2).sqrt(),\n            _4_14 = ((pl.col('x5')-pl.col('x25'))**2+(pl.col('x6')-pl.col('x26'))**2+(pl.col('x7')-pl.col('x27'))**2+(pl.col('x8')-pl.col('x28'))**2).sqrt(),\n            _4_15 = ((pl.col('x5')-pl.col('x29'))**2+(pl.col('x6')-pl.col('x30'))**2+(pl.col('x7')-pl.col('x31'))**2+(pl.col('x8')-pl.col('x32'))**2).sqrt(),\n            _4_16 = ((pl.col('x5')-pl.col('x33'))**2+(pl.col('x6')-pl.col('x34'))**2+(pl.col('x7')-pl.col('x35'))**2+(pl.col('x8')-pl.col('x36'))**2).sqrt(),\n            _4_17 = ((pl.col('x5')-pl.col('x37'))**2+(pl.col('x6')-pl.col('x38'))**2+(pl.col('x7')-pl.col('x39'))**2+(pl.col('x8')-pl.col('x40'))**2).sqrt(),\n            _4_18 = ((pl.col('x9')-pl.col('x13'))**2+(pl.col('x10')-pl.col('x14'))**2+(pl.col('x11')-pl.col('x15'))**2+(pl.col('x12')-pl.col('x16'))**2).sqrt(),\n            _4_19 = ((pl.col('x9')-pl.col('x17'))**2+(pl.col('x10')-pl.col('x18'))**2+(pl.col('x11')-pl.col('x19'))**2+(pl.col('x12')-pl.col('x20'))**2).sqrt(),\n            _4_20 = ((pl.col('x9')-pl.col('x21'))**2+(pl.col('x10')-pl.col('x22'))**2+(pl.col('x11')-pl.col('x23'))**2+(pl.col('x12')-pl.col('x24'))**2).sqrt(),\n            _4_21 = ((pl.col('x9')-pl.col('x25'))**2+(pl.col('x10')-pl.col('x26'))**2+(pl.col('x11')-pl.col('x27'))**2+(pl.col('x12')-pl.col('x28'))**2).sqrt(),\n            _4_22 = ((pl.col('x9')-pl.col('x29'))**2+(pl.col('x10')-pl.col('x30'))**2+(pl.col('x11')-pl.col('x31'))**2+(pl.col('x12')-pl.col('x32'))**2).sqrt(),\n            _4_23 = ((pl.col('x9')-pl.col('x33'))**2+(pl.col('x10')-pl.col('x34'))**2+(pl.col('x11')-pl.col('x35'))**2+(pl.col('x12')-pl.col('x36'))**2).sqrt(),\n            _4_24 = ((pl.col('x9')-pl.col('x37'))**2+(pl.col('x10')-pl.col('x38'))**2+(pl.col('x11')-pl.col('x39'))**2+(pl.col('x12')-pl.col('x40'))**2).sqrt(),\n            _4_25 = ((pl.col('x13')-pl.col('x17'))**2+(pl.col('x14')-pl.col('x18'))**2+(pl.col('x15')-pl.col('x19'))**2+(pl.col('x16')-pl.col('x20'))**2).sqrt(),\n            _4_26 = ((pl.col('x13')-pl.col('x21'))**2+(pl.col('x14')-pl.col('x22'))**2+(pl.col('x15')-pl.col('x23'))**2+(pl.col('x16')-pl.col('x24'))**2).sqrt(),\n            _4_27 = ((pl.col('x13')-pl.col('x25'))**2+(pl.col('x14')-pl.col('x26'))**2+(pl.col('x15')-pl.col('x27'))**2+(pl.col('x16')-pl.col('x28'))**2).sqrt(),\n            _4_28 = ((pl.col('x13')-pl.col('x29'))**2+(pl.col('x14')-pl.col('x30'))**2+(pl.col('x15')-pl.col('x31'))**2+(pl.col('x16')-pl.col('x32'))**2).sqrt(),\n            _4_29 = ((pl.col('x13')-pl.col('x33'))**2+(pl.col('x14')-pl.col('x34'))**2+(pl.col('x15')-pl.col('x35'))**2+(pl.col('x16')-pl.col('x36'))**2).sqrt(),\n            _4_30 = ((pl.col('x13')-pl.col('x37'))**2+(pl.col('x14')-pl.col('x38'))**2+(pl.col('x15')-pl.col('x39'))**2+(pl.col('x16')-pl.col('x40'))**2).sqrt(),\n            _4_31 = ((pl.col('x17')-pl.col('x21'))**2+(pl.col('x18')-pl.col('x22'))**2+(pl.col('x19')-pl.col('x23'))**2+(pl.col('x20')-pl.col('x24'))**2).sqrt(),\n            _4_32 = ((pl.col('x17')-pl.col('x25'))**2+(pl.col('x18')-pl.col('x26'))**2+(pl.col('x19')-pl.col('x27'))**2+(pl.col('x20')-pl.col('x28'))**2).sqrt(),\n            _4_33 = ((pl.col('x17')-pl.col('x29'))**2+(pl.col('x18')-pl.col('x30'))**2+(pl.col('x19')-pl.col('x31'))**2+(pl.col('x20')-pl.col('x32'))**2).sqrt(),\n            _4_34 = ((pl.col('x17')-pl.col('x33'))**2+(pl.col('x18')-pl.col('x34'))**2+(pl.col('x19')-pl.col('x35'))**2+(pl.col('x20')-pl.col('x36'))**2).sqrt(),\n            _4_35 = ((pl.col('x17')-pl.col('x37'))**2+(pl.col('x18')-pl.col('x38'))**2+(pl.col('x19')-pl.col('x39'))**2+(pl.col('x20')-pl.col('x40'))**2).sqrt(),\n            _4_36 = ((pl.col('x21')-pl.col('x25'))**2+(pl.col('x22')-pl.col('x26'))**2+(pl.col('x23')-pl.col('x27'))**2+(pl.col('x24')-pl.col('x28'))**2).sqrt(),\n            _4_37 = ((pl.col('x21')-pl.col('x29'))**2+(pl.col('x22')-pl.col('x30'))**2+(pl.col('x23')-pl.col('x31'))**2+(pl.col('x24')-pl.col('x32'))**2).sqrt(),\n            _4_38 = ((pl.col('x21')-pl.col('x33'))**2+(pl.col('x22')-pl.col('x34'))**2+(pl.col('x23')-pl.col('x35'))**2+(pl.col('x24')-pl.col('x36'))**2).sqrt(),\n            _4_39 = ((pl.col('x21')-pl.col('x37'))**2+(pl.col('x22')-pl.col('x38'))**2+(pl.col('x23')-pl.col('x39'))**2+(pl.col('x24')-pl.col('x40'))**2).sqrt(),\n            _4_40 = ((pl.col('x25')-pl.col('x29'))**2+(pl.col('x26')-pl.col('x30'))**2+(pl.col('x27')-pl.col('x31'))**2+(pl.col('x28')-pl.col('x32'))**2).sqrt(),\n            _4_41 = ((pl.col('x25')-pl.col('x33'))**2+(pl.col('x26')-pl.col('x34'))**2+(pl.col('x27')-pl.col('x35'))**2+(pl.col('x28')-pl.col('x36'))**2).sqrt(),\n            _4_42 = ((pl.col('x25')-pl.col('x37'))**2+(pl.col('x26')-pl.col('x38'))**2+(pl.col('x27')-pl.col('x39'))**2+(pl.col('x28')-pl.col('x40'))**2).sqrt(),\n            _4_43 = ((pl.col('x29')-pl.col('x33'))**2+(pl.col('x30')-pl.col('x34'))**2+(pl.col('x31')-pl.col('x35'))**2+(pl.col('x32')-pl.col('x36'))**2).sqrt(),\n            _4_44 = ((pl.col('x29')-pl.col('x37'))**2+(pl.col('x30')-pl.col('x38'))**2+(pl.col('x31')-pl.col('x39'))**2+(pl.col('x32')-pl.col('x40'))**2).sqrt(),\n            _4_45 = ((pl.col('x33')-pl.col('x37'))**2+(pl.col('x34')-pl.col('x38'))**2+(pl.col('x35')-pl.col('x39'))**2+(pl.col('x36')-pl.col('x40'))**2).sqrt(),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.281450Z","iopub.execute_input":"2024-09-09T06:41:04.282194Z","iopub.status.idle":"2024-09-09T06:41:04.479798Z","shell.execute_reply.started":"2024-09-09T06:41:04.282158Z","shell.execute_reply":"2024-09-09T06:41:04.478785Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.481988Z","iopub.execute_input":"2024-09-09T06:41:04.482476Z","iopub.status.idle":"2024-09-09T06:41:04.493138Z","shell.execute_reply.started":"2024-09-09T06:41:04.482426Z","shell.execute_reply":"2024-09-09T06:41:04.492308Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.494361Z","iopub.execute_input":"2024-09-09T06:41:04.494710Z","iopub.status.idle":"2024-09-09T06:41:04.502912Z","shell.execute_reply.started":"2024-09-09T06:41:04.494676Z","shell.execute_reply":"2024-09-09T06:41:04.502043Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_test = preprocess(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:04.504129Z","iopub.execute_input":"2024-09-09T06:41:04.504692Z","iopub.status.idle":"2024-09-09T06:41:10.418217Z","shell.execute_reply.started":"2024-09-09T06:41:04.504657Z","shell.execute_reply":"2024-09-09T06:41:10.417434Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#they are detected at the first run\nleast_important_features = ['onehot_32', 'onehot_6', 'onehot_33', 'onehot_30', 'onehot_26', 'onehot_22', 'onehot_36', 'onehot_4']\n#they are detected after the least_important_features are removed and it has increased cv score also so I add it\n#least_important_features_2 = ['onehot_17', 'onehot_42', 'onehot_29', 'onehot_13', 'onehot_25']\n#least_important_features += least_important_features_2\ndf_train.drop(columns =least_important_features,inplace = True)\nfor feature in least_important_features:\n    cat_cols.remove(feature)\n    feature_cols.remove(feature)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.421566Z","iopub.execute_input":"2024-09-09T06:41:10.422326Z","iopub.status.idle":"2024-09-09T06:41:10.701828Z","shell.execute_reply.started":"2024-09-09T06:41:10.422281Z","shell.execute_reply":"2024-09-09T06:41:10.700974Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           250,\n    'boosting_type':    'gbdt',\n    'random_state':     seed,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\nlgb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.702850Z","iopub.execute_input":"2024-09-09T06:41:10.703156Z","iopub.status.idle":"2024-09-09T06:41:10.710668Z","shell.execute_reply.started":"2024-09-09T06:41:10.703123Z","shell.execute_reply":"2024-09-09T06:41:10.709714Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"cb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        250,\n    'verbose':           False,\n    'random_state':      seed,\n    'max_depth':         7, \n    'learning_rate':     0.07, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24,\n    'cat_features':      cat_cols,\n}\n\ncb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', cb.CatBoostClassifier(**cb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.711781Z","iopub.execute_input":"2024-09-09T06:41:10.712127Z","iopub.status.idle":"2024-09-09T06:41:10.723661Z","shell.execute_reply.started":"2024-09-09T06:41:10.712090Z","shell.execute_reply":"2024-09-09T06:41:10.722791Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'enable_categorical': True,\n    'tree_method':        'hist',\n    'random_state':       seed,\n    'learning_rate':      0.08501257473292347, \n    'lambda':             8.879624125465703, \n    'alpha':              0.6779926606782505, \n    'max_depth':          6, \n    'subsample':          0.6012681388711075, \n    'colsample_bytree':   0.8437772277074493, \n    'colsample_bylevel':  0.5476090898823716, \n    'colsample_bynode':   0.9928601203635129, \n    'scale_pos_weight':   3.29440313334688,\n}\n\nxgb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', xgb.XGBClassifier(**xgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.724756Z","iopub.execute_input":"2024-09-09T06:41:10.725062Z","iopub.status.idle":"2024-09-09T06:41:10.737884Z","shell.execute_reply.started":"2024-09-09T06:41:10.725030Z","shell.execute_reply":"2024-09-09T06:41:10.737027Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"estimator = VotingClassifier([\n    ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n], voting='soft', weights=[0.50,0.40,0.15])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.738954Z","iopub.execute_input":"2024-09-09T06:41:10.739285Z","iopub.status.idle":"2024-09-09T06:41:10.748272Z","shell.execute_reply.started":"2024-09-09T06:41:10.739241Z","shell.execute_reply":"2024-09-09T06:41:10.747279Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X = df_train[feature_cols]\ny = df_train[target_col]\ngroups = df_train[group_col]\ncv = StratifiedGroupKFold(10, shuffle=True, random_state=seed)\n\nval_score = cross_val_score(\n    estimator=estimator, \n    X=X, y=y, \n    cv=cv, \n    groups=groups,\n    scoring=custom_metric,\n)\n\nnp.mean(val_score), val_score","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:41:10.749540Z","iopub.execute_input":"2024-09-09T06:41:10.749835Z","iopub.status.idle":"2024-09-09T06:54:25.975792Z","shell.execute_reply.started":"2024-09-09T06:41:10.749804Z","shell.execute_reply":"2024-09-09T06:54:25.974748Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(0.17387781750847747,\n array([0.19214979, 0.16587744, 0.1762829 , 0.18035588, 0.15940063,\n        0.18170355, 0.15782247, 0.17152731, 0.18165788, 0.17200033]))"},"metadata":{}}]},{"cell_type":"code","source":"X, y = df_train[feature_cols], df_train[target_col]\n\nimport pandas as pd\n\n# Sınıf dağılımını saymak\nclass_distribution = X.value_counts()\n\nprint(\"Class Distribution:\")\nprint(class_distribution)\n\nestimator.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:54:25.977034Z","iopub.execute_input":"2024-09-09T06:54:25.977390Z","iopub.status.idle":"2024-09-09T06:56:16.232200Z","shell.execute_reply.started":"2024-09-09T06:54:25.977352Z","shell.execute_reply":"2024-09-09T06:56:16.231121Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Class Distribution:\nage_approx  clin_size_long_diam_mm  tbp_lv_A   tbp_lv_Aext  tbp_lv_B   tbp_lv_Bext  tbp_lv_C   tbp_lv_Cext  tbp_lv_H   tbp_lv_Hext  tbp_lv_L   tbp_lv_Lext  tbp_lv_areaMM2  tbp_lv_area_perim_ratio  tbp_lv_color_std_mean  tbp_lv_deltaA  tbp_lv_deltaB  tbp_lv_deltaL  tbp_lv_deltaLB  tbp_lv_deltaLBnorm  tbp_lv_eccentricity  tbp_lv_minorAxisMM  tbp_lv_nevi_confidence  tbp_lv_norm_border  tbp_lv_norm_color  tbp_lv_perimeterMM  tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle  tbp_lv_x     tbp_lv_y     tbp_lv_z     x1        x2        x3         x4         x5         x6        x7        x8           x9        x10       x11        x12       x13       x14       x15       x16      x17         x18       x19       x20       x21       x22       x23        x24       x25        x26       x27        x28        x29        x30       x31        x32       x33       x34       x35        x36       x37            x38        x39       x40       x41         x42          _7_1         _7_2         _7_3       _7_4       _7_5           _7_6         _7_7         _7_8         _7_9           _7_10        _7_11        _7_12          _7_13      _7_14          _7_15          _6_1         _6_2         _6_3       _6_4       _6_5       _6_6           _6_7         _6_8         _6_9         _6_10        _6_11          _6_12        _6_13        _6_14        _6_15          _6_16      _6_17      _6_18          _6_19      _6_20          _6_21          _5_1         _5_2       _5_3         _5_4       _5_5       _5_6       _5_7           _5_8         _5_9         _5_10        _5_11        _5_12        _5_13          _5_14        _5_15      _5_16      _5_17      _5_18          _5_19        _5_20        _5_21        _5_22          _5_23      _5_24       _5_25          _5_26       _5_27          _5_28          _4_1         _4_2       _4_3         _4_4        _4_5       _4_6       _4_7       _4_8       _4_9           _4_10        _4_11        _4_12        _4_13        _4_14        _4_15        _4_16        _4_17          _4_18        _4_19       _4_20      _4_21      _4_22      _4_23      _4_24          _4_25        _4_26        _4_27        _4_28        _4_29        _4_30          _4_31       _4_32       _4_33       _4_34       _4_35          _4_36      _4_37      _4_38      _4_39          _4_40      _4_41      _4_42          _4_43      _4_44          _4_45          age_approx_patient_norm  clin_size_long_diam_mm_patient_norm  tbp_lv_A_patient_norm  tbp_lv_Aext_patient_norm  tbp_lv_B_patient_norm  tbp_lv_Bext_patient_norm  tbp_lv_C_patient_norm  tbp_lv_Cext_patient_norm  tbp_lv_H_patient_norm  tbp_lv_Hext_patient_norm  tbp_lv_L_patient_norm  tbp_lv_Lext_patient_norm  tbp_lv_areaMM2_patient_norm  tbp_lv_area_perim_ratio_patient_norm  tbp_lv_color_std_mean_patient_norm  tbp_lv_deltaA_patient_norm  tbp_lv_deltaB_patient_norm  tbp_lv_deltaL_patient_norm  tbp_lv_deltaLB_patient_norm  tbp_lv_deltaLBnorm_patient_norm  tbp_lv_eccentricity_patient_norm  tbp_lv_minorAxisMM_patient_norm  tbp_lv_nevi_confidence_patient_norm  tbp_lv_norm_border_patient_norm  tbp_lv_norm_color_patient_norm  tbp_lv_perimeterMM_patient_norm  tbp_lv_radial_color_std_max_patient_norm  tbp_lv_stdL_patient_norm  tbp_lv_stdLExt_patient_norm  tbp_lv_symm_2axis_patient_norm  tbp_lv_symm_2axis_angle_patient_norm  tbp_lv_x_patient_norm  tbp_lv_y_patient_norm  tbp_lv_z_patient_norm  x1_patient_norm  x2_patient_norm  x3_patient_norm  x4_patient_norm  x5_patient_norm  x6_patient_norm  x7_patient_norm  x8_patient_norm  x9_patient_norm  x10_patient_norm  x11_patient_norm  x12_patient_norm  x13_patient_norm  x14_patient_norm  x15_patient_norm  x16_patient_norm  x17_patient_norm  x18_patient_norm  x19_patient_norm  x20_patient_norm  x21_patient_norm  x22_patient_norm  x23_patient_norm  x24_patient_norm  x25_patient_norm  x26_patient_norm  x27_patient_norm  x28_patient_norm  x29_patient_norm  x30_patient_norm  x31_patient_norm  x32_patient_norm  x33_patient_norm  x34_patient_norm  x35_patient_norm  x36_patient_norm  x37_patient_norm  x38_patient_norm  x39_patient_norm  x40_patient_norm  x41_patient_norm  x42_patient_norm  count_per_patient  onehot_0  onehot_1  onehot_2  onehot_3  onehot_5  onehot_7  onehot_8  onehot_9  onehot_10  onehot_11  onehot_12  onehot_13  onehot_14  onehot_15  onehot_16  onehot_17  onehot_18  onehot_19  onehot_20  onehot_21  onehot_23  onehot_24  onehot_25  onehot_27  onehot_28  onehot_29  onehot_31  onehot_34  onehot_35  onehot_37  onehot_38  onehot_39  onehot_40  onehot_41  onehot_42  onehot_43  onehot_44  onehot_45  onehot_46\n85.0        21.99                   26.079785  19.748381    29.736354  31.810709    39.552572  37.442219    48.748145  58.167609    50.890849  59.541918    126.702946      44.304929                2.536091               6.331404       -2.074355      -8.651069      9.326246        6.346091            0.908471             9.169963            1.975117                7.115865            7.485594           74.923728           2.460110                     2.459176     5.016087        0.285642           100                       19.623352   1439.854980  -177.961243  0.417006  0.022571  9.419463   8.651069   10.919278  7.401507  1.030881  1450.943708  0.591334  1.691092  13.831685  2.032589  0.274618  0.041302  2.361637  1869.15  123.629721  5.169977  7.424078  1.952071  4.849707  0.258706  53.457877  6.304248  15.708887  1.557168  -1.464674  21.401349  13.246159  0.505591  53.266479  3.648024  3.465125  0.023237  87.798406  0.702710  183838.842529  17.056829  2.303964  1.877678  533.907382  3076.290963  1450.601720  1872.632832  59.127731  98.747245  183865.293998  2367.467120  1451.814780  1441.333203  183870.482260  1819.598498  1871.844967  181996.420642  98.681089  183811.552632  183863.405061  1450.977673  1863.924550  44.213944  23.878834  94.187996  183864.783698  2367.957863  1449.560729  1449.597248  1450.130077  183869.841381  1870.224853  1851.117641  1870.230216  183874.158486  46.971092  57.593608  183857.679462  86.338562  183849.603321  183811.850556  1441.593586  20.371139  1872.843214  44.581772  16.632413  93.949479  183838.820449  1450.683946  2360.391146  1397.570353  1429.612986  1450.765138  183843.403664  1859.319916  55.943321  28.054350  94.166521  183836.811190  1869.052759  1871.857644  1821.882500  183724.714396  36.342292  100.455445  183838.588037  104.002797  183840.307586  183835.222615  1442.374144  8.129351   1860.512323  123.518124  44.323741  22.742706  45.960980  78.839876  183838.426574  1449.015724  418.408598   1453.384416  1445.620842  1429.564508  1448.256304  1452.872176  183833.634719  1867.153398  123.254254  40.108199  28.942803  41.463991  74.053256  183838.252199  1871.282052  1863.552012  1847.817694  1866.241517  1870.402335  183848.051518  127.557298  110.078349  119.627293  144.663791  183715.213264  58.000145  8.812123   34.822718  183834.000760  57.600785  92.458605  183823.135370  36.014305  183825.604188  183835.398077  0.0                       9.465766                             1.298056               1.897280                 -0.357251               0.365296                  0.179873               0.749215                 -1.604837              -1.406641                  0.325723               0.244227                  11.649548                    4.352790                              1.601248                            0.088591                   -1.885775                    0.135800                   -0.144068                    -0.451575                         1.038425                          5.691919                        -0.806219                             1.934822                         1.761478                        9.708127                         1.646060                                 -0.154110                  4.632805                    -0.341994                        0.223722                              0.071104               1.024988              -2.903286              -1.455777        -2.571484         0.655967        -0.135800        -0.128786         1.795378        -0.080487         1.038985        -2.150804         4.711132          0.808943          0.510480         -0.230481         -0.236526         -0.132896          9.465816          1.226392          3.109660          1.789230         -1.478503          4.685039          9.461552         -1.671486         -0.128786          4.554895         -0.000382         -1.167386          6.738565          4.856510          0.031325          4.342504          3.083275          10.784707        -0.806202          15.543714         1.627045          15.109218        -0.137703          2.275496          3.819574          6.473004          11.864981        557                0         0         1         0         1         0         0         1         0          1          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0            1\n15.0        2.32                    25.811872  19.507916    27.771422  28.100265    37.914438  34.207947    47.094384  55.230639    57.079223  64.245025    2.308125        17.053231                0.000000               6.303956       -0.328842      -7.165803      7.356691        4.882407            0.759570             1.452959            5.503647                4.377227            0.000000           6.273834            0.000000                     0.808253     3.037013        0.480519           120                       157.647339  1233.951416   144.149048  0.626275  0.058640  8.136255   7.165803   9.549698   4.857746  0.000000  1252.304966  2.718151  0.367897  4.882407   2.103343  0.432987  0.012581  0.798211  34.80    0.000000    1.712265  4.916386  3.691718  1.196382  0.154667  51.162511  5.513521  5.844584   1.443727  -0.396896  3.014700   4.573330   0.000000  0.000000   0.000000  0.475175  0.366910  15.178353  0.000000  2890.476841    13.798601  0.000000  1.164926  16.722078   16.636488    1251.737675  36.430618    52.181020  21.587659  2890.517085    1251.929919  1253.102058  1247.837431  3147.723744    18.646804    38.137876    2855.784735    53.396266  2839.416732    2890.560115    1252.288382  30.308844    43.139060  12.944399  12.672498  2889.933817    1253.736935  1249.485915  1250.883379  1252.351065  3144.696138    62.178346    32.663655    37.672854    2890.359466    47.091231  36.927272  2885.805538    12.509249  2884.732890    2890.558214    1244.217737  14.470415  35.333983    43.220954  11.181401  11.704465  2890.444859    1251.876744  1250.957442  1201.163783  1249.296426  1251.929032  3144.644019    30.553930    51.445067  6.795479   15.335507  2888.408572    59.829301    33.589304    36.948760    2890.716873    48.514125  51.809923   2890.572964    16.023964   2890.898064    2890.541540    1245.206968  6.378684   28.592573    5.056038    43.061851  10.917671  11.538200  10.052747  2889.900913    1250.237884  1217.549001  1248.663407  1247.877561  1249.300489  1252.324275  1252.437873  3140.887222    33.031807    3.423414    46.431009  6.295523   5.642605   10.745301  2887.794202    31.428665    58.265458    32.296550    35.054525    37.655754    2890.272562    46.323650   7.932250    7.851550    10.998751   2890.507395    51.844808  51.569654  36.411863  2889.768891    3.598107   16.782934  2884.659335    15.726153  2885.936734    2890.072971    0.0                      -1.506401                             0.445533               0.704175                  0.175455               1.856636                  0.356051               1.598042                 -0.212966               0.663380                 -0.326948              -0.794365                 -1.411350                     0.972853                             -2.029281                           -0.271905                   -2.546679                    0.968367                   -1.444224                    -1.328794                         0.503311                         -1.322528                        -1.477161                             2.719613                        -1.979906                       -1.555868                        -1.842435                                 -1.334267                  2.741165                     3.107070                        1.125756                              1.134655               1.166702               0.287341              -0.565144        -1.042629         1.219573        -0.968367        -1.144864         2.766666        -3.203524         1.154922         2.938104        -1.922459         -1.746572          3.601207          3.085092         -1.246368         -1.371684         -1.506423         -1.998170          0.056767          2.773860         -2.261089         -2.069001         -1.506078          0.226626         -1.144861          0.656033         -0.677530         -1.180540          1.142151         -0.185244         -1.990809         -1.716860         -2.889884         -0.164763         -1.477155         -1.295317         -1.617950         -0.799906         -1.586457         -1.815734          0.993290          1.508315         -0.331748         23                 0         1         0         0         0         0         1         0         1          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          1          0          0            1\n            2.50                    13.599691  9.545997     22.627792  23.304820    26.400162  25.184136    58.993411  67.725272    36.117769  47.162487    4.616251        13.147169                1.307936               4.053694       -0.677028      -11.044719     11.208563       9.799411            0.515027             2.174873            91.931683               1.885996            3.414352           7.790419            0.976766                     4.553489     1.681505        0.240310           170                      -223.491333  184.088760    134.508911  0.869949  0.076062  8.731860   11.044719  11.784592  2.126306  1.339034  319.264302   1.687607  0.592555  13.213763  0.453224  0.213151  0.096549  4.152563  37.50    77.159582   1.938458  2.202368  2.131358  1.725664  0.166667  63.359341  6.803837  4.898471   2.452569  -2.556018  1.872116   4.329214   0.777836  6.439453   1.214911  0.255117  6.128779  15.206906  0.234727  1473.804061    15.775440  0.673622  1.022848  9.011628    16.639973    318.719498   79.174316    64.467485  21.344922  1473.916256    326.461286   325.191092   315.636583   1506.534407    75.268459    80.943955    1437.715369    64.850167  1410.605045    1473.065318    319.444931   70.676788    53.434562  17.053757  11.984502  1473.148016    333.592274   321.137264   316.987429   318.148003   1503.509105    40.272616    81.531980    69.859845    1475.777409    59.577530  49.176339  1472.701588    12.187995  1469.062903    1467.550565    310.880023   20.079609  86.609192    55.229574  14.924319  11.834282  1473.820750    319.268788   328.174311   255.995314   317.427299   319.403792   1503.417286    80.530635    64.537152  12.526580  14.319899  1473.493623    104.924104   87.116354    83.195979    1397.211339    61.739158  64.126291   1474.424030    15.625823   1476.431754    1472.762414    308.508182   11.541341  26.856725    77.108099   54.798606  15.278403  10.692953  13.992696  1473.073909    319.195574   282.023148   323.802369   318.721011   317.490939   318.180500   319.563979   1496.317243    38.170525    76.301359   50.547920  16.262488  7.313266   6.059882   1472.248264    84.728331    66.708242    36.631328    36.595678    39.335590    1474.129805    97.238998   72.419900   72.968502   78.131753   1396.714297    66.215168  57.256107  48.984891  1473.506484    9.191257   18.795685  1468.969803    11.093234  1469.562702    1473.652396    0.0                      -0.987594                            -1.301046              -1.134717                 -0.910245              -0.965892                 -1.308260              -1.158253                  0.725291               0.523342                 -0.831445              -0.590841                 -0.688526                    -1.071879                             -0.323710                           -1.065545                    0.121070                   -0.367761                    0.317210                     0.675474                        -0.989841                         -0.575470                         1.025343                            -0.549635                        -0.443793                       -0.878006                        -0.510848                                  0.399454                 -1.138170                     0.034387                        1.478981                             -0.696706              -1.405039               0.942039               1.145687         1.488061        -0.653926         0.367761         0.022387        -0.509761         0.144200        -1.331082         0.373706        -0.544813          0.145939         -0.387270         -0.037791          0.654701          0.420383         -0.987601         -0.231448         -0.711537         -0.501277         -0.522202         -0.819189         -0.987490          0.655005          0.022387         -1.093631          1.533523         -0.820984         -0.548807         -1.101281          0.002334         -0.514512         -0.396200         -1.043065          1.025340         -0.771723         -0.425038         -0.942337         -0.307947         -0.559511         -1.172336         -0.594643         -0.519059         72                 0         1         0         0         0         0         0         1         0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          1          0            1\n                                    13.881058  10.564710    23.925699  23.634362    27.660854  25.888147    59.878826  65.915054    29.392749  33.796074    3.396510        18.924859                0.277813               3.316349        0.291337      -4.403325      4.546140        4.820243            0.766982             1.744723            2.061362                3.702896            1.074286           8.017385            0.435895                     0.505563     1.587094        0.343434           5                         177.753632  1278.323608   52.532593   0.697889  0.052841  6.036228   4.403325   5.520173   4.046330  0.637324  1291.691633  2.360478  0.423643  5.894529   1.271702  0.314285  0.014959  0.498111  37.50    16.635088   1.848055  4.099171  4.024603  1.480811  0.166667  62.896940  3.187074  6.515369   1.432630  -0.265213  2.753445   5.277390   0.175045  3.977970   0.832702  0.518646  0.137424  15.206906  0.149701  4387.243114    8.011010   0.213077  1.227189  12.878788   17.497171    1291.021402  39.037496    63.261496  17.045237  4387.236141    1291.788911  1292.949065  1286.520901  4571.195647    29.578368    42.350483    4349.791432    64.413974  4324.398572    4387.092121    1291.653189  35.420093    57.955814  9.655203   13.000971  4386.584254    1293.723266  1288.934501  1290.277781  1290.898676  4570.608669    59.725187    37.150575    37.616192    4387.115600    57.891115  47.902969  4383.454808    10.623193  4380.773819    4383.306114    1285.671622  10.281546  40.610791    56.887926  6.383734   12.403287  4387.194854    1291.380958  1290.382704  1228.812839  1288.944478  1291.259545  4570.576194    35.586638    63.115453  7.484498   14.841541  4385.981994    72.818906    40.043756    38.935184    4370.774585    60.514444  63.107639   4387.424165    16.280498   4387.514714    4386.440759    1287.314856  3.567750   33.559041    16.158983   56.879220  8.841785   6.162186   10.111080  4386.557459    1290.439594  1254.208924  1287.721530  1290.020010  1288.941538  1290.869081  1291.639705  4567.801475    36.687394    14.717175   57.041943  7.643243   3.526486   9.563133   4384.892882    37.460628    71.220605    35.332265    37.165282    40.142873    4387.086082    60.748319   11.101576   11.916341   20.026548   4370.614994    63.376613  59.088088  47.796355  4386.217690    4.980760   16.846489  4380.732977    12.214850  4381.974365    4386.757291    0.0                      -1.119273                            -2.412639              -1.711341                 -2.289996              -2.643082                 -2.520211              -2.707573                 -0.091158              -0.675145                 -2.071536              -2.209015                 -0.834196                    -0.208517                             -1.375918                           -1.526282                    0.616800                    1.773306                   -1.810255                    -1.022224                         0.031682                         -1.036752                        -1.420644                             0.152485                        -1.251699                       -0.965552                        -1.040698                                 -1.497709                 -1.534190                     0.558459                       -1.678257                              2.347845               0.690901               0.383953               0.453627         0.022073        -0.875241        -1.773306        -1.862484         0.179064        -0.061242         0.746641         2.033834        -1.285676         -1.267752          0.138764          0.530525         -1.150403         -1.549026         -1.119277         -1.388791         -0.606422          0.180240          0.240150         -1.457448         -1.119215         -0.404256         -1.862477         -0.296327         -1.603882          0.676116         -0.520898         -0.432164         -1.049747         -0.715793         -1.007825         -1.028052         -1.420638         -0.814616         -0.548711         -0.790650         -1.886580         -1.252221         -0.170931         -0.611277         -0.612365         508                0         1         0         0         0         0         1         1         0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          1          0            1\n                                    15.897346  11.740269    27.582345  29.313856    31.835693  31.577462    60.042595  68.173781    42.130255  49.077548    3.246388        15.101202                0.712768               4.157076       -1.731511      -6.947293      7.242500        6.071008            0.823565             1.452959            20.381984               2.376329            2.435866           7.001740            0.908701                     1.793621     2.429053        0.258427           35                       -95.871864   751.677490   -17.651245   0.581184  0.066220  8.131186   6.947293   8.279148   2.634756  0.784372  757.972315   2.156779  0.463654  8.506874   0.614107  0.233079  0.036547  1.730381  37.50    42.796425   1.878587  2.700975  1.549280  1.446069  0.166667  64.108188  4.779969  5.357466   1.697655  -1.507243  1.809438   4.654765   0.293434  5.788417   1.202864  0.411793  1.358799  15.206906  0.234833  2460.671992    12.835881  0.587011  1.096228  9.691011    12.584312    757.477392   51.601466    64.628374  18.073891  2460.667409    758.284299   760.357332   753.527672   2572.727361    46.671999    54.383518    2423.397815    65.575173  2396.632552    2460.408300    757.960128   46.546476    56.734860  12.782380  13.152224  2460.163000    762.263784   758.478038   756.308437   756.818289   2570.296279    43.183871    52.636641    45.869714    2460.987727    59.777405  49.235524  2458.611935    10.754879  2455.376714    2454.948417    749.900315   14.701755  57.369737    56.101840  10.616690  12.931410  2460.628999    757.766032   758.063189   693.887636   756.171075   757.711070   2570.269253    51.281468    64.542548  8.760323   13.825110  2460.104217    83.716964    57.008965    54.093737    2418.188514    62.527271  64.698348   2461.047036    16.103027   2462.207851    2459.547377    751.104796   6.549110   31.217948    42.942252   56.025710  12.032095  7.425141   9.839837   2460.142476    757.425434   720.522547   757.212978   755.884514   756.172574   756.798295   757.916634   2566.553365    37.554933    41.087296   55.762477  10.652629  3.742399   6.991462   2458.559148    55.753276    70.449127    36.239716    36.790855    39.649586    2460.741760    74.121965   37.676056   38.300799   44.213723   2417.901362    65.816804  58.517545  49.137404  2460.081536    7.487337   17.504761  2455.340787    10.429901  2456.054763    2460.330558    0.0                      -0.987594                            -0.665230              -0.228260                  0.344222               0.566511                 -0.065916               0.433811                  0.921894               0.629536                 -0.015127              -0.355068                 -0.916086                    -0.449692                             -0.882804                           -1.009191                   -0.542030                    0.769670                   -0.782370                    -0.763208                         1.048307                         -1.338675                        -0.696433                            -0.094036                        -0.838831                       -1.060852                        -0.575789                                 -0.787629                  0.682938                     0.244196                       -1.074429                             -0.047649               0.191627              -1.525198              -1.084972         0.427566        -0.890517        -0.769670        -0.944021        -0.069391        -0.466296         0.055275         1.547328        -1.220688         -0.908798         -0.100559          0.213894         -0.788318         -0.798491         -0.987601         -0.859016         -0.780971         -0.066415         -0.749628         -1.373098         -0.987490          0.816329         -0.944019         -0.687502         -0.021836          0.015763         -0.587200         -0.790364         -1.008118         -0.590180         -0.420190         -0.428901         -0.696431         -0.771723         -0.424610         -0.753676         -0.923668         -0.680720         -0.449745         -0.508435         -0.667586         72                 0         1         0         0         0         0         0         1         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          1          0          0          0          0          0          0          1          0            1\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ..\n            2.60                    20.005305  14.008047    36.031108  36.250182    41.212291  38.862592    60.959952  68.872124    53.729109  61.205309    3.809345        14.333227                0.376063               5.997257       -0.219074      -7.476200      7.524912        5.306647            0.790327             1.646687            67.439914               1.775877            1.262035           7.389195            0.464290                     1.033813     2.780469        0.196262           45                        0.615112    915.565308   -55.533936   0.633341  0.069768  7.912172   7.476200   9.586901   1.972139  0.809957  917.248183   1.939755  0.515529  6.568682   0.348537  0.176730  0.016891  1.016641  39.00    22.924753   1.276080  2.041907  3.608630  1.570561  0.173333  64.916038  5.535000  4.968517   1.570124  -0.566006  1.450216   4.145463   0.135251  2.241219   0.737750  0.489952  4.495994  15.223666  0.091122  3494.114864    13.692532  0.297213  1.067990  7.654206    11.214427    916.695696   42.891870    65.485194  19.666852  3494.087791    917.279098   919.251949   913.261591   3610.659060    31.718362    46.238078    3455.143426    66.765074  3429.235501    3494.004534    917.230692   34.926958    56.409777  12.736570  10.115029  3493.535020    920.452081   915.516421   915.694638   916.562242   3608.284113    57.494371    42.329990    35.444272    3494.218371    61.164827  50.270294  3492.561928    11.884921  3489.186887    3491.925285    909.399396   14.974435  45.865672    57.231351  11.977735  9.938590   3494.067680    917.085241   916.992147   852.351692   915.801824   916.879815   3608.268079    39.667413    65.285961  6.727978   15.520259  3493.798487    77.347820    44.377145    44.553572    3471.431744    63.669055  65.251334   3494.323412    15.193925   3494.704869    3493.433928    909.845749   7.383358   32.272427    23.404708   57.044703  11.368237  9.481863   11.296431  3493.522260    916.950775   878.300796   913.738000   914.001103   915.810734   916.529544   917.318894   3602.979171    39.091146    21.727138   58.579577  7.899559   4.887554   9.639556   3492.205675    42.102949    72.145730    37.919188    38.487196    41.664143    3494.170869    66.438580   18.274924   19.032733   26.454108   3471.213686    65.712105  62.910875  50.187855  3493.171056    3.335325   16.726599  3489.167533    14.189464  3489.996291    3493.669040    0.0                      -1.082233                             0.178097              -0.044122                  0.382897               0.329852                  0.353935               0.281687                  0.272475               0.331022                  1.101593               1.016074                 -0.806651                    -1.026226                             -1.153793                            0.360411                    0.244137                   -0.114696                   -0.009014                    -0.582694                         0.206400                         -1.098208                         0.370653                            -1.061593                        -1.099137                       -1.035107                        -0.971004                                 -0.747036                  0.620432                    -0.828189                       -0.871677                              0.394481              -1.447468              -1.143303              -0.007132         1.579283         0.083148         0.114696         0.155250        -1.053636        -0.061051        -1.517335         1.152503        -0.983431         -0.947850         -0.788235         -0.864332         -1.001570         -0.752676         -1.082237         -1.150114         -1.410501         -1.049450          0.008355         -1.333861         -1.082177          0.319599          0.155250         -1.095722         -0.273479          0.285571         -0.824057         -1.171173         -1.261119         -0.952988         -1.189580         -1.101439          0.370652         -0.800400         -0.905168         -0.839890         -0.075909         -1.023683         -1.167956         -0.887989         -0.684971         508                0         1         0         0         0         0         0         1         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          1          0          0          0          0          0          0          1          0            1\n                                    20.580772  15.008412    28.829781  29.783463    35.422090  33.351269    54.478023  63.255660    42.112717  47.288367    2.664665        18.050249                0.000000               5.572360       -0.953682      -5.175650      5.321613        4.576510            0.896319             1.280369            5.220233                3.130433            0.000000           6.935263            0.000000                     0.730729     2.337723        0.287671           55                       -115.887299  824.653870   -29.129639   0.492450  0.055401  8.777637   5.175650   7.664728   3.418104  0.000000  833.266108   2.602677  0.384220  4.576510   0.900536  0.263461  0.015453  0.719610  39.00    0.000000    1.342251  3.473505  4.019539  1.298737  0.173333  58.866841  4.425233  6.112640   1.710410  -0.185657  1.995076   4.808560   0.000000  0.000000   0.000000  0.568118  0.348016  15.223666  0.000000  2220.375067    11.701692  0.000000  1.198496  11.219178   11.498212    832.853510   40.349598    59.423312  20.347321  2220.380570    833.361518   835.004607   828.614013   2369.229364    21.415092    41.896851    2181.443896    60.994447  2161.580161    2220.440936    833.257036   35.666928    52.232450  12.025948  12.639968  2219.951634    836.171325   831.037632   831.584919   833.337099   2367.529810    70.774235    37.844334    41.564770    2220.515841    54.403123  44.193842  2217.438751    12.330665  2214.324252    2220.439519    824.529822   12.835393  39.424665    50.125487  10.316370  12.169033  2220.337094    833.008025   832.692830   774.425518   831.275823   832.840271   2367.499239    34.782166    59.111418  5.990371   15.242259  2219.508775    68.817009    37.535492    40.705042    2220.746221    57.203211  59.161578   2220.712883    16.020382   2220.588128    2220.447302    828.174863   6.362959   34.771720    5.600794    50.101452  11.170600  11.066442  8.272242   2219.934084    832.399075   794.308205   829.291864   830.959419   831.274256   833.278013   833.441032   2363.999190    38.367340    4.317007    54.420660  6.160753   5.173872   10.877206  2217.806009    35.114761    67.658050    37.513594    39.270549    41.612150    2220.464272    55.422372   7.415378    7.290117    12.471336   2220.403742    59.318121  59.137438  43.873383  2219.889272    2.939545   16.553713  2214.285119    15.807038  2215.597733    2219.888509    0.0                      -1.082233                             0.421537               0.440242                 -1.207167              -1.194038                 -0.874118              -0.988100                 -1.907701              -1.580026                 -0.413026              -0.621454                 -0.883025                    -0.364274                             -2.004000                            0.061389                   -0.292219                    1.298783                   -1.341332                    -1.242468                         0.999645                         -1.327844                        -1.334094                            -0.208183                        -2.124654                       -1.085367                        -2.110590                                 -1.177735                 -0.178939                     0.033064                       -0.670032                             -0.890229              -1.983368              -0.770143              -1.012849         0.257608         0.525299        -1.298783        -0.798449        -0.194293        -0.061945        -2.025111         2.541193        -1.415353         -1.893186         -0.233944          0.015144         -1.112387         -1.208853         -1.082237         -2.020053         -1.317478         -0.193739          0.237328         -1.708168         -1.082177         -1.849062         -0.798446         -0.504452          1.083937          0.779410         -0.697311         -0.738252         -1.979539         -1.259078         -2.601754         -0.901525         -1.334089         -0.800400         -1.459652         -0.910114         -0.710379         -1.831008         -0.350626         -0.699175         -0.681692         508                0         1         0         0         0         0         0         1         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          1          0          0          0          0          0          0          1          0            1\n                                    20.770344  13.563670    26.083294  26.182553    33.342847  29.487273    51.469399  62.613933    35.894801  43.152856    2.720961        15.756851                1.012565               7.206674       -0.099259      -7.258055      7.551512        6.707147            0.862560             1.405747            74.890280               2.319091            2.736105           6.547807            0.816922                     1.706574     1.790985        0.234568           120                      -110.180061  681.557739    140.265625  0.540672  0.063464  11.144534  7.258055   10.228654  2.553658  1.239473  704.510499   2.406432  0.415553  9.443252   0.543984  0.213022  0.039547  1.641651  39.00    52.116092   1.972585  2.617123  6.556507  1.313982  0.173333  57.041666  5.905516  5.667995   1.731069  -0.050214  1.535905   4.897521   0.565367  6.345275   1.255199  0.387646  4.992685  15.223666  0.191624  1916.945438    14.563988  0.873398  1.119772  9.148148    9.573751     704.130389   57.426775    57.928430  19.407554  1916.946790    705.789363   706.487057   699.869518   2040.090531    50.211693    61.515847    1878.342280    58.703891  1859.970319    1916.416483    704.538106   53.412160    48.948925  14.815870  13.655970  1916.510140    709.071703   699.597942   702.813271   703.315470   2036.182703    39.944926    60.585580    50.610032    1917.658374    52.762101  42.982333  1914.947872    10.935957  1911.346749    1910.683196    693.456294   18.022993  65.633403    46.149602  13.881893  13.450142  1916.917330    704.336562   705.346753   647.501657   702.980688   704.293502   2036.164030    59.725869    57.847543  9.291887   14.803327  1916.477770    84.631512    64.432766    61.126398    1865.284353    55.750930  57.691476   1917.255049    15.465713   1917.044843    1915.808920    697.394536   7.181792   33.135536    52.315176   45.923699  13.679756  8.848797   9.533856   1916.496978    704.061016   665.590730   699.211391   700.890822   702.991052   703.296851   704.530645   2032.356216    39.302450    50.559086   47.912494  10.172422  4.041195   7.652645   1914.610550    61.247018    64.541742    37.934665    38.327733    41.414071    1917.161865    74.475140   46.795355   47.682038   53.706516   1864.880594    57.445280  51.036702  42.490916  1916.514739    6.552371   16.541424  1911.320793    10.949755  1912.106994    1916.635638    0.0                      -0.912349                             0.683245               0.524990                 -0.035330              -0.232022                  0.278559              -0.086687                 -0.684608              -0.686876                 -0.861718              -1.084488                 -1.003370                    -0.240926                             -0.601178                            0.653136                    0.484393                    0.683404                   -0.696697                    -0.517740                         1.305898                         -1.388587                         0.615258                            -0.147220                        -0.717618                       -1.166091                        -0.663357                                 -0.825070                 -0.871465                    -0.032113                        0.533274                             -0.120419              -0.005624               1.035383              -1.397917         0.130665         0.296368        -0.683404        -0.406566        -0.139630         0.034617        -0.113669         2.171831        -1.472903         -0.698971         -0.225526         -0.039423         -0.716158         -0.843141         -0.912356         -0.688812         -0.671959         -0.139547          1.206763         -1.634776         -0.912253         -0.706017         -0.406565         -0.412738          0.047007          1.178228         -0.754749         -0.558520         -0.440871         -0.525458         -0.315972         -0.523557          0.615256         -0.731393         -0.598758         -0.857621         -0.561698         -0.279936         -0.217894         -0.577319         -0.777840         72                 0         1         0         0         0         0         0         1         0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          0          0          0          0          1          0            1\n                                    20.831540  11.672370    40.824900  37.610370    45.832580  39.380000    62.966350  72.758280    56.564090  67.993090    3.490336        13.463250                1.627071               9.159166        3.214532      -11.429000     11.923870       7.914330            0.756023             1.704327            96.817150               2.246862            5.041219           6.855018            1.734537                     4.303010     1.772319        0.281250           155                       53.774180   1243.459000   156.837700  0.655510  0.074276  9.791930   11.429000  14.994852  2.528112  0.938038  1254.464033  1.963999  0.509165  12.955549  0.631930  0.249961  0.063286  4.046898  39.00    102.450722  2.681368  2.602388  8.859028  1.501928  0.173333  67.862315  8.657282  5.123857   1.527578   0.314899  1.927974   4.885436   0.918046  11.326923  1.554171  0.328518  6.454477  15.223666  0.487839  4378.500977    23.802700  1.230104  1.035071  10.968750   14.724855    1253.929875  101.896310   69.453140  23.517430  4378.513094    1255.186196  1256.073150  1249.785264  4552.751070    98.618212    99.774716    4340.236257    68.844145  4310.699227    4377.605342    1254.464833  91.879719    55.757616  17.520115  15.316209  4377.949323    1259.974961  1246.841644  1252.971358  1252.970167  4547.283582    53.187925    104.576557   93.868686    4379.453023    63.957633  54.844100  4376.298239    12.885350  4373.460058    4367.259460    1244.794087  22.174044  110.078854   58.974696  17.425122  15.179708  4378.483253    1254.263885  1256.449359  1186.630259  1252.540088  1254.260886  4547.261767    105.265831   69.121941  12.905720  13.010633  4377.951347    127.145345   109.108881   104.913280   4276.283220    66.176081  69.037015   4378.557652    17.528088   4378.242374    4377.049289    1243.151690  11.335188  28.166115    102.114428  58.142740  14.218362  10.884515  13.785015  4377.930482    1253.959028  1215.559940  1248.672556  1247.678214  1252.575509  1252.994751  1254.149470  4540.013498    39.428538    101.376393  55.493112  13.133454  3.493554   6.571655   4376.614691    106.594628   70.672962    37.605345    38.437054    40.607391    4378.480876    120.232475  97.606977   98.242419   103.308056  4276.109796    67.991833  57.085089  53.650693  4377.576610    11.037789  16.480744  4373.434034    8.230384   4373.687097    4378.229226    0.0                      -0.602173                            -0.077180              -0.308599                  1.918094               1.738357                  1.769606               1.390973                  1.333228               1.266366                  1.674167               1.404601                 -0.507344                    -0.650251                             -0.000348                            0.272488                    1.270419                    0.369860                   -0.364387                    -0.634178                         0.658768                         -0.713763                         0.625214                            -0.106992                         0.286996                       -0.657669                         0.627472                                 -0.101781                 -0.635099                     0.522757                        1.248398                              0.415246               0.602634               1.437458              -0.595369         0.827954        -0.397993        -0.369860        -0.202162        -0.066248        -0.896160         0.619530         1.225749        -0.676770         -0.453656         -0.079104          0.453892         -0.427570         -0.044725         -0.602175          0.413266          0.189262         -0.060412          0.743613         -0.953068         -0.602154          1.644139         -0.202162         -0.640797          0.143705          1.135820         -0.387114         -0.525180          0.610942          0.142767          0.364142         -0.409338          0.625212         -0.497443          1.128909         -0.468221         -0.020774          0.397120         -0.694672         -0.330287         -0.430558         20                 1         0         0         0         0         1         0         1         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0          0          0          0          0          1          0          0          0          0          0          0          0          1          0            1\n                                    21.238813  15.580026    25.862639  28.018324    33.465853  32.058753    50.606612  60.923071    49.726720  56.915482    4.391068        15.354438                0.431749               5.658788       -2.155685      -7.188762      7.591928        5.662831            0.596624             2.034143            3.746744                1.943753            1.321788           8.211113            0.449849                     1.418484     2.451000        0.193798           120                       209.858521  245.178757    147.482635  0.782363  0.065128  10.316458  7.188762   9.399316   2.137551  0.959743  354.830029   1.869958  0.534771  6.984619   0.376696  0.176228  0.024923  1.383991  39.00    21.849367   1.287388  2.202679  1.977172  1.684743  0.173333  55.764841  5.426698  5.326662   0.862863  -1.228553  1.591301   4.366662   0.176152  2.569229   0.786770  0.459134  0.249783  15.223666  0.087180  1558.082692    15.003234  0.257592  1.105381  7.558140    12.764732    354.308988   41.670894    56.699266  20.020355  1558.116412    356.088254   358.772035   350.857530   1596.280827    24.096181    45.579470    1519.150077    57.659795  1502.424191    1557.981342    354.940441   35.324771    47.853697  14.665626  13.680533  1557.453685    361.463545   356.246909   354.018975   354.145813   1593.822715    51.796829    41.717444    39.421846    1558.547446    51.873307  40.928679  1556.699372    11.407876  1552.875508    1555.649220    344.672463   16.029827  45.788801    45.673547  13.070557  13.526011  1558.062262    354.693216   356.075563   299.126098   353.256811   354.679201   1593.775787    38.631456    56.240091  7.897134   14.537229  1557.791872    69.654039    44.665988    44.167901    1536.788764    54.452407  56.432535   1558.457626    15.862893   1559.374807    1557.429808    347.880073   7.675208   33.047131    23.201437   45.491608  13.634731  10.670735  8.640122   1557.416339    354.588105   315.972017   353.075643   353.764977   353.271282   354.088116   355.147066   1588.618061    39.067317    20.619692   49.042609  8.999328   5.101565   8.368832   1556.294700    42.926435    63.927624    37.861131    38.460868    41.302237    1558.439660    57.346819   16.884972   17.562211   25.134376   1536.296031    57.242434  53.464893  40.909722  1557.464038    4.057535   17.233879  1552.821202    13.262669  1553.788528    1557.765654    0.0                      -0.912349                             0.812882               1.357949                 -0.091198               0.236129                  0.306674               0.553663                 -0.846283              -1.087224                  1.016250               0.609900                 -0.725933                    -0.369059                             -1.146789                           -0.190612                   -0.808767                    0.702640                   -0.685492                    -0.920712                        -0.450830                         -0.724250                        -1.096744                            -0.495970                        -1.288611                       -0.780472                        -1.013586                                 -0.948984                  0.736405                    -0.504259                        0.533274                              1.507257              -1.233189               1.152405               0.469097         0.309886        -0.029791        -0.702640        -0.635204        -0.500021        -0.273272        -1.218691         0.829853        -0.847795         -1.249910         -0.523650         -0.504100         -1.067869         -0.972799         -0.912356         -1.241567         -1.466594         -0.501006         -0.582444         -0.900257         -0.912253         -0.981084         -0.635203         -0.714758         -1.741767          0.238111         -0.720817         -1.065517         -1.252766         -0.964338         -1.248794         -0.243326         -1.096741         -0.731393         -1.019701         -0.926225         -0.469693         -1.141725         -0.359610         -0.779077         -0.660979         72                 0         1         0         0         0         0         0         1         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          1          0            1\nName: count, Length: 401054, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lgb',\n                              Pipeline(steps=[('sampler_1',\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              ('sampler_2',\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              ('classifier',\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                             interaction_constraints=None,\n                                                             lambda=8.879624125465703,\n                                                             learning_rate=0.08501257473292347,\n                                                             max_bin=None,\n                                                             max_cat_threshold=None,\n                                                             max_cat_to_onehot=None,\n                                                             max_delta_step=None,\n                                                             max_depth=6,\n                                                             max_leaves=None,\n                                                             min_child_weight=None,\n                                                             missing=nan,\n                                                             monotone_constraints=None,\n                                                             multi_strategy=None,\n                                                             n_estimators=None,\n                                                             n_jobs=None, ...))]))],\n                 voting='soft', weights=[0.5, 0.4, 0.15])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                             interaction_constraints=None,\n                                                             lambda=8.879624125465703,\n                                                             learning_rate=0.08501257473292347,\n                                                             max_bin=None,\n                                                             max_cat_threshold=None,\n                                                             max_cat_to_onehot=None,\n                                                             max_delta_step=None,\n                                                             max_depth=6,\n                                                             max_leaves=None,\n                                                             min_child_weight=None,\n                                                             missing=nan,\n                                                             monotone_constraints=None,\n                                                             multi_strategy=None,\n                                                             n_estimators=None,\n                                                             n_jobs=None, ...))]))],\n                 voting=&#x27;soft&#x27;, weights=[0.5, 0.4, 0.15])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                             interaction_constraints=None,\n                                                             lambda=8.879624125465703,\n                                                             learning_rate=0.08501257473292347,\n                                                             max_bin=None,\n                                                             max_cat_threshold=None,\n                                                             max_cat_to_onehot=None,\n                                                             max_delta_step=None,\n                                                             max_depth=6,\n                                                             max_leaves=None,\n                                                             min_child_weight=None,\n                                                             missing=nan,\n                                                             monotone_constraints=None,\n                                                             multi_strategy=None,\n                                                             n_estimators=None,\n                                                             n_jobs=None, ...))]))],\n                 voting=&#x27;soft&#x27;, weights=[0.5, 0.4, 0.15])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n               colsample_bynode=0.4025961355653304,\n               colsample_bytree=0.8329551585827726,\n               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n               learning_rate=0.03231007103195577, max_depth=4,\n               min_data_in_leaf=85, n_iter=250, num_leaves=103,\n               objective=&#x27;binary&#x27;, random_state=42,\n               scale_pos_weight=2.7984184778875543, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7d61781d3940&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.6779926606782505, base_score=None, booster=None,\n              callbacks=None, colsample_bylevel=0.5476090898823716,\n              colsample_bynode=0.9928601203635129,\n              colsample_bytree=0.8437772277074493, device=None,\n              early_stopping_rounds=None, enable_categorical=True,\n              eval_metric=None, feature_types=None, gamma=None,\n              grow_policy=None, importance_type=None,\n              interaction_constraints=None, lambda=8.879624125465703,\n              learning_rate=0.08501257473292347, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_subm['target'] = estimator.predict_proba(df_test[feature_cols])[:, 1]\n\ndf_subm.to_csv('submission_1.csv')\ndf_subm.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.233304Z","iopub.execute_input":"2024-09-09T06:56:16.233595Z","iopub.status.idle":"2024-09-09T06:56:16.397170Z","shell.execute_reply.started":"2024-09-09T06:56:16.233561Z","shell.execute_reply":"2024-09-09T06:56:16.396146Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                target\nisic_id               \nISIC_0015657  0.299342\nISIC_0015729  0.083241\nISIC_0015740  0.388403","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>isic_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ISIC_0015657</th>\n      <td>0.299342</td>\n    </tr>\n    <tr>\n      <th>ISIC_0015729</th>\n      <td>0.083241</td>\n    </tr>\n    <tr>\n      <th>ISIC_0015740</th>\n      <td>0.388403</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.398747Z","iopub.execute_input":"2024-09-09T06:56:16.399201Z","iopub.status.idle":"2024-09-09T06:56:16.406314Z","shell.execute_reply.started":"2024-09-09T06:56:16.399142Z","shell.execute_reply":"2024-09-09T06:56:16.405526Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-6\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n    #     '_3_1',    # x1-x    x2-x    x3-x\n    #     '_3_2',    # x1-x    x2-x    x3-x\n    #     '_3_3',    # x1-x    x2-x    x3-x\n    #     '_3_4',    # x1-x    x2-x    x3-x\n    #     '_3_5',    # x1-x    x2-x    x3-x\n    #     '_3_6',    # x1-x    x2-x    x3-x\n    #     '_3_7',    # x1-x    x2-x    x3-x\n    #     '_3_8',    # x1-x    x2-x    x3-x\n    #     '_3_9',    # x1-x    x2-x    x3-x\n    #     '_3_10',    # x1-x    x2-x    x3-x\n    #     '_3_11',    # x1-x    x2-x    x3-x\n    #     '_3_12',    # x1-x    x2-x    x3-x\n    #     '_3_13',    # x1-x    x2-x    x3-x\n    #     '_3_14',    # x4-x    x5-x    x6-x\n    #     '_3_15',    # x4-x    x5-x    x6-x\n    #     '_3_16',    # x4-x    x5-x    x6-x\n    #     '_3_17',    # x4-x    x5-x    x6-x\n    #     '_3_18',    # x4-x    x5-x    x6-x\n    #     '_3_19',    # x4-x    x5-x    x6-x\n    #     '_3_20',    # x4-x    x5-x    x6-x\n    #     '_3_21',    # x4-x    x5-x    x6-x\n    #     '_3_22',    # x4-x    x5-x    x6-x\n    #     '_3_23',    # x4-x    x5-x    x6-x\n    #     '_3_24',    # x4-x    x5-x    x6-x\n    #     '_3_25',    # x4-x    x5-x    x6-x\n    #     '_3_26',    # x7-x    x8-x    x9-x\n    #     '_3_27',    # x7-x    x8-x    x9-x\n    #     '_3_28',    # x7-x    x8-x    x9-x\n    #     '_3_29',    # x7-x    x8-x    x9-x\n    #     '_3_30',    # x7-x    x8-x    x9-x\n    #     '_3_31',    # x7-x    x8-x    x9-x\n    #     '_3_32',    # x7-x    x8-x    x9-x\n    #     '_3_33',    # x7-x    x8-x    x9-x\n    #     '_3_34',    # x7-x    x8-x    x9-x\n    #     '_3_35',    # x7-x    x8-x    x9-x\n    #     '_3_36',    # x7-x    x8-x    x9-x\n    #     '_3_37',    # x10-x    x11-x    x12-x\n    #     '_3_38',    # x10-x    x11-x    x12-x\n    #     '_3_39',    # x10-x    x11-x    x12-x\n    #     '_3_40',    # x10-x    x11-x    x12-x\n    #     '_3_41',    # x10-x    x11-x    x12-x\n    #     '_3_42',    # x10-x    x11-x    x12-x\n    #     '_3_43',    # x10-x    x11-x    x12-x\n    #     '_3_44',    # x10-x    x11-x    x12-x\n    #     '_3_45',    # x10-x    x11-x    x12-x\n    #     '_3_46',    # x10-x    x11-x    x12-x\n    #     '_3_47',    # x13-x    x14-x    x15-x\n    #     '_3_48',    # x13-x    x14-x    x15-x\n    #     '_3_49',    # x13-x    x14-x    x15-x\n    #     '_3_50',    # x13-x    x14-x    x15-x\n    #     '_3_51',    # x13-x    x14-x    x15-x\n    #     '_3_52',    # x13-x    x14-x    x15-x\n    #     '_3_53',    # x13-x    x14-x    x15-x\n    #     '_3_54',    # x13-x    x14-x    x15-x\n    #     '_3_55',    # x13-x    x14-x    x15-x\n    #     '_3_56',    # x16-x    x17-x    x18-x\n    #     '_3_57',    # x16-x    x17-x    x18-x\n    #     '_3_58',    # x16-x    x17-x    x18-x\n    #     '_3_59',    # x16-x    x17-x    x18-x\n    #     '_3_60',    # x16-x    x17-x    x18-x\n    #     '_3_61',    # x16-x    x17-x    x18-x\n    #     '_3_62',    # x16-x    x17-x    x18-x\n    #     '_3_63',    # x16-x    x17-x    x18-x\n    #     '_3_64',    # x19-x    x20-x    x21-x\n    #     '_3_65',    # x19-x    x20-x    x21-x\n    #     '_3_66',    # x19-x    x20-x    x21-x\n    #     '_3_67',    # x19-x    x20-x    x21-x\n    #     '_3_68',    # x19-x    x20-x    x21-x\n    #     '_3_69',    # x19-x    x20-x    x21-x\n    #     '_3_70',    # x19-x    x20-x    x21-x\n    #     '_3_71',    # x22-x    x23-x    x24-x\n    #     '_3_72',    # x22-x    x23-x    x24-x\n    #     '_3_73',    # x22-x    x23-x    x24-x\n    #     '_3_74',    # x22-x    x23-x    x24-x\n    #     '_3_75',    # x22-x    x23-x    x24-x\n    #     '_3_76',    # x22-x    x23-x    x24-x\n    #     '_3_77',    # x25-x    x26-x    x27-x\n    #     '_3_78',    # x25-x    x26-x    x27-x\n    #     '_3_79',    # x25-x    x26-x    x27-x\n    #     '_3_80',    # x25-x    x26-x    x27-x\n    #     '_3_81',    # x25-x    x26-x    x27-x\n    #     '_3_82',    # x28-x    x29-x    x30-x\n    #     '_3_83',    # x28-x    x29-x    x30-x\n    #     '_3_84',    # x28-x    x29-x    x30-x\n    #     '_3_85',    # x28-x    x29-x    x30-x\n    #     '_3_86',    # x31-x    x32-x    x33-x\n    #     '_3_87',    # x31-x    x32-x    x33-x\n    #     '_3_88',    # x31-x    x32-x    x33-x\n    #     '_3_89',    # x34-x    x35-x    x36-x\n    #     '_3_90',    # x34-x    x35-x    x36-x\n    #     '_3_91',    # x37-x    x38-x    x39-x\n]\n\nnew_num_cols = [\n    'x1',      # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'x2',      # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'x3',      # tbp_lv_H                - tbp_lv_Hext              abs\n    'x4',      # tbp_lv_L                - tbp_lv_Lext              abs\n    'x5',      # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'x6',      # tbp_lv_norm_border      + tbp_lv_symm_2axis    \n    'x7',      # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n    'x8',      # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'x9',      # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'x10',     # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'x11',     # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'x12',     # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'x13',     # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n    'x14',     # tbp_lv_stdL             / tbp_lv_Lext\n    'x15',     # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'x16',     # clin_size_long_diam_mm  * age_approx\n    'x17',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'x18',     # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'x19',     # border_complexity       + lesion_shape_index\n    'x20',     # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n    'x21',     # tbp_lv_areaMM2          + 1  np.log\n    'x22',     # clin_size_long_diam_mm  / age_approx\n    'x23',     # tbp_lv_H                + tbp_lv_Hext    / 2\n    'x24',     # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'x25',     # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'x26',     # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'x27',     # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n    'x28',     # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'x29',     # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'x30',     # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'x31',     # tbp_lv_norm_border      * tbp_lv_norm_color\n    'x32',\n    'x33',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'x34',     # tbp_lv_nevi_confidence  / age_approx\n    'x35',\n    'x36',     # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n    'x37',     # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'x38',     # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'x39',     # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'x40',     # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'x41',     # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'x42',     # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\nnew_num_cols2 = [    \n    '_7_1',    # x1-x8   x2-x9   x3-x10  x4-x11  x5-x12  x6-x13  x7-x14\n    '_7_2',    # x1-x15  x2-x16  x3-x17  x4-x18  x5-x19  x6-x20  x7-x21\n    '_7_3',    # x1-x22  x2-x23  x3-x24  x4-x25  x5-x26  x6-x27  x7-x28\n    '_7_4',    # x1-x29  x2-x30  x3-x31  x4-x32  x5-x33  x6-x34  x7-x35\n    '_7_5',    # x1-x36  x2-x37  x3-x38  x4-x39  x5-x40  x6-x41  x7-x42\n    '_7_6',    # x8-x15  x9-x16  x10-x17  x11-x18  x12-x19  x13-x20  x14-x21\n    '_7_7',    # x8-x22  x9-x23  x10-x24  x11-x25  x12-x26  x13-x27  x14-x28\n    '_7_8',    # x8-x29  x9-x30  x10-x31  x11-x32  x12-x33  x13-x34  x14-x35\n    '_7_9',    # x8-x36  x9-x37  x10-x38  x11-x39  x12-x40  x13-x41  x14-x42\n    '_7_10',   # x15-x22  x16-x23  x17-x24  x18-x25  x19-x26  x20-x27  x21-x28\n    '_7_11',   # x15-x29  x16-x30  x17-x31  x18-x32  x19-x33  x20-x34  x21-x35\n    '_7_12',   # x15-x36  x16-x37  x17-x38  x18-x39  x19-x40  x20-x41  x21-x42\n    '_7_13',   # x22-x29  x23-x30  x24-x31  x25-x32  x26-x33  x27-x34  x28-x35\n    '_7_14',   # x22-x36  x23-x37  x24-x38  x25-x39  x26-x40  x27-x41  x28-x42\n    '_7_15',   # x29-x36  x30-x37  x31-x38  x32-x39  x33-x40  x34-x41  x35-x42\n    \n    '_6_1',    # x1-x7   x2-x8   x3-x9   x4-x10  x5-x11  x6-x12\n    '_6_2',    # x1-x13  x2-x14  x3-x15  x4-x16  x5-x17  x6-x18\n    '_6_3',    # x1-x19  x2-x20  x3-x21  x4-x22  x5-x23  x6-x24\n    '_6_4',    # x1-x25  x2-x26  x3-x27  x4-x28  x5-x29  x6-x30\n    '_6_5',    # x1-x31  x2-x32  x3-x33  x4-x34  x5-x35  x6-x36\n    '_6_6',    # x1-x37  x2-x38  x3-x39  x4-x40  x5-x41  x6-x42\n    '_6_7',    # x7-x13  x8-x14  x9-x15  x10-x16  x11-x17  x12-x23\n    '_6_8',    # x7-x19  x8-x20  x9-x21  x10-x22  x11-x23  x12-x24\n    '_6_9',    # x7-x25  x8-x26  x9-x27  x10-x28  x11-x29  x12-x30\n    '_6_10',   # x7-x31  x8-x32  x9-x33  x10-x34  x11-x35  x12-x36\n    '_6_11',   # x7-x37  x8-x38  x9-x39  x10-x40  x11-x41  x12-x42\n    '_6_12',   # x13-x19  x14-x20  x15-x21  x16-x22  x17-x23  x18-x24\n    '_6_13',   # x13-x25  x14-x26  x15-x27  x16-x28  x17-x29  x18-x30\n    '_6_14',   # x13-x31  x14-x32  x15-x33  x16-x34  x17-x35  x18-x36\n    '_6_15',   # x13-x37  x14-x38  x15-x39  x16-x40  x17-x41  x18-x42\n    '_6_16',   # x19-x25  x20-x26  x21-x27  x22-x28  x23-x29  x24-x30\n    '_6_17',   # x19-x31  x20-x32  x21-x33  x22-x34  x23-x35  x24-x36\n    '_6_18',   # x19-x37  x20-x38  x21-x39  x22-x40  x23-x41  x24-x42\n    '_6_19',   # x25-x31  x26-x32  x27-x33  x28-x34  x29-x35  x30-x36\n    '_6_20',   # x25-x37  x26-x38  x27-x39  x28-x40  x29-x41  x30-x42\n    '_6_21',   # x31-x37  x32-x38  x33-x39  x34-x40  x35-x41  x36-x42\n    \n    '_5_1',    # x1-x6    x2-x7    x3-x8    x4-x9    x5-x10\n    '_5_2',    # x1-x11   x2-x12   x3-x13   x4-x14   x5-x15\n    '_5_3',    # x1-x16   x2-x17   x3-x18   x4-x19   x5-x20\n    '_5_4',    # x1-x21   x2-x22   x3-x23   x4-x24   x5-x25\n    '_5_5',    # x1-x26   x2-x27   x3-x28   x4-x29   x5-x30\n    '_5_6',    # x1-x31   x2-x32   x3-x33   x4-x34   x5-x35\n    '_5_7',    # x1-x36   x2-x37   x3-x38   x4-x39   x5-x40\n    '_5_8',    # x6-x11   x7-x12   x8-x13   x9-x14   x10-x15\n    '_5_9',    # x6-x16   x7-x17   x8-x18   x9-x19   x10-x20\n    '_5_10',   # x6-x21   x7-x22   x8-x23   x9-x24   x10-x25\n    '_5_11',   # x6-x26   x7-x27   x8-x28   x9-x29   x10-x30\n    '_5_12',   # x6-x31   x7-x32   x8-x33   x9-x34   x10-x35\n    '_5_13',   # x6-x36   x7-x37   x8-x38   x9-x39   x10-x40\n    '_5_14',   # x11-x16   x12-x17   x13-x18   x14-x19   x15-x20\n    '_5_15',   # x11-x21   x12-x22   x13-x23   x14-x24   x15-x25\n    '_5_16',   # x11-x26   x12-x27   x13-x28   x14-x29   x15-x30\n    '_5_17',   # x11-x31   x12-x32   x13-x33   x14-x34   x15-x35\n    '_5_18',   # x11-x36   x12-x37   x13-x38   x14-x39   x15-x40\n    '_5_19',   # x16-x21   x17-x22   x18-x23   x19-x24   x20-x25\n    '_5_20',   # x16-x26   x17-x27   x18-x28   x19-x29   x20-x30\n    '_5_21',   # x16-x31   x17-x32   x18-x33   x19-x34   x20-x35\n    '_5_22',   # x16-x36   x17-x37   x18-x38   x19-x39   x20-x40\n    '_5_23',   # x21-x26   x22-x27   x23-x28   x24-x29   x25-x30\n    '_5_24',   # x21-x31   x22-x32   x23-x33   x24-x34   x25-x35\n    '_5_25',   # x21-x36   x22-x37   x23-x38   x24-x39   x25-x40\n    '_5_26',   # x26-x31   x27-x32   x28-x33   x29-x34   x30-x35\n    '_5_27',   # x26-x36   x27-x37   x28-x38   x29-x39   x30-x40\n    '_5_28',   # x31-x36   x32-x37   x33-x38   x34-x39   x35-x40\n    \n    '_4_1',    # x1-x5    x2-x6    x3-x7    x4-x8    \n    '_4_2',    # x1-x9    x2-x10   x3-x11   x4-x12\n    '_4_3',    # x1-x13   x2-x14   x3-x15   x4-x16\n    '_4_4',    # x1-x17   x2-x18   x3-x19   x4-x20\n    '_4_5',    # x1-x21   x2-x22   x3-x23   x4-x24\n    '_4_6',    # x1-x25   x2-x26   x3-x27   x4-x28\n    '_4_7',    # x1-x29   x2-x30   x3-x31   x4-x32\n    '_4_8',    # x1-x33   x2-x34   x3-x35   x4-x36\n    '_4_9',    # x1-x37   x2-x38   x3-x39   x4-x40\n    '_4_10',   # x5-x9    x6-x10   x7-x11   x8-x12\n    '_4_11',   # x5-x13   x6-x14   x7-x15   x8-x16\n    '_4_12',   # x5-x17   x6-x18   x7-x19   x8-x20\n    '_4_13',   # x5-x21   x6-x22   x7-x23   x8-x24\n    '_4_14',   # x5-x25   x6-x26   x7-x27   x8-x28\n    '_4_15',   # x5-x29   x6-x30   x7-x31   x8-x32\n    '_4_16',   # x5-x33   x6-x34   x7-x35   x8-x36\n    '_4_17',   # x5-x37   x6-x38   x7-x39   x8-x40\n    '_4_18',   # x9-x13   x10-x14   x11-x15   x12-x16\n    '_4_19',   # x9-x17   x10-x18   x11-x19   x12-x20\n    '_4_20',   # x9-x21   x10-x22   x11-x23   x12-x24\n    '_4_21',   # x9-x25   x10-x26   x11-x27   x12-x28\n    '_4_22',   # x9-x29   x10-x30   x11-x31   x12-x32\n    '_4_23',   # x9-x33   x10-x34   x11-x35   x12-x36\n    '_4_24',   # x9-x37   x10-x38   x11-x39   x12-x40\n    '_4_25',   # x13-x17   x14-x18   x15-x19   x16-x20\n    '_4_26',   # x13-x21   x14-x22   x15-x23   x16-x24\n    '_4_27',   # x13-x25   x14-x26   x15-x27   x16-x28\n    '_4_28',   # x13-x29   x14-x30   x15-x31   x16-x32\n    '_4_29',   # x13-x33   x14-x34   x15-x35   x16-x36\n    '_4_30',   # x13-x37   x14-x38   x15-x39   x16-x40\n    '_4_31',   # x17-x21   x18-x22   x19-x23   x20-x24\n    '_4_32',   # x17-x25   x18-x26   x19-x27   x20-x28\n    '_4_33',   # x17-x29   x18-x30   x19-x31   x20-x32\n    '_4_34',   # x17-x33   x18-x34   x19-x35   x20-x36\n    '_4_35',   # x17-x37   x18-x38   x19-x39   x20-x40\n    '_4_36',   # x21-x25   x22-x26   x23-x27   x24-x28\n    '_4_37',   # x21-x29   x22-x30   x23-x31   x24-x32\n    '_4_38',   # x21-x33   x22-x34   x23-x35   x24-x36\n    '_4_39',   # x21-x37   x22-x38   x23-x39   x24-x40\n    '_4_40',   # x25-x29   x26-x30   x27-x31   x28-x32\n    '_4_41',   # x25-x33   x26-x34   x27-x35   x28-x36\n    '_4_42',   # x25-x37   x26-x38   x27-x39   x28-x40\n    '_4_43',   # x29-x33   x30-x34   x31-x35   x32-x36\n    '_4_44',   # x29-x37   x30-x38   x31-x39   x32-x40\n    '_4_45',   # x33-x37   x34-x38   x35-x39   x36-x40\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols + new_num_cols2]\nspecial_cols = ['count_per_patient']\nfeature_cols = num_cols + new_num_cols + new_num_cols2 + cat_cols + norm_cols + special_cols # ","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.411768Z","iopub.execute_input":"2024-09-09T06:56:16.412084Z","iopub.status.idle":"2024-09-09T06:56:16.445668Z","shell.execute_reply.started":"2024-09-09T06:56:16.412049Z","shell.execute_reply":"2024-09-09T06:56:16.444738Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            x1    = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            x2    = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            x3    = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            x4    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            x5    = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            x6    = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            x7    = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            x8    = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            x9    = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            x10   = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            x11   = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            xc1   = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            x12   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            x13   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            x14   = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            x15   = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            x16   = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            x17   = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            x18   = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            x19   = pl.col('x6') + pl.col('x2'),\n            x20   = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            x21   = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            x22   = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            x23   = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            x24   = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            x25   = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            x26   = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            x27   = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            x28   = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            x29   = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            x30   = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            x31   = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            x32   = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            x33   = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            x34   = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            x35   = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            x36   = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            x37   = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            x38   = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            x39   = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            x40   = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            x41   = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            x42   = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            _7_1  = ((pl.col('x1')-pl.col('x8'))**2 +(pl.col('x2')-pl.col('x9'))**2 +(pl.col('x3')-pl.col('x10'))**2+(pl.col('x4')-pl.col('x11'))**2+(pl.col('x5')-pl.col('x12'))**2+(pl.col('x6')-pl.col('x13'))**2+(pl.col('x7')-pl.col('x14'))**2).sqrt(),\n            _7_2  = ((pl.col('x1')-pl.col('x15'))**2+(pl.col('x2')-pl.col('x16'))**2+(pl.col('x3')-pl.col('x17'))**2+(pl.col('x4')-pl.col('x18'))**2+(pl.col('x5')-pl.col('x19'))**2+(pl.col('x6')-pl.col('x20'))**2+(pl.col('x7')-pl.col('x21'))**2).sqrt(),\n            _7_3  = ((pl.col('x1')-pl.col('x22'))**2+(pl.col('x2')-pl.col('x23'))**2+(pl.col('x3')-pl.col('x24'))**2+(pl.col('x4')-pl.col('x25'))**2+(pl.col('x5')-pl.col('x26'))**2+(pl.col('x6')-pl.col('x27'))**2+(pl.col('x7')-pl.col('x28'))**2).sqrt(),\n            _7_4  = ((pl.col('x1')-pl.col('x29'))**2+(pl.col('x2')-pl.col('x30'))**2+(pl.col('x3')-pl.col('x31'))**2+(pl.col('x4')-pl.col('x32'))**2+(pl.col('x5')-pl.col('x33'))**2+(pl.col('x6')-pl.col('x34'))**2+(pl.col('x7')-pl.col('x35'))**2).sqrt(),\n            _7_5  = ((pl.col('x1')-pl.col('x36'))**2+(pl.col('x2')-pl.col('x37'))**2+(pl.col('x3')-pl.col('x38'))**2+(pl.col('x4')-pl.col('x39'))**2+(pl.col('x5')-pl.col('x40'))**2+(pl.col('x6')-pl.col('x41'))**2+(pl.col('x7')-pl.col('x42'))**2).sqrt(),\n            _7_6  = ((pl.col('x8')-pl.col('x15'))**2+(pl.col('x9')-pl.col('x16'))**2+(pl.col('x10')-pl.col('x17'))**2+(pl.col('x11')-pl.col('x18'))**2+(pl.col('x12')-pl.col('x19'))**2+(pl.col('x13')-pl.col('x20'))**2+(pl.col('x14')-pl.col('x21'))**2).sqrt(),\n            _7_7  = ((pl.col('x8')-pl.col('x22'))**2+(pl.col('x9')-pl.col('x23'))**2+(pl.col('x10')-pl.col('x24'))**2+(pl.col('x11')-pl.col('x25'))**2+(pl.col('x12')-pl.col('x26'))**2+(pl.col('x13')-pl.col('x27'))**2+(pl.col('x14')-pl.col('x28'))**2).sqrt(),\n            _7_8  = ((pl.col('x8')-pl.col('x29'))**2+(pl.col('x9')-pl.col('x30'))**2+(pl.col('x10')-pl.col('x31'))**2+(pl.col('x11')-pl.col('x32'))**2+(pl.col('x12')-pl.col('x33'))**2+(pl.col('x13')-pl.col('x34'))**2+(pl.col('x14')-pl.col('x35'))**2).sqrt(),\n            _7_9  = ((pl.col('x8')-pl.col('x36'))**2+(pl.col('x9')-pl.col('x37'))**2+(pl.col('x10')-pl.col('x38'))**2+(pl.col('x11')-pl.col('x39'))**2+(pl.col('x12')-pl.col('x40'))**2+(pl.col('x13')-pl.col('x41'))**2+(pl.col('x14')-pl.col('x42'))**2).sqrt(),\n            _7_10 = ((pl.col('x15')-pl.col('x22'))**2+(pl.col('x16')-pl.col('x23'))**2+(pl.col('x17')-pl.col('x24'))**2+(pl.col('x18')-pl.col('x25'))**2+(pl.col('x19')-pl.col('x26'))**2+(pl.col('x20')-pl.col('x27'))**2+(pl.col('x21')-pl.col('x28'))**2).sqrt(),\n            _7_11 = ((pl.col('x15')-pl.col('x29'))**2+(pl.col('x16')-pl.col('x30'))**2+(pl.col('x17')-pl.col('x31'))**2+(pl.col('x18')-pl.col('x32'))**2+(pl.col('x19')-pl.col('x33'))**2+(pl.col('x20')-pl.col('x34'))**2+(pl.col('x21')-pl.col('x35'))**2).sqrt(),\n            _7_12 = ((pl.col('x15')-pl.col('x36'))**2+(pl.col('x16')-pl.col('x37'))**2+(pl.col('x17')-pl.col('x38'))**2+(pl.col('x18')-pl.col('x39'))**2+(pl.col('x19')-pl.col('x40'))**2+(pl.col('x20')-pl.col('x41'))**2+(pl.col('x21')-pl.col('x42'))**2).sqrt(),\n            _7_13 = ((pl.col('x22')-pl.col('x29'))**2+(pl.col('x23')-pl.col('x30'))**2+(pl.col('x24')-pl.col('x31'))**2+(pl.col('x25')-pl.col('x32'))**2+(pl.col('x26')-pl.col('x33'))**2+(pl.col('x27')-pl.col('x34'))**2+(pl.col('x28')-pl.col('x35'))**2).sqrt(),\n            _7_14 = ((pl.col('x22')-pl.col('x36'))**2+(pl.col('x23')-pl.col('x37'))**2+(pl.col('x24')-pl.col('x38'))**2+(pl.col('x25')-pl.col('x39'))**2+(pl.col('x26')-pl.col('x40'))**2+(pl.col('x27')-pl.col('x41'))**2+(pl.col('x28')-pl.col('x42'))**2).sqrt(),\n            _7_15 = ((pl.col('x29')-pl.col('x36'))**2+(pl.col('x30')-pl.col('x37'))**2+(pl.col('x31')-pl.col('x38'))**2+(pl.col('x32')-pl.col('x39'))**2+(pl.col('x33')-pl.col('x40'))**2+(pl.col('x34')-pl.col('x41'))**2+(pl.col('x35')-pl.col('x42'))**2).sqrt(),\n        )\n                           #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n        .with_columns(\n            _6_1  = ((pl.col('x1')-pl.col('x7'))**2+(pl.col('x2')-pl.col('x8'))**2+(pl.col('x3')-pl.col('x9'))**2+(pl.col('x4')-pl.col('x10'))**2+(pl.col('x5')-pl.col('x11'))**2+(pl.col('x6')-pl.col('x12'))**2).sqrt(),\n            _6_2  = ((pl.col('x1')-pl.col('x13'))**2+(pl.col('x2')-pl.col('x14'))**2+(pl.col('x3')-pl.col('x15'))**2+(pl.col('x4')-pl.col('x16'))**2+(pl.col('x5')-pl.col('x17'))**2+(pl.col('x6')-pl.col('x18'))**2).sqrt(),\n            _6_3  = ((pl.col('x1')-pl.col('x19'))**2+(pl.col('x2')-pl.col('x20'))**2+(pl.col('x3')-pl.col('x21'))**2+(pl.col('x4')-pl.col('x22'))**2+(pl.col('x5')-pl.col('x23'))**2+(pl.col('x6')-pl.col('x24'))**2).sqrt(),\n            _6_4  = ((pl.col('x1')-pl.col('x25'))**2+(pl.col('x2')-pl.col('x26'))**2+(pl.col('x3')-pl.col('x27'))**2+(pl.col('x4')-pl.col('x28'))**2+(pl.col('x5')-pl.col('x29'))**2+(pl.col('x6')-pl.col('x30'))**2).sqrt(),\n            _6_5  = ((pl.col('x1')-pl.col('x31'))**2+(pl.col('x2')-pl.col('x32'))**2+(pl.col('x3')-pl.col('x33'))**2+(pl.col('x4')-pl.col('x34'))**2+(pl.col('x5')-pl.col('x35'))**2+(pl.col('x6')-pl.col('x36'))**2).sqrt(),\n            _6_6  = ((pl.col('x1')-pl.col('x37'))**2+(pl.col('x2')-pl.col('x38'))**2+(pl.col('x3')-pl.col('x39'))**2+(pl.col('x4')-pl.col('x40'))**2+(pl.col('x5')-pl.col('x41'))**2+(pl.col('x6')-pl.col('x42'))**2).sqrt(),\n            _6_7  = ((pl.col('x7')-pl.col('x13'))**2+(pl.col('x8')-pl.col('x14'))**2+(pl.col('x9')-pl.col('x15'))**2+(pl.col('x10')-pl.col('x16'))**2+(pl.col('x11')-pl.col('x17'))**2+(pl.col('x12')-pl.col('x23'))**2).sqrt(),\n            _6_8  = ((pl.col('x7')-pl.col('x19'))**2+(pl.col('x8')-pl.col('x20'))**2+(pl.col('x9')-pl.col('x21'))**2+(pl.col('x10')-pl.col('x22'))**2+(pl.col('x11')-pl.col('x23'))**2+(pl.col('x12')-pl.col('x24'))**2).sqrt(),\n            _6_9  = ((pl.col('x7')-pl.col('x25'))**2+(pl.col('x8')-pl.col('x26'))**2+(pl.col('x9')-pl.col('x27'))**2+(pl.col('x10')-pl.col('x28'))**2+(pl.col('x11')-pl.col('x29'))**2+(pl.col('x12')-pl.col('x30'))**2).sqrt(),\n            _6_10 = ((pl.col('x7')-pl.col('x31'))**2+(pl.col('x8')-pl.col('x32'))**2+(pl.col('x9')-pl.col('x33'))**2+(pl.col('x10')-pl.col('x34'))**2+(pl.col('x11')-pl.col('x35'))**2+(pl.col('x12')-pl.col('x36'))**2).sqrt(),\n            _6_11 = ((pl.col('x7')-pl.col('x37'))**2+(pl.col('x8')-pl.col('x38'))**2+(pl.col('x9')-pl.col('x39'))**2+(pl.col('x10')-pl.col('x40'))**2+(pl.col('x11')-pl.col('x41'))**2+(pl.col('x12')-pl.col('x42'))**2).sqrt(),\n            _6_12 = ((pl.col('x13')-pl.col('x19'))**2+(pl.col('x14')-pl.col('x20'))**2+(pl.col('x15')-pl.col('x21'))**2+(pl.col('x16')-pl.col('x22'))**2+(pl.col('x17')-pl.col('x23'))**2+(pl.col('x18')-pl.col('x24'))**2).sqrt(),\n            _6_13 = ((pl.col('x13')-pl.col('x25'))**2+(pl.col('x14')-pl.col('x26'))**2+(pl.col('x15')-pl.col('x27'))**2+(pl.col('x16')-pl.col('x28'))**2+(pl.col('x17')-pl.col('x29'))**2+(pl.col('x18')-pl.col('x30'))**2).sqrt(),\n            _6_14 = ((pl.col('x13')-pl.col('x31'))**2+(pl.col('x14')-pl.col('x32'))**2+(pl.col('x15')-pl.col('x33'))**2+(pl.col('x16')-pl.col('x34'))**2+(pl.col('x17')-pl.col('x35'))**2+(pl.col('x18')-pl.col('x36'))**2).sqrt(),\n            _6_15 = ((pl.col('x13')-pl.col('x37'))**2+(pl.col('x14')-pl.col('x38'))**2+(pl.col('x15')-pl.col('x39'))**2+(pl.col('x16')-pl.col('x40'))**2+(pl.col('x17')-pl.col('x41'))**2+(pl.col('x18')-pl.col('x42'))**2).sqrt(),\n            _6_16 = ((pl.col('x19')-pl.col('x25'))**2+(pl.col('x20')-pl.col('x26'))**2+(pl.col('x21')-pl.col('x27'))**2+(pl.col('x22')-pl.col('x28'))**2+(pl.col('x23')-pl.col('x29'))**2+(pl.col('x24')-pl.col('x30'))**2).sqrt(),\n            _6_17 = ((pl.col('x19')-pl.col('x31'))**2+(pl.col('x20')-pl.col('x32'))**2+(pl.col('x21')-pl.col('x33'))**2+(pl.col('x22')-pl.col('x34'))**2+(pl.col('x23')-pl.col('x35'))**2+(pl.col('x24')-pl.col('x36'))**2).sqrt(),\n            _6_18 = ((pl.col('x19')-pl.col('x37'))**2+(pl.col('x20')-pl.col('x38'))**2+(pl.col('x21')-pl.col('x39'))**2+(pl.col('x22')-pl.col('x40'))**2+(pl.col('x23')-pl.col('x41'))**2+(pl.col('x24')-pl.col('x42'))**2).sqrt(),\n            _6_19 = ((pl.col('x25')-pl.col('x31'))**2+(pl.col('x26')-pl.col('x32'))**2+(pl.col('x27')-pl.col('x33'))**2+(pl.col('x28')-pl.col('x34'))**2+(pl.col('x29')-pl.col('x35'))**2+(pl.col('x30')-pl.col('x36'))**2).sqrt(),\n            _6_20 = ((pl.col('x25')-pl.col('x37'))**2+(pl.col('x26')-pl.col('x38'))**2+(pl.col('x27')-pl.col('x39'))**2+(pl.col('x28')-pl.col('x40'))**2+(pl.col('x29')-pl.col('x41'))**2+(pl.col('x30')-pl.col('x42'))**2).sqrt(),\n            _6_21 = ((pl.col('x31')-pl.col('x37'))**2+(pl.col('x32')-pl.col('x38'))**2+(pl.col('x33')-pl.col('x39'))**2+(pl.col('x34')-pl.col('x40'))**2+(pl.col('x35')-pl.col('x41'))**2+(pl.col('x36')-pl.col('x42'))**2).sqrt(),\n        )                    \n# #                            #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n        .with_columns(  \n            _5_1  = ((pl.col('x1')-pl.col('x6'))**2 +(pl.col('x2')-pl.col('x7'))**2 +(pl.col('x3')-pl.col('x8'))**2 +(pl.col('x4')-pl.col('x9'))**2 +(pl.col('x5')-pl.col('x10'))**2).sqrt(),\n            _5_2  = ((pl.col('x1')-pl.col('x11'))**2+(pl.col('x2')-pl.col('x12'))**2+(pl.col('x3')-pl.col('x13'))**2+(pl.col('x4')-pl.col('x14'))**2+(pl.col('x5')-pl.col('x15'))**2).sqrt(),\n            _5_3  = ((pl.col('x1')-pl.col('x16'))**2+(pl.col('x2')-pl.col('x17'))**2+(pl.col('x3')-pl.col('x18'))**2+(pl.col('x4')-pl.col('x19'))**2+(pl.col('x5')-pl.col('x20'))**2).sqrt(),\n            _5_4  = ((pl.col('x1')-pl.col('x21'))**2+(pl.col('x2')-pl.col('x22'))**2+(pl.col('x3')-pl.col('x23'))**2+(pl.col('x4')-pl.col('x24'))**2+(pl.col('x5')-pl.col('x25'))**2).sqrt(),\n            _5_5  = ((pl.col('x1')-pl.col('x26'))**2+(pl.col('x2')-pl.col('x27'))**2+(pl.col('x3')-pl.col('x28'))**2+(pl.col('x4')-pl.col('x29'))**2+(pl.col('x5')-pl.col('x30'))**2).sqrt(),\n            _5_6  = ((pl.col('x1')-pl.col('x31'))**2+(pl.col('x2')-pl.col('x32'))**2+(pl.col('x3')-pl.col('x33'))**2+(pl.col('x4')-pl.col('x34'))**2+(pl.col('x5')-pl.col('x35'))**2).sqrt(),\n            _5_7  = ((pl.col('x1')-pl.col('x36'))**2+(pl.col('x2')-pl.col('x37'))**2+(pl.col('x3')-pl.col('x38'))**2+(pl.col('x4')-pl.col('x39'))**2+(pl.col('x5')-pl.col('x40'))**2).sqrt(),\n            _5_8  = ((pl.col('x6')-pl.col('x11'))**2+(pl.col('x7')-pl.col('x12'))**2+(pl.col('x8')-pl.col('x13'))**2+(pl.col('x9')-pl.col('x14'))**2+(pl.col('x10')-pl.col('x15'))**2).sqrt(),\n            _5_9  = ((pl.col('x6')-pl.col('x16'))**2+(pl.col('x7')-pl.col('x17'))**2+(pl.col('x8')-pl.col('x18'))**2+(pl.col('x9')-pl.col('x19'))**2+(pl.col('x10')-pl.col('x20'))**2).sqrt(),\n            _5_10 = ((pl.col('x6')-pl.col('x21'))**2+(pl.col('x7')-pl.col('x22'))**2+(pl.col('x8')-pl.col('x23'))**2+(pl.col('x9')-pl.col('x24'))**2+(pl.col('x10')-pl.col('x25'))**2).sqrt(),\n            _5_11 = ((pl.col('x6')-pl.col('x26'))**2+(pl.col('x7')-pl.col('x27'))**2+(pl.col('x8')-pl.col('x28'))**2+(pl.col('x9')-pl.col('x29'))**2+(pl.col('x10')-pl.col('x30'))**2).sqrt(),\n            _5_12 = ((pl.col('x6')-pl.col('x31'))**2+(pl.col('x7')-pl.col('x32'))**2+(pl.col('x8')-pl.col('x33'))**2+(pl.col('x9')-pl.col('x34'))**2+(pl.col('x10')-pl.col('x35'))**2).sqrt(),\n            _5_13 = ((pl.col('x6')-pl.col('x36'))**2+(pl.col('x7')-pl.col('x37'))**2+(pl.col('x8')-pl.col('x38'))**2+(pl.col('x9')-pl.col('x39'))**2+(pl.col('x10')-pl.col('x40'))**2).sqrt(),\n            _5_14 = ((pl.col('x11')-pl.col('x16'))**2+(pl.col('x12')-pl.col('x17'))**2+(pl.col('x13')-pl.col('x18'))**2+(pl.col('x14')-pl.col('x19'))**2+(pl.col('x15')-pl.col('x20'))**2).sqrt(),\n            _5_15 = ((pl.col('x11')-pl.col('x21'))**2+(pl.col('x12')-pl.col('x22'))**2+(pl.col('x13')-pl.col('x23'))**2+(pl.col('x14')-pl.col('x24'))**2+(pl.col('x15')-pl.col('x25'))**2).sqrt(),\n            _5_16 = ((pl.col('x11')-pl.col('x26'))**2+(pl.col('x12')-pl.col('x27'))**2+(pl.col('x13')-pl.col('x28'))**2+(pl.col('x14')-pl.col('x29'))**2+(pl.col('x15')-pl.col('x30'))**2).sqrt(),\n            _5_17 = ((pl.col('x11')-pl.col('x31'))**2+(pl.col('x12')-pl.col('x32'))**2+(pl.col('x13')-pl.col('x33'))**2+(pl.col('x14')-pl.col('x34'))**2+(pl.col('x15')-pl.col('x35'))**2).sqrt(),\n            _5_18 = ((pl.col('x11')-pl.col('x36'))**2+(pl.col('x12')-pl.col('x37'))**2+(pl.col('x13')-pl.col('x38'))**2+(pl.col('x14')-pl.col('x39'))**2+(pl.col('x15')-pl.col('x40'))**2).sqrt(),\n            _5_19 = ((pl.col('x16')-pl.col('x21'))**2+(pl.col('x17')-pl.col('x22'))**2+(pl.col('x18')-pl.col('x23'))**2+(pl.col('x19')-pl.col('x24'))**2+(pl.col('x20')-pl.col('x25'))**2).sqrt(),\n            _5_20 = ((pl.col('x16')-pl.col('x26'))**2+(pl.col('x17')-pl.col('x27'))**2+(pl.col('x18')-pl.col('x28'))**2+(pl.col('x19')-pl.col('x29'))**2+(pl.col('x20')-pl.col('x30'))**2).sqrt(),\n            _5_21 = ((pl.col('x16')-pl.col('x31'))**2+(pl.col('x17')-pl.col('x32'))**2+(pl.col('x18')-pl.col('x33'))**2+(pl.col('x19')-pl.col('x34'))**2+(pl.col('x20')-pl.col('x35'))**2).sqrt(),\n            _5_22 = ((pl.col('x16')-pl.col('x36'))**2+(pl.col('x17')-pl.col('x37'))**2+(pl.col('x18')-pl.col('x38'))**2+(pl.col('x19')-pl.col('x39'))**2+(pl.col('x20')-pl.col('x40'))**2).sqrt(),\n            _5_23 = ((pl.col('x21')-pl.col('x26'))**2+(pl.col('x22')-pl.col('x27'))**2+(pl.col('x23')-pl.col('x28'))**2+(pl.col('x24')-pl.col('x29'))**2+(pl.col('x25')-pl.col('x30'))**2).sqrt(),\n            _5_24 = ((pl.col('x21')-pl.col('x31'))**2+(pl.col('x22')-pl.col('x32'))**2+(pl.col('x23')-pl.col('x33'))**2+(pl.col('x24')-pl.col('x34'))**2+(pl.col('x25')-pl.col('x35'))**2).sqrt(),\n            _5_25 = ((pl.col('x21')-pl.col('x36'))**2+(pl.col('x22')-pl.col('x37'))**2+(pl.col('x23')-pl.col('x38'))**2+(pl.col('x24')-pl.col('x39'))**2+(pl.col('x25')-pl.col('x40'))**2).sqrt(),\n            _5_26 = ((pl.col('x26')-pl.col('x31'))**2+(pl.col('x27')-pl.col('x32'))**2+(pl.col('x28')-pl.col('x33'))**2+(pl.col('x29')-pl.col('x34'))**2+(pl.col('x30')-pl.col('x35'))**2).sqrt(),\n            _5_27 = ((pl.col('x26')-pl.col('x36'))**2+(pl.col('x27')-pl.col('x37'))**2+(pl.col('x28')-pl.col('x38'))**2+(pl.col('x29')-pl.col('x39'))**2+(pl.col('x30')-pl.col('x40'))**2).sqrt(),\n            _5_28 = ((pl.col('x31')-pl.col('x36'))**2+(pl.col('x32')-pl.col('x37'))**2+(pl.col('x33')-pl.col('x38'))**2+(pl.col('x34')-pl.col('x39'))**2+(pl.col('x35')-pl.col('x40'))**2).sqrt(),\n        )\n        .with_columns(        #  = ((pl.col('    ')-pl.col('   '))**2+(pl.col('   '))**2).sqrt(),\n            _4_1 = ((pl.col('x1')-pl.col('x5'))**2+(pl.col('x2')-pl.col('x6'))**2+(pl.col('x3')-pl.col('x7'))**2+(pl.col('x4')-pl.col('x8'))**2).sqrt(),    \n            _4_2 = ((pl.col('x1')-pl.col('x9'))**2+(pl.col('x2')-pl.col('x10'))**2+(pl.col('x3')-pl.col('x11'))**2+(pl.col('x4')-pl.col('x12'))**2).sqrt(),\n            _4_3 = ((pl.col('x1')-pl.col('x13'))**2+(pl.col('x2')-pl.col('x14'))**2+(pl.col('x3')-pl.col('x15'))**2+(pl.col('x4')-pl.col('x16'))**2).sqrt(),\n            _4_4 = ((pl.col('x1')-pl.col('x17'))**2+(pl.col('x2')-pl.col('x18'))**2+(pl.col('x3')-pl.col('x19'))**2+(pl.col('x4')-pl.col('x20'))**2).sqrt(),\n            _4_5 = ((pl.col('x1')-pl.col('x21'))**2+(pl.col('x2')-pl.col('x22'))**2+(pl.col('x3')-pl.col('x23'))**2+(pl.col('x4')-pl.col('x24'))**2).sqrt(),\n            _4_6 = ((pl.col('x1')-pl.col('x25'))**2+(pl.col('x2')-pl.col('x26'))**2+(pl.col('x3')-pl.col('x27'))**2+(pl.col('x4')-pl.col('x28'))**2).sqrt(),\n            _4_7 = ((pl.col('x1')-pl.col('x29'))**2+(pl.col('x2')-pl.col('x30'))**2+(pl.col('x3')-pl.col('x31'))**2+(pl.col('x4')-pl.col('x32'))**2).sqrt(),\n            _4_8 = ((pl.col('x1')-pl.col('x33'))**2+(pl.col('x2')-pl.col('x34'))**2+(pl.col('x3')-pl.col('x35'))**2+(pl.col('x4')-pl.col('x36'))**2).sqrt(),\n            _4_9 = ((pl.col('x1')-pl.col('x37'))**2+(pl.col('x2')-pl.col('x38'))**2+(pl.col('x3')-pl.col('x39'))**2+(pl.col('x4')-pl.col('x40'))**2).sqrt(),\n            _4_10 = ((pl.col('x5')-pl.col('x9'))**2+(pl.col('x6')-pl.col('x10'))**2+(pl.col('x7')-pl.col('x11'))**2+(pl.col('x8')-pl.col('x12'))**2).sqrt(),\n            _4_11 = ((pl.col('x5')-pl.col('x13'))**2+(pl.col('x6')-pl.col('x14'))**2+(pl.col('x7')-pl.col('x15'))**2+(pl.col('x8')-pl.col('x16'))**2).sqrt(),\n            _4_12 = ((pl.col('x5')-pl.col('x17'))**2+(pl.col('x6')-pl.col('x18'))**2+(pl.col('x7')-pl.col('x19'))**2+(pl.col('x8')-pl.col('x20'))**2).sqrt(),\n            _4_13 = ((pl.col('x5')-pl.col('x21'))**2+(pl.col('x6')-pl.col('x22'))**2+(pl.col('x7')-pl.col('x23'))**2+(pl.col('x8')-pl.col('x24'))**2).sqrt(),\n            _4_14 = ((pl.col('x5')-pl.col('x25'))**2+(pl.col('x6')-pl.col('x26'))**2+(pl.col('x7')-pl.col('x27'))**2+(pl.col('x8')-pl.col('x28'))**2).sqrt(),\n            _4_15 = ((pl.col('x5')-pl.col('x29'))**2+(pl.col('x6')-pl.col('x30'))**2+(pl.col('x7')-pl.col('x31'))**2+(pl.col('x8')-pl.col('x32'))**2).sqrt(),\n            _4_16 = ((pl.col('x5')-pl.col('x33'))**2+(pl.col('x6')-pl.col('x34'))**2+(pl.col('x7')-pl.col('x35'))**2+(pl.col('x8')-pl.col('x36'))**2).sqrt(),\n            _4_17 = ((pl.col('x5')-pl.col('x37'))**2+(pl.col('x6')-pl.col('x38'))**2+(pl.col('x7')-pl.col('x39'))**2+(pl.col('x8')-pl.col('x40'))**2).sqrt(),\n            _4_18 = ((pl.col('x9')-pl.col('x13'))**2+(pl.col('x10')-pl.col('x14'))**2+(pl.col('x11')-pl.col('x15'))**2+(pl.col('x12')-pl.col('x16'))**2).sqrt(),\n            _4_19 = ((pl.col('x9')-pl.col('x17'))**2+(pl.col('x10')-pl.col('x18'))**2+(pl.col('x11')-pl.col('x19'))**2+(pl.col('x12')-pl.col('x20'))**2).sqrt(),\n            _4_20 = ((pl.col('x9')-pl.col('x21'))**2+(pl.col('x10')-pl.col('x22'))**2+(pl.col('x11')-pl.col('x23'))**2+(pl.col('x12')-pl.col('x24'))**2).sqrt(),\n            _4_21 = ((pl.col('x9')-pl.col('x25'))**2+(pl.col('x10')-pl.col('x26'))**2+(pl.col('x11')-pl.col('x27'))**2+(pl.col('x12')-pl.col('x28'))**2).sqrt(),\n            _4_22 = ((pl.col('x9')-pl.col('x29'))**2+(pl.col('x10')-pl.col('x30'))**2+(pl.col('x11')-pl.col('x31'))**2+(pl.col('x12')-pl.col('x32'))**2).sqrt(),\n            _4_23 = ((pl.col('x9')-pl.col('x33'))**2+(pl.col('x10')-pl.col('x34'))**2+(pl.col('x11')-pl.col('x35'))**2+(pl.col('x12')-pl.col('x36'))**2).sqrt(),\n            _4_24 = ((pl.col('x9')-pl.col('x37'))**2+(pl.col('x10')-pl.col('x38'))**2+(pl.col('x11')-pl.col('x39'))**2+(pl.col('x12')-pl.col('x40'))**2).sqrt(),\n            _4_25 = ((pl.col('x13')-pl.col('x17'))**2+(pl.col('x14')-pl.col('x18'))**2+(pl.col('x15')-pl.col('x19'))**2+(pl.col('x16')-pl.col('x20'))**2).sqrt(),\n            _4_26 = ((pl.col('x13')-pl.col('x21'))**2+(pl.col('x14')-pl.col('x22'))**2+(pl.col('x15')-pl.col('x23'))**2+(pl.col('x16')-pl.col('x24'))**2).sqrt(),\n            _4_27 = ((pl.col('x13')-pl.col('x25'))**2+(pl.col('x14')-pl.col('x26'))**2+(pl.col('x15')-pl.col('x27'))**2+(pl.col('x16')-pl.col('x28'))**2).sqrt(),\n            _4_28 = ((pl.col('x13')-pl.col('x29'))**2+(pl.col('x14')-pl.col('x30'))**2+(pl.col('x15')-pl.col('x31'))**2+(pl.col('x16')-pl.col('x32'))**2).sqrt(),\n            _4_29 = ((pl.col('x13')-pl.col('x33'))**2+(pl.col('x14')-pl.col('x34'))**2+(pl.col('x15')-pl.col('x35'))**2+(pl.col('x16')-pl.col('x36'))**2).sqrt(),\n            _4_30 = ((pl.col('x13')-pl.col('x37'))**2+(pl.col('x14')-pl.col('x38'))**2+(pl.col('x15')-pl.col('x39'))**2+(pl.col('x16')-pl.col('x40'))**2).sqrt(),\n            _4_31 = ((pl.col('x17')-pl.col('x21'))**2+(pl.col('x18')-pl.col('x22'))**2+(pl.col('x19')-pl.col('x23'))**2+(pl.col('x20')-pl.col('x24'))**2).sqrt(),\n            _4_32 = ((pl.col('x17')-pl.col('x25'))**2+(pl.col('x18')-pl.col('x26'))**2+(pl.col('x19')-pl.col('x27'))**2+(pl.col('x20')-pl.col('x28'))**2).sqrt(),\n            _4_33 = ((pl.col('x17')-pl.col('x29'))**2+(pl.col('x18')-pl.col('x30'))**2+(pl.col('x19')-pl.col('x31'))**2+(pl.col('x20')-pl.col('x32'))**2).sqrt(),\n            _4_34 = ((pl.col('x17')-pl.col('x33'))**2+(pl.col('x18')-pl.col('x34'))**2+(pl.col('x19')-pl.col('x35'))**2+(pl.col('x20')-pl.col('x36'))**2).sqrt(),\n            _4_35 = ((pl.col('x17')-pl.col('x37'))**2+(pl.col('x18')-pl.col('x38'))**2+(pl.col('x19')-pl.col('x39'))**2+(pl.col('x20')-pl.col('x40'))**2).sqrt(),\n            _4_36 = ((pl.col('x21')-pl.col('x25'))**2+(pl.col('x22')-pl.col('x26'))**2+(pl.col('x23')-pl.col('x27'))**2+(pl.col('x24')-pl.col('x28'))**2).sqrt(),\n            _4_37 = ((pl.col('x21')-pl.col('x29'))**2+(pl.col('x22')-pl.col('x30'))**2+(pl.col('x23')-pl.col('x31'))**2+(pl.col('x24')-pl.col('x32'))**2).sqrt(),\n            _4_38 = ((pl.col('x21')-pl.col('x33'))**2+(pl.col('x22')-pl.col('x34'))**2+(pl.col('x23')-pl.col('x35'))**2+(pl.col('x24')-pl.col('x36'))**2).sqrt(),\n            _4_39 = ((pl.col('x21')-pl.col('x37'))**2+(pl.col('x22')-pl.col('x38'))**2+(pl.col('x23')-pl.col('x39'))**2+(pl.col('x24')-pl.col('x40'))**2).sqrt(),\n            _4_40 = ((pl.col('x25')-pl.col('x29'))**2+(pl.col('x26')-pl.col('x30'))**2+(pl.col('x27')-pl.col('x31'))**2+(pl.col('x28')-pl.col('x32'))**2).sqrt(),\n            _4_41 = ((pl.col('x25')-pl.col('x33'))**2+(pl.col('x26')-pl.col('x34'))**2+(pl.col('x27')-pl.col('x35'))**2+(pl.col('x28')-pl.col('x36'))**2).sqrt(),\n            _4_42 = ((pl.col('x25')-pl.col('x37'))**2+(pl.col('x26')-pl.col('x38'))**2+(pl.col('x27')-pl.col('x39'))**2+(pl.col('x28')-pl.col('x40'))**2).sqrt(),\n            _4_43 = ((pl.col('x29')-pl.col('x33'))**2+(pl.col('x30')-pl.col('x34'))**2+(pl.col('x31')-pl.col('x35'))**2+(pl.col('x32')-pl.col('x36'))**2).sqrt(),\n            _4_44 = ((pl.col('x29')-pl.col('x37'))**2+(pl.col('x30')-pl.col('x38'))**2+(pl.col('x31')-pl.col('x39'))**2+(pl.col('x32')-pl.col('x40'))**2).sqrt(),\n            _4_45 = ((pl.col('x33')-pl.col('x37'))**2+(pl.col('x34')-pl.col('x38'))**2+(pl.col('x35')-pl.col('x39'))**2+(pl.col('x36')-pl.col('x40'))**2).sqrt(),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols + new_num_cols2)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.447321Z","iopub.execute_input":"2024-09-09T06:56:16.447647Z","iopub.status.idle":"2024-09-09T06:56:16.656527Z","shell.execute_reply.started":"2024-09-09T06:56:16.447611Z","shell.execute_reply":"2024-09-09T06:56:16.655606Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.657923Z","iopub.execute_input":"2024-09-09T06:56:16.658670Z","iopub.status.idle":"2024-09-09T06:56:16.670118Z","shell.execute_reply.started":"2024-09-09T06:56:16.658623Z","shell.execute_reply":"2024-09-09T06:56:16.669162Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.671475Z","iopub.execute_input":"2024-09-09T06:56:16.671862Z","iopub.status.idle":"2024-09-09T06:56:16.683679Z","shell.execute_reply.started":"2024-09-09T06:56:16.671816Z","shell.execute_reply":"2024-09-09T06:56:16.682627Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_test = preprocess(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:16.684985Z","iopub.execute_input":"2024-09-09T06:56:16.685502Z","iopub.status.idle":"2024-09-09T06:56:25.876205Z","shell.execute_reply.started":"2024-09-09T06:56:16.685444Z","shell.execute_reply":"2024-09-09T06:56:25.874659Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#they are detected at the first run\nleast_important_features = ['onehot_32', 'onehot_6', 'onehot_33', 'onehot_30', 'onehot_26', 'onehot_22', 'onehot_36', 'onehot_4']\n#they are detected after the least_important_features are removed and it has increased cv score also so I add it\n#least_important_features_2 = ['onehot_17', 'onehot_42', 'onehot_29', 'onehot_13', 'onehot_25']\n#least_important_features += least_important_features_2\ndf_train.drop(columns =least_important_features,inplace = True)\nfor feature in least_important_features:\n    cat_cols.remove(feature)\n    feature_cols.remove(feature)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:25.878095Z","iopub.execute_input":"2024-09-09T06:56:25.878588Z","iopub.status.idle":"2024-09-09T06:56:26.264793Z","shell.execute_reply.started":"2024-09-09T06:56:25.878534Z","shell.execute_reply":"2024-09-09T06:56:26.263957Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           250,\n    'boosting_type':    'gbdt',\n    'random_state':     seed,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\nlgb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:26.265967Z","iopub.execute_input":"2024-09-09T06:56:26.266351Z","iopub.status.idle":"2024-09-09T06:56:26.273814Z","shell.execute_reply.started":"2024-09-09T06:56:26.266300Z","shell.execute_reply":"2024-09-09T06:56:26.272858Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        250,\n    'verbose':           False,\n    'random_state':      seed,\n    'max_depth':         7, \n    'learning_rate':     0.07, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24,\n    'cat_features':      cat_cols,\n}\n\ncb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', cb.CatBoostClassifier(**cb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:26.275120Z","iopub.execute_input":"2024-09-09T06:56:26.275744Z","iopub.status.idle":"2024-09-09T06:56:26.287829Z","shell.execute_reply.started":"2024-09-09T06:56:26.275700Z","shell.execute_reply":"2024-09-09T06:56:26.287010Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'enable_categorical': True,\n    'tree_method':        'hist',\n    'random_state':       seed,\n    'learning_rate':      0.08501257473292347, \n    'lambda':             8.879624125465703, \n    'alpha':              0.6779926606782505, \n    'max_depth':          6, \n    'subsample':          0.6012681388711075, \n    'colsample_bytree':   0.8437772277074493, \n    'colsample_bylevel':  0.5476090898823716, \n    'colsample_bynode':   0.9928601203635129, \n    'scale_pos_weight':   3.29440313334688,\n}\n\nxgb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', xgb.XGBClassifier(**xgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:26.289089Z","iopub.execute_input":"2024-09-09T06:56:26.289713Z","iopub.status.idle":"2024-09-09T06:56:26.299137Z","shell.execute_reply.started":"2024-09-09T06:56:26.289668Z","shell.execute_reply":"2024-09-09T06:56:26.298186Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"estimator = VotingClassifier([\n    ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n], voting='soft', weights=[0.50,0.40,0.15])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:26.300278Z","iopub.execute_input":"2024-09-09T06:56:26.300595Z","iopub.status.idle":"2024-09-09T06:56:26.312306Z","shell.execute_reply.started":"2024-09-09T06:56:26.300555Z","shell.execute_reply":"2024-09-09T06:56:26.311334Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X = df_train[feature_cols]\ny = df_train[target_col]\ngroups = df_train[group_col]\ncv = StratifiedGroupKFold(10, shuffle=True, random_state=seed)\n\nval_score = cross_val_score(\n    estimator=estimator, \n    X=X, y=y, \n    cv=cv, \n    groups=groups,\n    scoring=custom_metric,\n)\n\nnp.mean(val_score), val_score","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:56:26.313454Z","iopub.execute_input":"2024-09-09T06:56:26.313738Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# 0.1646452862152964, array([0.16646449, 0.16233454, 0.18117699, 0.15594694, 0.15730347]))\n# 0.17108539569350173,array([0.16736593, 0.17469648, 0.18511761, 0.16641646, 0.1618305 ]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = df_train[feature_cols], df_train[target_col]\n\nestimator.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_subm['target'] = estimator.predict_proba(df_test[feature_cols])[:, 1]\n\ndf_subm.to_csv('submission_2.csv')\ndf_subm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas.api.types\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n\nimport lightgbm as lgb\nfrom scipy.stats import zscore\nfrom numpy import nanmean, nanstd\nnp.seterr(invalid='ignore')\n\nimport copy\nimport os","metadata":{"papermill":{"duration":5.153457,"end_time":"2024-09-04T03:59:17.463407","exception":false,"start_time":"2024-09-04T03:59:12.30995","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This notebook adds accumulated noise in an effort to boost LB score...\n\n# This is an effort to intentionally OVERFIT to the LB using this strategy:\n* See https://www.kaggle.com/code/richolson/isic-2024-shake-up-lb-overfitting-simulator\n\n# THIS WILL RESULT IN OVERFITTING AND A BAD FINAL SCORE!\n* Note to self: Manually select other notebooks for competition scoring...\n\n# Before adding \"magic noise\" - it scores .184\n* The further above .184 it scores on the LB - the worse it is likely to perform on the final test set!\n* See https://www.kaggle.com/code/richolson/isic-2024-lgbm-imagenet-v5a for the original version of this notebook","metadata":{"papermill":{"duration":0.01661,"end_time":"2024-09-04T03:59:17.497988","exception":false,"start_time":"2024-09-04T03:59:17.481378","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Magic Noise Seeds\n* Defines array of noise seeds we use to boost LB score\n* This is just for fun - will hurt final standings... (badly)","metadata":{"papermill":{"duration":0.011492,"end_time":"2024-09-04T03:59:17.521546","exception":false,"start_time":"2024-09-04T03:59:17.510054","status":"completed"},"tags":[]}},{"cell_type":"code","source":"noise_test_candidate = [22]\n\n# prior seeds that helped\nmagic_noise_seeds = [2, 3, 9, 17]\n\nmagic_noise_seeds = magic_noise_seeds + noise_test_candidate\n\n#we are just keeping of track of seeds that didn't help (unused)\nbad_seeds = [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20]\n\n#value of 0.0000003 has been determined to provide useful noise level (lower than expected)\n#this value should be kept through this experiment\nmagic_noise_factor = 0.0000003\n\nmagic_noise_seeds","metadata":{"papermill":{"duration":0.024958,"end_time":"2024-09-04T03:59:17.558246","exception":false,"start_time":"2024-09-04T03:59:17.533288","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Setup","metadata":{"papermill":{"duration":0.012318,"end_time":"2024-09-04T03:59:17.586773","exception":false,"start_time":"2024-09-04T03:59:17.574455","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\n\n#verify these are set before committing!!!\nmax_estimators = 8010    \nearly_stopping_rounds = 450  #high number assures we train through any \"lucky\" cv bounces\n\n#set to false if want to see full train results / save models.... (false if want to save on GPU)\n\nSCORING, QUICK_TEST, SAVE_TRAIN = 1, 2, 3\n\n#set to QUICK_TEST when submitting to avoid wasting GPU\nmode = QUICK_TEST\n\n#ugly duckling tabular analysis\ndo_ud = True\n\n#load OOF imagenet preds\nload_train_imagepreds_and_cv = True\n\ndo_imagenet_uglyduckling = False\nimport_ud_auged_train = False\n\n#how much gaussian noise to oof image preds\n#best LB improvement with 0.005 so far \noof_imagenet_folds_noise_std = 0.005  # Standard deviation of the Gaussian noise\n\n#assures mode = SCORING on submit\nif len(df_test) > 3:\n    mode = SCORING\n\nif mode == QUICK_TEST:\n    df_train = df_train.head(50030)  #10k too few for successful train\n    max_estimators = 503\n    do_ud = False  #True for saving out augmented train data\n    \nif mode == SAVE_TRAIN:\n    max_estimators = 503\n    do_ud = True  #True for saving out augmented train data\n\n#to keep same code base across imagenet / non-imagenet notebooks\nmain_imagenet_column_name = \"imagenet_predict\"\nimage_net_columns = [main_imagenet_column_name]\n\ndf_train","metadata":{"papermill":{"duration":7.082574,"end_time":"2024-09-04T03:59:24.681442","exception":false,"start_time":"2024-09-04T03:59:17.598868","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import OOF ImageNet predictions and CV fold","metadata":{"papermill":{"duration":0.012621,"end_time":"2024-09-04T03:59:24.706889","exception":false,"start_time":"2024-09-04T03:59:24.694268","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if load_train_imagepreds_and_cv:\n    oof_image_net_preds = pd.read_csv(\"/kaggle/input/isic-2024-imagenet-gen-2-output/oof_predictions.csv\")\n\n    # Rename the 'oof_prediction' column to 'imagenet_predict'\n    oof_image_net_preds = oof_image_net_preds.rename(columns={'oof_prediction': main_imagenet_column_name})\n\n    # Merge with df_train\n    df_train = df_train.merge(oof_image_net_preds[['fold', 'imagenet_predict']], left_index=True, right_index=True, how='left')","metadata":{"papermill":{"duration":0.643132,"end_time":"2024-09-04T03:59:25.364066","exception":false,"start_time":"2024-09-04T03:59:24.720934","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjust pAUC of OOF imagepred folds....\n* Bring the noise!\n* Keeps LGBM from considering image predictions way-too-much (decreases feature importance)","metadata":{"papermill":{"duration":0.012296,"end_time":"2024-09-04T03:59:25.389383","exception":false,"start_time":"2024-09-04T03:59:25.377087","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\n\ndef comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n    v_gt = abs(np.floor(np.asarray(solution.values))-1)\n    v_pred = np.array([1.0 - x for x in submission.values])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return partial_auc\n\ndef pauc_score_func(y_true, y_pred):\n    y_true = np.asarray(y_true).flatten()\n    y_pred = np.asarray(y_pred).flatten()\n    y_true_df = pd.DataFrame(y_true, columns=['target'])\n    y_pred_df = pd.DataFrame(y_pred, columns=['prediction'])\n    return comp_score(y_true_df, y_pred_df, \"\", min_tpr=0.80)\n\ndef process_imagenet_column(df, main_imagenet_column_name, target_column_name, random_seed=42, noise_mean=0, noise_std=0.01):\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n        \n    noise = np.random.normal(loc=noise_mean, scale=noise_std, size=len(df))\n    df[main_imagenet_column_name] += noise\n    \n    # Clip the adjusted values to ensure they remain between 0 and 1\n    df[main_imagenet_column_name] = df[main_imagenet_column_name].clip(0, 1)\n    \n    return df\n\nprint(\"Before adjust pauc:\", pauc_score_func(df_train[\"target\"], df_train[\"imagenet_predict\"]))\n\ntarget_column_name = 'target'\nrandom_seed = 42  # Set a fixed random seed for reproducibility\n\ndf_train = process_imagenet_column(df_train, main_imagenet_column_name, target_column_name, random_seed, noise_mean=0, noise_std=oof_imagenet_folds_noise_std)\n\n# Print the final results\nprint(\"\\nFinal results:\")\nprint(df_train[[main_imagenet_column_name, target_column_name]].head())\n\nprint(\"After adjust pauc:\", pauc_score_func(df_train[\"target\"], df_train[\"imagenet_predict\"]))\n","metadata":{"papermill":{"duration":0.314737,"end_time":"2024-09-04T03:59:25.716657","exception":false,"start_time":"2024-09-04T03:59:25.40192","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do ImageNet inference for test data","metadata":{"papermill":{"duration":0.012535,"end_time":"2024-09-04T03:59:25.74291","exception":false,"start_time":"2024-09-04T03:59:25.730375","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport h5py\nimport timm\nfrom torchvision import transforms\nfrom PIL import Image\nimport io\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass ISICDataset(Dataset):\n    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n        self.hdf5_file = h5py.File(hdf5_file, 'r')\n        self.isic_ids = isic_ids\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n        img = Image.open(io.BytesIO(img_bytes))\n        img = np.array(img)\n        \n        if self.transform:\n            transformed = self.transform(image=img)\n            img = transformed['image']\n        \n        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n        return img, target\n\n    def __del__(self):\n        self.hdf5_file.close()\n\nbase_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\n@torch.no_grad()\ndef ensemble_predict(models, test_loader, device):\n    all_predictions = []\n    \n    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n        inputs = inputs.to(device)\n        fold_predictions = torch.stack([model(inputs).softmax(dim=1)[:, 1] for model in models])\n        avg_predictions = fold_predictions.mean(dim=0)\n        all_predictions.append(avg_predictions.cpu())\n    \n    return torch.cat(all_predictions).numpy()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndf_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\nTEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\nTRAIN_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n\n#only for verifiying can work with larger test dataset\n#df_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\n#TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n\nmodel_configs = [\n    (\"/kaggle/input/isic-2024-multifold-v2-offsite-train/v2_model_fold_2_epoch_1.pth\", 'tf_efficientnetv2_b1'),\n    (\"/kaggle/input/isic-2024-multifold-v2-offsite-train/v2_model_fold_4_epoch_1.pth\", 'tf_efficientnetv2_b1'),\n    (\"/kaggle/input/imagenet-143lb-from-isic-2024-imagenet-model-a/best_model.pth\", 'tf_efficientnetv2_b1'),\n    (\"/kaggle/input/isic-2024-effnetv2b0-lb-0-151/effnetv2b0_151lb_isic2024.pth\", 'tf_efficientnet_b0')\n]\n\nmodels = [timm.create_model(model_type, pretrained=False, num_classes=2).to(device) for _, model_type in model_configs]\nfor model, (model_path, _) in zip(models, model_configs):\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n\ntest_dataset = ISICDataset(\n    hdf5_file=TEST_HDF5_FILE_PATH,\n    isic_ids=df_test['isic_id'].values,\n    transform=base_transform,\n)\ntest_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n\npredictions = ensemble_predict(models, test_loader, device)\ndf_test[main_imagenet_column_name] = predictions\n\nprint(df_test[main_imagenet_column_name].head())\n","metadata":{"papermill":{"duration":10.057549,"end_time":"2024-09-04T03:59:35.813718","exception":false,"start_time":"2024-09-04T03:59:25.756169","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ugly Duckling Imagenet Feature Extraction","metadata":{"papermill":{"duration":0.013304,"end_time":"2024-09-04T03:59:35.841033","exception":false,"start_time":"2024-09-04T03:59:35.827729","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport random\n\nBATCH_SIZE = 128\nNUM_WORKERS = 4\n\n# Set a fixed number of threads for NumPy\nos.environ['OMP_NUM_THREADS'] = '1'\n\ndef get_infer_model(num_classes=2, model_class = \"\", model_file = \"\", is_imagenet = False):\n    \n    model = timm.create_model(model_class, pretrained=False)\n    \n    # Replace the classifier if your MODEL_PATH doesn't include it\n    # If MODEL_PATH includes the classifier, you can remove these lines\n    if not is_imagenet:\n        in_features = model.classifier.in_features\n        model.classifier = torch.nn.Linear(in_features, num_classes)\n    \n    # Load your trained weights\n    if torch.cuda.is_available(): \n        model.load_state_dict(torch.load(model_file))\n    else:\n        model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n        \n    model = model.to(device)\n    \n    return model\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n# Set seed for reproducibility\nset_seed()\n\n# Ensure deterministic GPU operations\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\ndef extract_features(model, loader, device):\n    features = []\n    isic_ids = []\n    model.eval()\n    with torch.no_grad():\n        for inputs, batch_isic_ids in tqdm(loader, desc=\"Extracting features\"):\n            inputs = inputs.to(device)\n            output = model(inputs)\n            features.append(output.cpu())\n            isic_ids.extend(batch_isic_ids)\n    return torch.cat(features).numpy(), isic_ids\n\ndef calculate_outlier_scores(features):\n    print(\"Normalizing features...\")\n    scaler = StandardScaler()\n    features_normalized = scaler.fit_transform(features)\n    \n    print(\"Calculating Isolation Forest scores...\")\n    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_jobs=1)  # n_jobs=1 for determinism\n    outlier_scores_if = iso_forest.fit_predict(features_normalized)\n    outlier_scores_if = (outlier_scores_if * -1 + 1) / 2\n    \n    print(\"Calculating Local Outlier Factor scores...\")\n    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, n_jobs=1)  # n_jobs=1 for determinism\n    outlier_scores_lof = lof.fit_predict(features_normalized)\n    outlier_scores_lof = (outlier_scores_lof * -1 + 1) / 2\n    \n    print(\"Combining scores...\")\n    outlier_scores_combined = (outlier_scores_if + outlier_scores_lof) / 2\n    \n    return outlier_scores_if, outlier_scores_lof, outlier_scores_combined\n\ndef add_outlier_scores_to_df(df, isic_ids, outlier_scores_if, outlier_scores_lof, outlier_scores_combined):\n    print(\"Adding outlier scores to dataframe...\")\n    temp_df = pd.DataFrame({\n        'isic_id': isic_ids,\n        'outlier_score_if': outlier_scores_if,\n        'outlier_score_lof': outlier_scores_lof,\n        'outlier_score_combined': outlier_scores_combined\n    })\n    return df.merge(temp_df, on='isic_id', how='left')\n\ndef gpu_correlation(tensor):\n    centered = tensor - tensor.mean(dim=0)\n    cov = torch.matmul(centered.t(), centered) / (tensor.size(0) - 1)\n    std = torch.sqrt(torch.diag(cov))\n    cor = cov / torch.ger(std, std)\n    return cor\n\ndef plot_correlation_heatmap(df, target_column, feature_columns, device):\n    print(\"Plotting correlation heatmap...\")\n    tensor = torch.tensor(df[feature_columns + [target_column]].values, dtype=torch.float32).to(device)\n    corr = gpu_correlation(tensor)\n    corr_cpu = corr.cpu().numpy()\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_cpu, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0,\n                xticklabels=feature_columns + [target_column],\n                yticklabels=feature_columns + [target_column])\n    plt.title('Correlation Heatmap: Outlier Scores vs Target')\n    plt.show()\n    \n    return corr_cpu\n\nif do_imagenet_uglyduckling:\n    print(f\"Using device: {device}\")\n\n    print(\"Loading the model...\")\n    model = get_infer_model(num_classes=2, model_class=\"tf_efficientnetv2_b1\", model_file=\"/kaggle/input/isic-2024-tf-efficientnetv2-b1/best_model.pth\", is_imagenet=False)\n\n    # Recreate DataLoaders with deterministic settings\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, \n                              pin_memory=True, worker_init_fn=seed_worker, generator=g)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, \n                             pin_memory=True, worker_init_fn=seed_worker, generator=g)\n\n    print(\"Extracting features for train set...\")\n    train_features, train_isic_ids = extract_features(model, train_loader, device)\n    print(\"Extracting features for test set...\")\n    test_features, test_isic_ids = extract_features(model, test_loader, device)\n\n    print(\"Calculating outlier scores for train set...\")\n    train_outlier_scores_if, train_outlier_scores_lof, train_outlier_scores_combined = calculate_outlier_scores(train_features)\n    print(\"Calculating outlier scores for test set...\")\n    test_outlier_scores_if, test_outlier_scores_lof, test_outlier_scores_combined = calculate_outlier_scores(test_features)\n\n    print(\"Adding outlier scores to dataframes...\")\n    df_train = add_outlier_scores_to_df(df_train, train_isic_ids, train_outlier_scores_if, train_outlier_scores_lof, train_outlier_scores_combined)\n    df_test = add_outlier_scores_to_df(df_test, test_isic_ids, test_outlier_scores_if, test_outlier_scores_lof, test_outlier_scores_combined)\n\n    outlier_score_columns = ['outlier_score_if', 'outlier_score_lof', 'outlier_score_combined']\n    corr_matrix = plot_correlation_heatmap(df_train, 'target', outlier_score_columns, device)\n\n    print(\"Correlations with target:\")\n    target_correlations = corr_matrix[-1, :-1]\n    for col, corr in zip(outlier_score_columns, target_correlations):\n        print(f\"{col}: {corr:.4f}\")\n        \n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n    # Delete large variables\n    del train_features, test_features\n    del train_outlier_scores_if, train_outlier_scores_lof, train_outlier_scores_combined\n    del test_outlier_scores_if, test_outlier_scores_lof, test_outlier_scores_combined\n    del corr_matrix\n\n    # Force garbage collection\n    import gc\n    gc.collect()\n\n    image_net_columns.extend(outlier_score_columns) \n    print(image_net_columns)","metadata":{"papermill":{"duration":0.320299,"end_time":"2024-09-04T03:59:36.17427","exception":false,"start_time":"2024-09-04T03:59:35.853971","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial new features\n* Credit to https://www.kaggle.com/code/snnclsr/lgbm-baseline-with-new-features","metadata":{"papermill":{"duration":0.013002,"end_time":"2024-09-04T03:59:36.200975","exception":false,"start_time":"2024-09-04T03:59:36.187973","status":"completed"},"tags":[]}},{"cell_type":"code","source":"num_cols = [\n    'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', \n    'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', \n    'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', \n    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n    'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n    'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n    'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n    'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n]\n\nnum_cols = num_cols + image_net_columns\n\n# anatom_site_general (why isn't this in here?)\ncat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n\ndef feature_engineering(df):\n    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n    df[\"symmetry_border_consistency2\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n    df[\"color_consistency2\"] = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n    \n    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n    df[\"3d_lesion_orientation\"] = np.arctan2(df_train[\"tbp_lv_y\"], df_train[\"tbp_lv_x\"])\n    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n    \n    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n    df[\"age_size_symmetry_index2\"] = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n\n    new_num_cols = [\n        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\", \"area_to_perimeter_ratio\",\n        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"symmetry_border_consistency2\", \"color_consistency\",\"color_consistency2\",\n\n        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\", \n        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n        \n        \"color_variance_ratio\", \"border_color_interaction\", \"size_color_contrast_ratio\", \"age_normalized_nevi_confidence\",\n        \"color_asymmetry_index\", \"3d_volume_approximation\", \"color_range\", \"shape_color_consistency\", \"border_length_ratio\", \n        \"age_size_symmetry_index\", \"age_size_symmetry_index2\",\n    ]\n    new_cat_cols = [\"combined_anatomical_site\"]\n    \n    return df, new_num_cols, new_cat_cols\n\n# Generate features for test and train\ndf_train, new_num_cols, new_cat_cols = feature_engineering(df_train.copy())\ndf_test, _, _ = feature_engineering(df_test.copy())\n\nnum_cols = num_cols + new_num_cols\ncat_cols = cat_cols + new_cat_cols","metadata":{"papermill":{"duration":0.13927,"end_time":"2024-09-04T03:59:36.353744","exception":false,"start_time":"2024-09-04T03:59:36.214474","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional new features...","metadata":{"papermill":{"duration":0.012915,"end_time":"2024-09-04T03:59:36.380196","exception":false,"start_time":"2024-09-04T03:59:36.367281","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def additional_feature_engineering(df):\n    # Asymmetry features\n    df['asymmetry_ratio'] = df['tbp_lv_symm_2axis'] / df['tbp_lv_perimeterMM']\n    df['asymmetry_area_ratio'] = df['tbp_lv_symm_2axis'] / df['tbp_lv_areaMM2']\n\n    # Color variation features\n    df['color_variation_intensity'] = df['tbp_lv_norm_color'] * df['tbp_lv_deltaLBnorm']\n    df['color_contrast_ratio'] = df['tbp_lv_deltaLBnorm'] / (df['tbp_lv_L'] + 1e-5)\n\n    # Shape complexity features\n    df['shape_irregularity'] = df['tbp_lv_perimeterMM'] / (2 * np.sqrt(np.pi * df['tbp_lv_areaMM2']))\n    df['border_density'] = df['tbp_lv_norm_border'] / df['tbp_lv_perimeterMM']\n\n    # Size-related features\n    df['size_age_ratio'] = df['clin_size_long_diam_mm'] / (df['age_approx'] + 1e-5)\n    df['area_diameter_ratio'] = df['tbp_lv_areaMM2'] / (df['clin_size_long_diam_mm']**2 + 1e-5)\n\n    # Location-based features\n    df['location_size_interaction'] = df.apply(lambda row: f\"{row['tbp_lv_location_simple']}_{bin_size(row['clin_size_long_diam_mm'])}\", axis=1)\n    df['location_age_interaction'] = df.apply(lambda row: f\"{row['tbp_lv_location_simple']}_{bin_age(row['age_approx'])}\", axis=1)\n\n    # 3D position features\n    df['3d_position_norm'] = np.sqrt(df['tbp_lv_x']**2 + df['tbp_lv_y']**2 + df['tbp_lv_z']**2)\n    df['3d_position_angle_xy'] = np.arctan2(df['tbp_lv_y'], df['tbp_lv_x'])\n    df['3d_position_angle_xz'] = np.arctan2(df['tbp_lv_z'], df['tbp_lv_x'])\n\n    # Color space transformations\n    df['lab_chroma'] = np.sqrt(df['tbp_lv_A']**2 + df['tbp_lv_B']**2)\n    df['lab_hue'] = np.arctan2(df['tbp_lv_B'], df['tbp_lv_A'])\n\n    # Texture-related features\n    df['texture_contrast'] = df['tbp_lv_stdL'] / (df['tbp_lv_L'] + 1e-5)\n    df['texture_uniformity'] = 1 / (1 + df['tbp_lv_color_std_mean'])\n\n    # Color difference features\n    df['color_difference_AB'] = np.sqrt(df['tbp_lv_deltaA']**2 + df['tbp_lv_deltaB']**2)\n    df['color_difference_total'] = np.sqrt(df['tbp_lv_deltaA']**2 + df['tbp_lv_deltaB']**2 + df['tbp_lv_deltaL']**2)\n\n    # Anatomical site encoding\n    df['anatom_site_encoded'] = df['anatom_site_general'].map(anatom_site_encoding)\n\n    # Sex encoding\n    df['sex_encoded'] = df['sex'].map({'male': 0, 'female': 1})\n\n    return df\n\ndef bin_size(size):\n    if size < 5:\n        return 'very_small'\n    elif size < 10:\n        return 'small'\n    elif size < 20:\n        return 'medium'\n    else:\n        return 'large'\n\ndef bin_age(age):\n    if age < 30:\n        return 'young'\n    elif age < 60:\n        return 'middle_aged'\n    else:\n        return 'senior'\n\n# Encoding for anatomical sites\nanatom_site_encoding = {\n    'torso': 0,\n    'upper extremity': 1,\n    'lower extremity': 2,\n    'head/neck': 3,\n    'palms/soles': 4,\n    'oral/genital': 5\n}\n\n# Add these new features to your existing feature engineering pipeline\ndf_train = additional_feature_engineering(df_train)\ndf_test = additional_feature_engineering(df_test)\n\n# Update your feature lists\nnew_num_cols = [\n    'asymmetry_ratio', 'asymmetry_area_ratio', 'color_variation_intensity',\n    'color_contrast_ratio', 'shape_irregularity', 'border_density',\n    'size_age_ratio', 'area_diameter_ratio', '3d_position_norm',\n    '3d_position_angle_xy', '3d_position_angle_xz', 'lab_chroma', 'lab_hue',\n    'texture_contrast', 'texture_uniformity', 'color_difference_AB',\n    'color_difference_total', 'anatom_site_encoded', 'sex_encoded'\n]\nnew_cat_cols = ['location_size_interaction', 'location_age_interaction']\n\nnum_cols += new_num_cols\ncat_cols += new_cat_cols","metadata":{"papermill":{"duration":2.117409,"end_time":"2024-09-04T03:59:38.510538","exception":false,"start_time":"2024-09-04T03:59:36.393129","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tabular Ugly Ducklings\n* Computes \"ugly duckling\" features for patients and locations, adding z-scores, percentiles, counts, severity, and consistency metrics","metadata":{"papermill":{"duration":0.013175,"end_time":"2024-09-04T03:59:38.537238","exception":false,"start_time":"2024-09-04T03:59:38.524063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def ugly_duckling_processing(df, num_cols):\n    ud_columns = num_cols.copy()\n    new_num_cols = []\n    \n    #if false - only do location-based ugly ducklings\n    include_patient_wide_ud = False  \n    \n    counter = 0\n    \n    def calc_ugly_duckling_scores(group, grouping):\n        nonlocal counter\n        counter += 1\n        if counter % 10 == 0: print(\".\", end=\"\", flush=True)\n        z_scores = group[ud_columns].apply(lambda x: zscore(x, nan_policy='omit'))\n        ud_scores = np.abs(z_scores)\n        prefix = 'ud_' if grouping == 'patient' else 'ud_loc_'\n        ud_scores.columns = [f'{prefix}{col}' for col in ud_columns]\n        return ud_scores\n\n    print(\"Analyzing ducklings\", end=\"\", flush=True)\n    ud_location_col = 'tbp_lv_location'\n    ud_scores_loc = df.groupby(['patient_id', ud_location_col])[ud_columns + ['patient_id', ud_location_col]].apply(\n        lambda x: calc_ugly_duckling_scores(x, 'location')\n    ).reset_index(level=[0, 1], drop=True)\n    \n    print(\"\\nConcat ducklings\")\n    df = pd.concat([df, ud_scores_loc], axis=1)\n    \n    if include_patient_wide_ud:\n        print(\"Analyzing ducklings (part 2)\", end=\"\", flush=True)\n        ud_scores_patient = df.groupby('patient_id')[ud_columns + ['patient_id']].apply(\n            lambda x: calc_ugly_duckling_scores(x, 'patient')\n        ).reset_index(level=0, drop=True)\n        df = pd.concat([df, ud_scores_patient], axis=1)\n        print()  # New line after progress indicator\n\n    print(\"Extending ducklings\")\n    new_num_cols.extend([f'ud_loc_{col}' for col in ud_columns])\n    if include_patient_wide_ud:\n        new_num_cols.extend([f'ud_{col}' for col in ud_columns])\n\n    print(\"Enhancing ugly duckling features\", end=\"\", flush=True)\n    \n    # 1. Percentile-based ugly duckling scores\n    def calc_percentile_ud_scores(group):\n        nonlocal counter\n        counter += 1\n        if counter % 10 == 0: print(\".\", end=\"\", flush=True)\n        percentiles = group[ud_columns].rank(pct=True)\n        return percentiles.add_prefix('ud_percentile_')\n    \n    counter = 0  # Reset counter for percentile calculation\n    ud_percentiles = df.groupby('patient_id')[ud_columns].apply(calc_percentile_ud_scores).reset_index(level=0, drop=True)\n    df = pd.concat([df, ud_percentiles], axis=1)\n    new_num_cols.extend([f'ud_percentile_{col}' for col in ud_columns])\n    print()  # New line after progress indicator\n\n    # 2. Ugly duckling count features\n    threshold = 2.0  # You can adjust this threshold\n    if include_patient_wide_ud:\n        ud_count = (df[[f'ud_{col}' for col in ud_columns]].abs() > threshold).sum(axis=1)\n        df['ud_count_patient'] = ud_count\n        new_num_cols.append('ud_count_patient')\n    \n    ud_count_loc = (df[[f'ud_loc_{col}' for col in ud_columns]].abs() > threshold).sum(axis=1)\n    df['ud_count_location'] = ud_count_loc\n    new_num_cols.append('ud_count_location')\n\n    # 3. Ugly duckling severity features\n    if include_patient_wide_ud:\n        df['ud_max_severity_patient'] = df[[f'ud_{col}' for col in ud_columns]].abs().max(axis=1)\n        new_num_cols.append('ud_max_severity_patient')\n    df['ud_max_severity_location'] = df[[f'ud_loc_{col}' for col in ud_columns]].abs().max(axis=1)\n    new_num_cols.append('ud_max_severity_location')\n\n    # 4. Ugly duckling consistency features\n    if include_patient_wide_ud:\n        df['ud_consistency_patient'] = df[[f'ud_{col}' for col in ud_columns]].abs().std(axis=1)\n        new_num_cols.append('ud_consistency_patient')\n    df['ud_consistency_location'] = df[[f'ud_loc_{col}' for col in ud_columns]].abs().std(axis=1)\n    new_num_cols.append('ud_consistency_location')\n\n    return df, new_num_cols\n\nif do_ud:\n    df_train, ud_num_cols = ugly_duckling_processing(df_train.copy(), num_cols)\n    df_test, _ = ugly_duckling_processing(df_test.copy(), num_cols)\n\n    # Update the list of columns to train on\n    num_cols = num_cols + ud_num_cols","metadata":{"papermill":{"duration":0.037202,"end_time":"2024-09-04T03:59:38.587643","exception":false,"start_time":"2024-09-04T03:59:38.550441","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assemble final list of columns to train on...","metadata":{"papermill":{"duration":0.013521,"end_time":"2024-09-04T03:59:38.614567","exception":false,"start_time":"2024-09-04T03:59:38.601046","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_cols = num_cols + cat_cols","metadata":{"papermill":{"duration":0.02169,"end_time":"2024-09-04T03:59:38.649648","exception":false,"start_time":"2024-09-04T03:59:38.627958","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving train dataset to file\n* Includes imagenet(s), ugly ducklings\n* Not category encoded","metadata":{"papermill":{"duration":0.012969,"end_time":"2024-09-04T03:59:38.675655","exception":false,"start_time":"2024-09-04T03:59:38.662686","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if mode == SAVE_TRAIN:\n    df_train.to_csv(\"isic_2024_train_auged.csv\", index=False)","metadata":{"papermill":{"duration":0.021765,"end_time":"2024-09-04T03:59:38.711228","exception":false,"start_time":"2024-09-04T03:59:38.689463","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overrides train data with previously augmented\n* Just loads pre-calculated for quicker testing","metadata":{"papermill":{"duration":0.013324,"end_time":"2024-09-04T03:59:38.738091","exception":false,"start_time":"2024-09-04T03:59:38.724767","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if import_ud_auged_train:\n    #everything including catcols\n    train_cols = ['age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB', 'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color', 'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'lesion_size_ratio', 'lesion_shape_index', 'hue_contrast', 'luminance_contrast', 'lesion_color_difference', 'border_complexity', 'color_uniformity', '3d_position_distance', 'perimeter_to_area_ratio', 'lesion_visibility_score', 'symmetry_border_consistency', 'color_consistency', 'size_age_interaction', 'hue_color_std_interaction', 'lesion_severity_index', 'shape_complexity_index', 'color_contrast_index', 'log_lesion_area', 'normalized_lesion_size', 'mean_hue_difference', 'std_dev_contrast', 'color_shape_composite_index', '3d_lesion_orientation', 'overall_color_difference', 'symmetry_perimeter_interaction', 'comprehensive_lesion_index', 'asymmetry_ratio', 'asymmetry_area_ratio', 'color_variation_intensity', 'color_contrast_ratio', 'shape_irregularity', 'border_density', 'size_age_ratio', 'area_diameter_ratio', '3d_position_norm', '3d_position_angle_xy', '3d_position_angle_xz', 'lab_chroma', 'lab_hue', 'texture_contrast', 'texture_uniformity', 'color_difference_AB', 'color_difference_total', 'anatom_site_encoded', 'sex_encoded', 'ud_loc_age_approx', 'ud_loc_clin_size_long_diam_mm', 'ud_loc_tbp_lv_A', 'ud_loc_tbp_lv_Aext', 'ud_loc_tbp_lv_B', 'ud_loc_tbp_lv_Bext', 'ud_loc_tbp_lv_C', 'ud_loc_tbp_lv_Cext', 'ud_loc_tbp_lv_H', 'ud_loc_tbp_lv_Hext', 'ud_loc_tbp_lv_L', 'ud_loc_tbp_lv_Lext', 'ud_loc_tbp_lv_areaMM2', 'ud_loc_tbp_lv_area_perim_ratio', 'ud_loc_tbp_lv_color_std_mean', 'ud_loc_tbp_lv_deltaA', 'ud_loc_tbp_lv_deltaB', 'ud_loc_tbp_lv_deltaL', 'ud_loc_tbp_lv_deltaLB', 'ud_loc_tbp_lv_deltaLBnorm', 'ud_loc_tbp_lv_eccentricity', 'ud_loc_tbp_lv_minorAxisMM', 'ud_loc_tbp_lv_nevi_confidence', 'ud_loc_tbp_lv_norm_border', 'ud_loc_tbp_lv_norm_color', 'ud_loc_tbp_lv_perimeterMM', 'ud_loc_tbp_lv_radial_color_std_max', 'ud_loc_tbp_lv_stdL', 'ud_loc_tbp_lv_stdLExt', 'ud_loc_tbp_lv_symm_2axis', 'ud_loc_tbp_lv_symm_2axis_angle', 'ud_loc_tbp_lv_x', 'ud_loc_tbp_lv_y', 'ud_loc_tbp_lv_z', 'ud_loc_lesion_size_ratio', 'ud_loc_lesion_shape_index', 'ud_loc_hue_contrast', 'ud_loc_luminance_contrast', 'ud_loc_lesion_color_difference', 'ud_loc_border_complexity', 'ud_loc_color_uniformity', 'ud_loc_3d_position_distance', 'ud_loc_perimeter_to_area_ratio', 'ud_loc_lesion_visibility_score', 'ud_loc_symmetry_border_consistency', 'ud_loc_color_consistency', 'ud_loc_size_age_interaction', 'ud_loc_hue_color_std_interaction', 'ud_loc_lesion_severity_index', 'ud_loc_shape_complexity_index', 'ud_loc_color_contrast_index', 'ud_loc_log_lesion_area', 'ud_loc_normalized_lesion_size', 'ud_loc_mean_hue_difference', 'ud_loc_std_dev_contrast', 'ud_loc_color_shape_composite_index', 'ud_loc_3d_lesion_orientation', 'ud_loc_overall_color_difference', 'ud_loc_symmetry_perimeter_interaction', 'ud_loc_comprehensive_lesion_index', 'ud_loc_asymmetry_ratio', 'ud_loc_asymmetry_area_ratio', 'ud_loc_color_variation_intensity', 'ud_loc_color_contrast_ratio', 'ud_loc_shape_irregularity', 'ud_loc_border_density', 'ud_loc_size_age_ratio', 'ud_loc_area_diameter_ratio', 'ud_loc_3d_position_norm', 'ud_loc_3d_position_angle_xy', 'ud_loc_3d_position_angle_xz', 'ud_loc_lab_chroma', 'ud_loc_lab_hue', 'ud_loc_texture_contrast', 'ud_loc_texture_uniformity', 'ud_loc_color_difference_AB', 'ud_loc_color_difference_total', 'ud_loc_anatom_site_encoded', 'ud_loc_sex_encoded', 'ud_percentile_age_approx', 'ud_percentile_clin_size_long_diam_mm', 'ud_percentile_tbp_lv_A', 'ud_percentile_tbp_lv_Aext', 'ud_percentile_tbp_lv_B', 'ud_percentile_tbp_lv_Bext', 'ud_percentile_tbp_lv_C', 'ud_percentile_tbp_lv_Cext', 'ud_percentile_tbp_lv_H', 'ud_percentile_tbp_lv_Hext', 'ud_percentile_tbp_lv_L', 'ud_percentile_tbp_lv_Lext', 'ud_percentile_tbp_lv_areaMM2', 'ud_percentile_tbp_lv_area_perim_ratio', 'ud_percentile_tbp_lv_color_std_mean', 'ud_percentile_tbp_lv_deltaA', 'ud_percentile_tbp_lv_deltaB', 'ud_percentile_tbp_lv_deltaL', 'ud_percentile_tbp_lv_deltaLB', 'ud_percentile_tbp_lv_deltaLBnorm', 'ud_percentile_tbp_lv_eccentricity', 'ud_percentile_tbp_lv_minorAxisMM', 'ud_percentile_tbp_lv_nevi_confidence', 'ud_percentile_tbp_lv_norm_border', 'ud_percentile_tbp_lv_norm_color', 'ud_percentile_tbp_lv_perimeterMM', 'ud_percentile_tbp_lv_radial_color_std_max', 'ud_percentile_tbp_lv_stdL', 'ud_percentile_tbp_lv_stdLExt', 'ud_percentile_tbp_lv_symm_2axis', 'ud_percentile_tbp_lv_symm_2axis_angle', 'ud_percentile_tbp_lv_x', 'ud_percentile_tbp_lv_y', 'ud_percentile_tbp_lv_z', 'ud_percentile_lesion_size_ratio', 'ud_percentile_lesion_shape_index', 'ud_percentile_hue_contrast', 'ud_percentile_luminance_contrast', 'ud_percentile_lesion_color_difference', 'ud_percentile_border_complexity', 'ud_percentile_color_uniformity', 'ud_percentile_3d_position_distance', 'ud_percentile_perimeter_to_area_ratio', 'ud_percentile_lesion_visibility_score', 'ud_percentile_symmetry_border_consistency', 'ud_percentile_color_consistency', 'ud_percentile_size_age_interaction', 'ud_percentile_hue_color_std_interaction', 'ud_percentile_lesion_severity_index', 'ud_percentile_shape_complexity_index', 'ud_percentile_color_contrast_index', 'ud_percentile_log_lesion_area', 'ud_percentile_normalized_lesion_size', 'ud_percentile_mean_hue_difference', 'ud_percentile_std_dev_contrast', 'ud_percentile_color_shape_composite_index', 'ud_percentile_3d_lesion_orientation', 'ud_percentile_overall_color_difference', 'ud_percentile_symmetry_perimeter_interaction', 'ud_percentile_comprehensive_lesion_index', 'ud_percentile_asymmetry_ratio', 'ud_percentile_asymmetry_area_ratio', 'ud_percentile_color_variation_intensity', 'ud_percentile_color_contrast_ratio', 'ud_percentile_shape_irregularity', 'ud_percentile_border_density', 'ud_percentile_size_age_ratio', 'ud_percentile_area_diameter_ratio', 'ud_percentile_3d_position_norm', 'ud_percentile_3d_position_angle_xy', 'ud_percentile_3d_position_angle_xz', 'ud_percentile_lab_chroma', 'ud_percentile_lab_hue', 'ud_percentile_texture_contrast', 'ud_percentile_texture_uniformity', 'ud_percentile_color_difference_AB', 'ud_percentile_color_difference_total', 'ud_percentile_anatom_site_encoded', 'ud_percentile_sex_encoded', 'ud_count_location', 'ud_max_severity_location', 'ud_consistency_location', 'sex', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'combined_anatomical_site', 'location_size_interaction', 'location_age_interaction']\n    cat_cols = ['sex', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'combined_anatomical_site', 'location_size_interaction', 'location_age_interaction']\n\n    df_train = pd.read_csv(\"/kaggle/input/isic-2024-tabular-feature-generation/isic_2024_train_auged.csv\")\n\n    missing_cols = set(df_train.columns) - set(df_test.columns)\n    new_cols = pd.DataFrame({col: df_train[col].iloc[0] for col in missing_cols}, index=df_test.index).astype(df_train[list(missing_cols)].dtypes)\n    df_test = pd.concat([df_test, new_cols], axis=1)[df_train.columns]","metadata":{"papermill":{"duration":0.035059,"end_time":"2024-09-04T03:59:38.835392","exception":false,"start_time":"2024-09-04T03:59:38.800333","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode Columns\n* This may have a bug... (but fixing didn't effect score)","metadata":{"papermill":{"duration":0.013075,"end_time":"2024-09-04T03:59:38.862039","exception":false,"start_time":"2024-09-04T03:59:38.848964","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Encode categories\ncategory_encoder = OrdinalEncoder(\n    categories='auto',\n    dtype=int,\n    handle_unknown='use_encoded_value',\n    unknown_value=-2,\n    encoded_missing_value=-1,\n)\n\nX_cat = category_encoder.fit_transform(df_train[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    df_train[cat_col] = X_cat[:, c]\n\nX_cat = category_encoder.fit_transform(df_test[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    df_test[cat_col] = X_cat[:, c]","metadata":{"papermill":{"duration":0.154826,"end_time":"2024-09-04T03:59:39.030121","exception":false,"start_time":"2024-09-04T03:59:38.875295","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce Features\n* Removing features that experiments indicated hurt score","metadata":{"papermill":{"duration":0.013149,"end_time":"2024-09-04T03:59:39.056983","exception":false,"start_time":"2024-09-04T03:59:39.043834","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#stuff to remove\nbase_removals_1 = [\n    \"ud_percentile_log_lesion_area\", \"ud_count_location\", \"texture_uniformity\", \"ud_loc_tbp_lv_y\",\n    \"log_lesion_area\", \"ud_percentile_symmetry_border_consistency\", \"ud_percentile_3d_position_distance\", \"ud_loc_color_contrast_ratio\",\n    \"ud_loc_3d_position_angle_xy\", \"tbp_lv_perimeterMM\", \"normalized_lesion_size\", \"ud_loc_area_diameter_ratio\",\n    \"ud_consistency_location\", \"tbp_lv_deltaA\", \"tbp_lv_C\", \"ud_percentile_tbp_lv_norm_color\",\n    \"ud_loc_std_dev_contrast\", \"ud_loc_texture_uniformity\", \"ud_loc_tbp_lv_radial_color_std_max\", \"perimeter_to_area_ratio\",\n    \"lab_hue\", \"ud_loc_color_consistency\", \"tbp_lv_B\", \"ud_percentile_age_approx\",\n    \"ud_loc_3d_position_distance\", \"ud_percentile_lesion_shape_index\", \"ud_loc_tbp_lv_area_perim_ratio\", \"tbp_lv_minorAxisMM\",\n    \"ud_loc_tbp_lv_deltaB\", \"ud_percentile_color_contrast_index\", \"ud_loc_overall_color_difference\", \"shape_complexity_index\",\n    \"ud_loc_border_complexity\", \"sex_encoded\", \"mean_hue_difference\", \"ud_loc_lesion_visibility_score\",\n    \"tbp_lv_A\", \"tbp_lv_Bext\", \"ud_loc_tbp_lv_stdL\", \"ud_loc_asymmetry_ratio\",\n    \"ud_loc_tbp_lv_deltaA\"\n    ]\n\n\n# Remove items from train_cols that are in features\ntrain_cols = [col for col in train_cols if col not in base_removals_1]\n\n\nbase_removals_2 = [\"ud_loc_tbp_lv_eccentricity\", \"ud_percentile_size_age_interaction\", \"ud_percentile_tbp_lv_C\", \"ud_percentile_lesion_visibility_score\", \"ud_percentile_tbp_lv_L\",\n                   \"ud_loc_tbp_lv_symm_2axis_angle\", \"asymmetry_area_ratio\", \"ud_loc_mean_hue_difference\", \"tbp_lv_H\", \"ud_percentile_tbp_lv_Lext\", \"ud_percentile_tbp_lv_deltaL\",\n                   \"ud_percentile_size_age_ratio\", \"comprehensive_lesion_index\", \"tbp_lv_deltaB\", \"ud_loc_symmetry_border_consistency\", \"ud_percentile_tbp_lv_perimeterMM\", \"hue_color_std_interaction\"]\n\n# Remove items from train_cols that are in features\ntrain_cols = [col for col in train_cols if col not in base_removals_2]\n\n\nbase_removals_3 = [\"tbp_lv_Hext\", \"ud_percentile_color_difference_AB\", \"hue_contrast\", \"ud_loc_color_difference_total\"]\n\n# Remove items from train_cols that are in features\ntrain_cols = [col for col in train_cols if col not in base_removals_3]\n\nprint(\"Updated train_cols:\", train_cols)","metadata":{"papermill":{"duration":0.026713,"end_time":"2024-09-04T03:59:39.097067","exception":false,"start_time":"2024-09-04T03:59:39.070354","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using folds already defined in imagenet data","metadata":{"papermill":{"duration":0.013196,"end_time":"2024-09-04T03:59:39.12375","exception":false,"start_time":"2024-09-04T03:59:39.110554","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if not load_train_imagepreds_and_cv:\n    gkf = GroupKFold(n_splits=5)\n\n    df_train[\"fold\"] = -1\n    for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n        df_train.loc[val_idx, \"fold\"] = idx","metadata":{"papermill":{"duration":0.021737,"end_time":"2024-09-04T03:59:39.158713","exception":false,"start_time":"2024-09-04T03:59:39.136976","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assign robustness scores used as sample weights\n* Seems to help a little...","metadata":{"papermill":{"duration":0.012931,"end_time":"2024-09-04T03:59:39.185029","exception":false,"start_time":"2024-09-04T03:59:39.172098","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train['robustness_score'] = 100\n\ndf_train.loc[df_train['lesion_id'].notna(), 'robustness_score'] = 200\n\ndf_train.loc[df_train['iddx_1'] == \"Indeterminate\", 'robustness_score'] = 50\n\ndf_train['robustness_score'] += 0.25 * df_train['tbp_lv_dnn_lesion_confidence'].fillna(0)\n\ndef create_sample_weights(df, robustness_column='robustness_score', min_weight=1, max_weight=10):\n    min_score = df[robustness_column].min()\n    max_score = df[robustness_column].max()\n    weights = min_weight + (max_weight - min_weight) * (df[robustness_column] - min_score) / (max_score - min_score)\n    return weights","metadata":{"papermill":{"duration":0.035917,"end_time":"2024-09-04T03:59:39.234185","exception":false,"start_time":"2024-09-04T03:59:39.198268","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train with early stopping ","metadata":{"papermill":{"duration":0.013006,"end_time":"2024-09-04T03:59:39.260279","exception":false,"start_time":"2024-09-04T03:59:39.247273","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class EarlyStoppingException(Exception):\n    pass\n\nclass EarlyStoppingByPAUC:\n    def __init__(self, stopping_cycles, period=1, eval_set=None):\n        self.stopping_cycles = stopping_cycles\n        self.period = period\n        self.eval_set = eval_set\n        self.best_score = -np.inf\n        self.best_iteration = 0\n        self.best_model = None\n        self.counter = 0\n\n    def __call__(self, env):\n        if self.eval_set is None or env.iteration % self.period != 0:\n            return False\n\n        y_true = self.eval_set[0][1]\n        y_pred = env.model.predict(self.eval_set[0][0], num_iteration=env.iteration)\n        current_score = pauc_score_func(y_true, y_pred)\n\n        print(f\"Iteration {env.iteration}, Current pAUC: {current_score:.5f}\")\n\n        if current_score > self.best_score:\n            self.best_score = current_score\n            self.best_iteration = env.iteration\n            self.best_model_state = copy.deepcopy(env.model)\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        if self.counter >= self.stopping_cycles:\n            print(f\"Early stopping at iteration {env.iteration}\")\n            print(f\"Best iteration: {self.best_iteration}\")\n            print(f\"Best pAUC: {self.best_score:.5f}\")\n            raise EarlyStoppingException()\n            return True\n\n        return False\n\n    \ndef train_lgbm_with_early_stopping(df_train, train_cols, use_early_stopping=True, early_stopping_rounds=100):\n    lgb_params = {\n        'objective': 'binary',\n        \"random_state\": 42,\n        \"n_estimators\": max_estimators,\n        'learning_rate': 0.001,\n        'num_leaves': 37,\n        'min_data_in_leaf': 57,\n        'bagging_freq': 1,\n        'pos_bagging_fraction': 0.74,\n        'neg_bagging_fraction': 0.07,\n        'feature_fraction': 0.57,\n        'lambda_l1': 0.21,\n        'lambda_l2': 0.7,\n        \"verbosity\": -1\n    }\n    scores = []\n    models = []\n    for fold in range(5):\n        df_train_fold = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n        df_valid_fold = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n        \n        train_weights = create_sample_weights(df_train_fold)\n        \n        train_dataset = lgb.Dataset(df_train_fold[train_cols], df_train_fold[\"target\"], weight=train_weights)\n        \n        valid_dataset = lgb.Dataset(df_valid_fold[train_cols], df_valid_fold[\"target\"], reference=train_dataset)\n        \n        eval_set = [(df_valid_fold[train_cols], df_valid_fold[\"target\"])]\n        callbacks = []\n        \n        if use_early_stopping:\n            rounds_between_pauc_check = 50\n            early_stopping_callback = EarlyStoppingByPAUC(\n                stopping_cycles=early_stopping_rounds // rounds_between_pauc_check,\n                period=rounds_between_pauc_check,\n                eval_set=eval_set\n            )\n            callbacks.append(early_stopping_callback)\n        \n        try:\n            model = lgb.train(\n                lgb_params,\n                train_dataset,\n                valid_sets=[valid_dataset],\n                callbacks=callbacks,\n                num_boost_round=lgb_params['n_estimators']\n            )\n\n        except EarlyStoppingException:\n            print(f\"Training stopped early.\")\n        else:\n            print(f\"Completed without early stopping\")\n\n        model = early_stopping_callback.best_model_state\n        score = early_stopping_callback.best_score\n        print(f\"Using best model from iteration {early_stopping_callback.best_iteration}\")\n        print(f\"Fold {fold} / Partial AUC Score: {score:.5f}\")            \n        \n        scores.append(score)        \n        models.append(model)\n    \n    print(\"\\nAverage pAUC:\", np.mean(scores))\n    return models, scores\n\n# Usage\nuse_early_stopping = True\nmodels, scores = train_lgbm_with_early_stopping(df_train, train_cols, use_early_stopping, early_stopping_rounds)\nnp.mean(scores)","metadata":{"papermill":{"duration":15.358891,"end_time":"2024-09-04T03:59:54.632351","exception":false,"start_time":"2024-09-04T03:59:39.27346","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature importances\n* Interesting - but don't seem to matter much... ","metadata":{"papermill":{"duration":0.020369,"end_time":"2024-09-04T03:59:54.673782","exception":false,"start_time":"2024-09-04T03:59:54.653413","status":"completed"},"tags":[]}},{"cell_type":"code","source":"importances = np.mean([model.feature_importance(importance_type='gain') for model in models], axis=0)\ndf_imp = pd.DataFrame({\n    \"feature\": models[0].feature_name(),  # Assuming all models have the same feature names\n    \"importance\": importances\n}).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n\n# Print top 10 most important features\nprint(df_imp.head(30))","metadata":{"papermill":{"duration":0.034724,"end_time":"2024-09-04T03:59:54.728858","exception":false,"start_time":"2024-09-04T03:59:54.694134","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Models","metadata":{"papermill":{"duration":0.02055,"end_time":"2024-09-04T03:59:54.771397","exception":false,"start_time":"2024-09-04T03:59:54.750847","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_directory=\"saved_models\"\n\ndef save_models(models):\n    # Create the directory if it doesn't exist\n    if not os.path.exists(model_directory):\n        os.makedirs(model_directory)\n    \n    for i, model in enumerate(models):\n        model_path = os.path.join(model_directory, f\"model_fold_{i}.txt\")\n        model.save_model(model_path)\n    \n    print(f\"Models saved in {model_directory}\")\n\ndef load_models(directory=\"saved_models\"):\n    models = []\n    for i in range(5):  # Assuming 5-fold cross-validation\n        model_path = os.path.join(directory, f\"model_fold_{i}.txt\")\n        if os.path.exists(model_path):\n            model = lgb.Booster(model_file=model_path)\n            models.append(model)\n    \n    print(f\"Loaded {len(models)} models from {directory}\")\n    return models\n\nsave_models(models)","metadata":{"papermill":{"duration":0.058263,"end_time":"2024-09-04T03:59:54.85035","exception":false,"start_time":"2024-09-04T03:59:54.792087","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking Ensemble","metadata":{"papermill":{"duration":0.02084,"end_time":"2024-09-04T03:59:54.892347","exception":false,"start_time":"2024-09-04T03:59:54.871507","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef get_probabilities(model, X):\n    if hasattr(model, 'predict_proba'):\n        return model.predict_proba(X)[:, 1]\n    else:\n        return sigmoid(model.predict(X))\n\ndef stacking_ensemble_lgb_new(models, X_train, y_train, X_test, train_cols, meta_model=LogisticRegression()):\n    num_models = len(models)\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    oof_preds = np.zeros((len(y_train), num_models))\n    test_preds = np.zeros((len(X_test), num_models))\n\n    for i, model in enumerate(models):\n        # Generate out-of-fold predictions\n        for train_idx, val_idx in kf.split(X_train):\n            oof_preds[val_idx, i] = get_probabilities(model, X_train.iloc[val_idx][train_cols])\n        \n        # Generate test predictions\n        test_preds[:, i] = get_probabilities(model, X_test[train_cols])\n\n    # Train meta-model\n    meta_model.fit(oof_preds, y_train)\n    final_preds = meta_model.predict_proba(test_preds)[:, 1]\n    return final_preds","metadata":{"papermill":{"duration":0.033845,"end_time":"2024-09-04T03:59:54.947557","exception":false,"start_time":"2024-09-04T03:59:54.913712","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assign Predictions","metadata":{"papermill":{"duration":0.020748,"end_time":"2024-09-04T03:59:54.989824","exception":false,"start_time":"2024-09-04T03:59:54.969076","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#just average models (values look different than as produces by ensemble test code)\n#preds = np.mean([model.predict(df_test[train_cols]) for model in models], 0)\n\n# Stacking Ensemble\npreds = stacking_ensemble_lgb_new(models, df_train, df_train[\"target\"], df_test, train_cols)\npreds","metadata":{"papermill":{"duration":2.347619,"end_time":"2024-09-04T03:59:57.358222","exception":false,"start_time":"2024-09-04T03:59:55.010603","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Noise to final preds...","metadata":{"papermill":{"duration":0.04843,"end_time":"2024-09-04T03:59:57.456083","exception":false,"start_time":"2024-09-04T03:59:57.407653","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def generate_seeded_noise(seed, size, noise_factor):\n    np.random.seed(seed)\n    return np.random.normal(loc=0, scale=noise_factor, size=size)\n\ndef apply_stacked_noise(preds, magic_noise_seeds, noise_factor=0.025):\n    stacked_noise = np.zeros_like(preds)\n    for i, noise_seed in enumerate(magic_noise_seeds):\n        layer_noise = generate_seeded_noise(noise_seed, len(preds), noise_factor)\n        stacked_noise += layer_noise\n    \n    # Modify predictions with stacked noise\n    modified_preds = np.clip(preds + stacked_noise, 0, 1)\n    \n    return modified_preds\n\npreds = apply_stacked_noise(preds, magic_noise_seeds, magic_noise_factor)\n\npreds","metadata":{"papermill":{"duration":0.033893,"end_time":"2024-09-04T03:59:57.524656","exception":false,"start_time":"2024-09-04T03:59:57.490763","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit!","metadata":{"papermill":{"duration":0.020666,"end_time":"2024-09-04T03:59:57.566475","exception":false,"start_time":"2024-09-04T03:59:57.545809","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\ndf_sub[\"target\"] = preds\ndf_sub.to_csv(\"submission_3.csv\", index=False)\ndf_sub","metadata":{"papermill":{"duration":0.042339,"end_time":"2024-09-04T03:59:57.629986","exception":false,"start_time":"2024-09-04T03:59:57.587647","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm1 = pd.read_csv('submission_1.csv')\nsm2 = pd.read_csv('submission_2.csv')\nsm3 = pd.read_csv('submission_3.csv')\ndisplay(sm1,sm2,sm3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms = pd.merge(sm1,sm2, on=['isic_id'])\nsms = pd.merge(sms,sm3, on=['isic_id'])\nsms['target'] = (sms['target_x']/100000 + sms['target_y']/1000 + sms['target']) / 3\nsub = sms[['isic_id','target']]\nsub.to_csv('submission.csv', index=False, float_format='%.7f')\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}